#!/bin/bash
# Titre: Script d'installation de l'infrastructure LIONS sur VPS
# Description: Orchestre l'installation compl√®te de l'infrastructure LIONS sur un VPS
# Auteur: √âquipe LIONS Infrastructure
# Date: 2023-05-15
# Version: 1.0.0

# Configuration
readonly SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
readonly PROJECT_ROOT="$(cd "${SCRIPT_DIR}/.." && pwd)"
readonly ANSIBLE_DIR="${PROJECT_ROOT}/ansible"
readonly LOG_DIR="./logs/infrastructure"
readonly LOG_FILE="${LOG_DIR}/install-$(date +%Y%m%d-%H%M%S).log"
readonly DEFAULT_ENV="development"
readonly BACKUP_DIR="${LOG_DIR}/backups"
readonly STATE_FILE="${LOG_DIR}/.installation_state"
readonly LOCK_FILE="/tmp/lions_install.lock"
readonly REQUIRED_SPACE_MB=5000  # 5 Go d'espace disque requis
readonly TIMEOUT_SECONDS=1800    # 30 minutes de timeout pour les commandes longues
readonly REQUIRED_PORTS=(22 22225 80 443 6443 30000 30001)

# Couleurs pour l'affichage
readonly COLOR_RESET="\033[0m"
readonly COLOR_RED="\033[0;31m"
readonly COLOR_GREEN="\033[0;32m"
readonly COLOR_YELLOW="\033[0;33m"
readonly COLOR_BLUE="\033[0;34m"
readonly COLOR_MAGENTA="\033[0;35m"
readonly COLOR_CYAN="\033[0;36m"
readonly COLOR_WHITE="\033[0;37m"
readonly COLOR_BOLD="\033[1m"

# Variables globales
INSTALLATION_STEP=""
LAST_COMMAND=""
LAST_ERROR=""
RETRY_COUNT=0
MAX_RETRIES=3

# Cr√©ation des r√©pertoires n√©cessaires
mkdir -p "${LOG_DIR}"
mkdir -p "${BACKUP_DIR}"

# Activation du mode strict apr√®s les v√©rifications initiales
set -euo pipefail

# Fonction de logging am√©lior√©e
function log() {
    local level="$1"
    local message="$2"
    local timestamp="$(date +"%Y-%m-%d %H:%M:%S")"
    local caller_info=""
    local log_color="${COLOR_RESET}"
    local log_prefix=""

    # D√©termination de la fonction appelante et du num√©ro de ligne
    if [[ "${debug_mode}" == "true" ]]; then
        # R√©cup√©ration de la trace d'appel (fonction appelante et num√©ro de ligne)
        local caller_function=$(caller 0 | awk '{print $2}')
        local caller_line=$(caller 0 | awk '{print $1}')

        if [[ -n "${caller_function}" && "${caller_function}" != "main" ]]; then
            caller_info=" [${caller_function}:${caller_line}]"
        else
            caller_info=" [ligne:${caller_line}]"
        fi
    fi

    # S√©lection de la couleur et du pr√©fixe en fonction du niveau
    case "${level}" in
        "INFO")     log_color="${COLOR_BLUE}"; log_prefix="‚ÑπÔ∏è " ;;
        "WARNING")  log_color="${COLOR_YELLOW}"; log_prefix="‚ö†Ô∏è " ;;
        "ERROR")    log_color="${COLOR_RED}"; log_prefix="‚ùå " ;;
        "DEBUG")    log_color="${COLOR_MAGENTA}"; log_prefix="üîç " ;;
        "SUCCESS")  log_color="${COLOR_GREEN}"; log_prefix="‚úÖ " ;;
        "STEP")     log_color="${COLOR_CYAN}${COLOR_BOLD}"; log_prefix="üîÑ " ;;
    esac

    # Affichage du message avec formatage
    echo -e "${log_color}${log_prefix}[${timestamp}] [${level}]${caller_info}${COLOR_RESET} ${message}"

    # Enregistrement dans le fichier de log
    echo "[${timestamp}] [${level}]${caller_info} ${message}" >> "${LOG_FILE}"

    # Enregistrement des erreurs dans un fichier s√©par√© pour faciliter le diagnostic
    if [[ "${level}" == "ERROR" ]]; then
        echo "[${timestamp}] [${level}]${caller_info} ${message}" >> "${LOG_DIR}/errors.log"
    fi

    # Enregistrement des avertissements dans un fichier s√©par√©
    if [[ "${level}" == "WARNING" ]]; then
        echo "[${timestamp}] [${level}]${caller_info} ${message}" >> "${LOG_DIR}/warnings.log"
    fi
}

# Fonction pour collecter et analyser les logs
function collect_logs() {
    local output_dir="${LOG_DIR}/diagnostic-$(date +%Y%m%d-%H%M%S)"
    mkdir -p "${output_dir}"

    log "INFO" "Collecte des logs pour diagnostic dans ${output_dir}..."

    # Copie du log d'installation
    cp "${LOG_FILE}" "${output_dir}/install.log"

    # Collecte des logs du VPS
    if [[ -n "${ansible_host}" && -n "${ansible_port}" && -n "${ansible_user}" ]]; then
        log "INFO" "Collecte des logs du VPS..."

        # Cr√©ation d'un script temporaire pour collecter les logs sur le VPS
        local tmp_script=$(mktemp)
        cat > "${tmp_script}" << 'EOF'
#!/bin/bash
# Script de collecte de logs sur le VPS
OUTPUT_DIR="/tmp/lions_logs"
mkdir -p "${OUTPUT_DIR}"

# Logs syst√®me
echo "Collecte des logs syst√®me..."
dmesg > "${OUTPUT_DIR}/dmesg.log" 2>/dev/null || true
journalctl -n 1000 > "${OUTPUT_DIR}/journalctl.log" 2>/dev/null || true
journalctl -u k3s -n 500 > "${OUTPUT_DIR}/k3s.log" 2>/dev/null || true
journalctl -u kubelet -n 500 > "${OUTPUT_DIR}/kubelet.log" 2>/dev/null || true

# Informations syst√®me
echo "Collecte des informations syst√®me..."
uname -a > "${OUTPUT_DIR}/uname.log" 2>/dev/null || true
free -h > "${OUTPUT_DIR}/memory.log" 2>/dev/null || true
df -h > "${OUTPUT_DIR}/disk.log" 2>/dev/null || true
top -b -n 1 > "${OUTPUT_DIR}/top.log" 2>/dev/null || true
ps aux > "${OUTPUT_DIR}/ps.log" 2>/dev/null || true
netstat -tuln > "${OUTPUT_DIR}/netstat.log" 2>/dev/null || true
ip addr > "${OUTPUT_DIR}/ip_addr.log" 2>/dev/null || true
ip route > "${OUTPUT_DIR}/ip_route.log" 2>/dev/null || true

# Logs Kubernetes
if command -v kubectl &>/dev/null; then
    echo "Collecte des logs Kubernetes..."
    kubectl get nodes -o wide > "${OUTPUT_DIR}/k8s_nodes.log" 2>/dev/null || true
    kubectl get pods --all-namespaces -o wide > "${OUTPUT_DIR}/k8s_pods.log" 2>/dev/null || true
    kubectl get services --all-namespaces > "${OUTPUT_DIR}/k8s_services.log" 2>/dev/null || true
    kubectl get deployments --all-namespaces > "${OUTPUT_DIR}/k8s_deployments.log" 2>/dev/null || true
    kubectl get events --all-namespaces --sort-by='.lastTimestamp' > "${OUTPUT_DIR}/k8s_events.log" 2>/dev/null || true

    # Logs des pods en erreur
    for pod in $(kubectl get pods --all-namespaces -o jsonpath='{range .items[?(@.status.phase!="Running")]}{.metadata.namespace}/{.metadata.name}{"\n"}{end}'); do
        ns=$(echo ${pod} | cut -d/ -f1)
        name=$(echo ${pod} | cut -d/ -f2)
        kubectl logs -n ${ns} ${name} > "${OUTPUT_DIR}/pod_${ns}_${name}.log" 2>/dev/null || true
        kubectl describe pod -n ${ns} ${name} > "${OUTPUT_DIR}/pod_${ns}_${name}_describe.log" 2>/dev/null || true
    done
fi

# Compression des logs
tar -czf "/tmp/lions_logs.tar.gz" -C "/tmp" "lions_logs" 2>/dev/null || true
rm -rf "${OUTPUT_DIR}"

echo "Collecte des logs termin√©e"
EOF

        # Copie et ex√©cution du script sur le VPS
        scp -P "${ansible_port}" "${tmp_script}" "${ansible_user}@${ansible_host}:/tmp/collect_logs.sh" &>/dev/null
        ssh -o BatchMode=yes -o ConnectTimeout=10 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "chmod +x /tmp/collect_logs.sh && sudo /tmp/collect_logs.sh" &>/dev/null

        # R√©cup√©ration des logs
        scp -P "${ansible_port}" "${ansible_user}@${ansible_host}:/tmp/lions_logs.tar.gz" "${output_dir}/vps_logs.tar.gz" &>/dev/null

        # Nettoyage
        ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "rm -f /tmp/collect_logs.sh /tmp/lions_logs.tar.gz" &>/dev/null
        rm -f "${tmp_script}"

        # Extraction des logs
        mkdir -p "${output_dir}/vps_logs"
        tar -xzf "${output_dir}/vps_logs.tar.gz" -C "${output_dir}/vps_logs" &>/dev/null
        rm -f "${output_dir}/vps_logs.tar.gz"
    fi

    # Collecte des logs locaux
    log "INFO" "Collecte des logs locaux..."

    # Informations syst√®me locales
    uname -a > "${output_dir}/local_uname.log" 2>/dev/null || true
    df -h > "${output_dir}/local_disk.log" 2>/dev/null || true

    # Logs Kubernetes locaux
    if command_exists kubectl; then
        kubectl version --client > "${output_dir}/local_kubectl_version.log" 2>/dev/null || true
        kubectl config view --minify > "${output_dir}/local_kubectl_config.log" 2>/dev/null || true
    fi

    # Logs Ansible locaux
    if command_exists ansible-playbook; then
        ansible-playbook --version > "${output_dir}/local_ansible_version.log" 2>/dev/null || true
    fi

    # Compression des logs
    log "INFO" "Compression des logs..."
    local archive_file="${LOG_DIR}/diagnostic-$(date +%Y%m%d-%H%M%S).tar.gz"
    tar -czf "${archive_file}" -C "$(dirname "${output_dir}")" "$(basename "${output_dir}")" &>/dev/null
    rm -rf "${output_dir}"

    log "SUCCESS" "Logs collect√©s et archiv√©s dans ${archive_file}"

    # Analyse des logs
    log "INFO" "Analyse des logs..."

    # Extraction des erreurs courantes
    if tar -xzf "${archive_file}" -C /tmp &>/dev/null; then
        local extracted_dir="/tmp/$(basename "${output_dir}")"

        # Recherche des erreurs courantes
        log "INFO" "Recherche des erreurs courantes..."

        # Erreurs de connexion
        if grep -r "Connection refused" "${extracted_dir}" &>/dev/null; then
            log "WARNING" "Erreurs de connexion d√©tect√©es - v√©rifiez que les services sont en cours d'ex√©cution"
        fi

        # Erreurs de permission
        if grep -r "Permission denied" "${extracted_dir}" &>/dev/null; then
            log "WARNING" "Erreurs de permission d√©tect√©es - v√©rifiez les droits d'acc√®s"
        fi

        # Erreurs d'espace disque
        if grep -r "No space left on device" "${extracted_dir}" &>/dev/null; then
            log "WARNING" "Erreurs d'espace disque d√©tect√©es - lib√©rez de l'espace et r√©essayez"
        fi

        # Erreurs de m√©moire
        if grep -r "Out of memory" "${extracted_dir}" &>/dev/null; then
            log "WARNING" "Erreurs de m√©moire d√©tect√©es - augmentez la m√©moire disponible"
        fi

        # Erreurs de r√©seau
        if grep -r "Network is unreachable" "${extracted_dir}" &>/dev/null; then
            log "WARNING" "Erreurs de r√©seau d√©tect√©es - v√©rifiez la connectivit√© r√©seau"
        fi

        # Nettoyage
        rm -rf "${extracted_dir}"
    fi

    return 0
}

# Fonction de gestion des erreurs
function handle_error() {
    local exit_code=$?
    local line_number=$1
    local command_name=$2

    # D√©sactivation du mode strict pour la gestion des erreurs
    set +euo pipefail

    log "ERROR" "Une erreur s'est produite √† la ligne ${line_number} (code ${exit_code})"
    log "ERROR" "Derni√®re commande ex√©cut√©e: ${LAST_COMMAND}"

    # Collecte d'informations de diagnostic suppl√©mentaires
    local error_details=""
    case ${exit_code} in
        1)   error_details="Erreur g√©n√©rale ou erreur de commande inconnue" ;;
        2)   error_details="Erreur de syntaxe dans l'utilisation de la commande" ;;
        126) error_details="La commande ne peut pas √™tre ex√©cut√©e (probl√®me de permissions)" ;;
        127) error_details="Commande non trouv√©e" ;;
        128) error_details="Argument invalide pour exit" ;;
        130) error_details="Script termin√© par Ctrl+C" ;;
        137) error_details="Script termin√© par SIGKILL (possiblement manque de m√©moire)" ;;
        139) error_details="Erreur de segmentation (bug dans un programme)" ;;
        *)   error_details="Code d'erreur non sp√©cifique" ;;
    esac

    log "ERROR" "D√©tails de l'erreur: ${error_details}"

    # Enregistrement de l'erreur avec plus de d√©tails
    LAST_ERROR="Erreur √† la ligne ${line_number} (code ${exit_code}): ${LAST_COMMAND} - ${error_details}"

    # Sauvegarde de l'√©tat actuel et des logs pour analyse
    echo "${INSTALLATION_STEP}" > "${STATE_FILE}"
    cp "${LOG_FILE}" "${BACKUP_DIR}/error-log-$(date +%Y%m%d-%H%M%S).log"

    # V√©rification de l'√©tat du syst√®me avant de tenter une reprise
    log "INFO" "V√©rification de l'√©tat du syst√®me avant reprise..."

    # V√©rification de la connectivit√© r√©seau
    if ! ping -c 1 -W 5 "${ansible_host}" &>/dev/null; then
        log "ERROR" "Connectivit√© r√©seau perdue avec le VPS (${ansible_host})"
        log "ERROR" "Impossible de reprendre l'installation sans connectivit√© r√©seau"
        cleanup
        exit 1
    fi

    # V√©rification de l'espace disque
    if ! check_disk_space; then
        log "ERROR" "Espace disque insuffisant pour continuer l'installation"
        cleanup
        exit 1
    fi

    # Tentative de reprise si possible
    if [[ ${RETRY_COUNT} -lt ${MAX_RETRIES} ]]; then
        RETRY_COUNT=$((RETRY_COUNT + 1))
        log "WARNING" "Tentative de reprise (${RETRY_COUNT}/${MAX_RETRIES})..."

        # Suppression du fichier de verrouillage avant la reprise
        if [[ -f "${LOCK_FILE}" ]]; then
            log "INFO" "Suppression du fichier de verrouillage avant la reprise..."
            rm -f "${LOCK_FILE}"
        fi

        # Attente avant la reprise pour permettre au syst√®me de se stabiliser
        log "INFO" "Attente de 10 secondes avant reprise..."
        sleep 10

        # Reprise en fonction de l'√©tape avec gestion sp√©cifique selon la commande qui a √©chou√©
        case "${INSTALLATION_STEP}" in
            "init_vps")
                log "INFO" "Reprise de l'initialisation du VPS..."
                if [[ "${command_name}" == "ansible_playbook" ]]; then
                    log "INFO" "Tentative de reprise avec des options plus s√ªres..."
                    # Tentative avec des options plus s√ªres pour Ansible
                    ansible-playbook -i "${ANSIBLE_DIR}/${inventory_file}" "${ANSIBLE_DIR}/playbooks/init-vps.yml" --ask-become-pass --forks=1 --timeout=60
                else
                    initialiser_vps
                fi
                ;;
            "install_k3s")
                log "INFO" "Reprise de l'installation de K3s..."
                if [[ "${command_name}" == "ansible_playbook" ]]; then
                    log "INFO" "Tentative de reprise avec des options plus s√ªres..."
                    # Tentative avec des options plus s√ªres pour Ansible
                    ansible-playbook -i "${ANSIBLE_DIR}/${inventory_file}" "${ANSIBLE_DIR}/playbooks/install-k3s.yml" --ask-become-pass --forks=1 --timeout=60
                else
                    installer_k3s
                fi
                ;;
            "deploy_infra")
                log "INFO" "Reprise du d√©ploiement de l'infrastructure de base..."
                if [[ "${command_name}" == "kubectl_apply" ]]; then
                    log "INFO" "Tentative de reprise avec validation d√©sactiv√©e..."
                    kubectl apply -k "${PROJECT_ROOT}/kubernetes/overlays/${environment}" --validate=false --timeout=10m
                else
                    deployer_infrastructure_base
                fi
                ;;
            "deploy_monitoring")
                log "INFO" "Reprise du d√©ploiement du monitoring..."
                if [[ "${command_name}" == "helm_install" ]]; then
                    log "INFO" "Tentative de reprise avec des options plus s√ªres..."
                    helm upgrade --install prometheus prometheus-community/kube-prometheus-stack --namespace monitoring --values "${values_file}" --timeout 15m --atomic
                else
                    deployer_monitoring
                fi
                ;;
            "verify")
                log "INFO" "Reprise de la v√©rification de l'installation..."
                verifier_installation
                ;;
            "prerequis")
                log "INFO" "Reprise de la v√©rification des pr√©requis..."
                verifier_prerequis
                ;;
            *)
                log "ERROR" "Impossible de reprendre √† l'√©tape '${INSTALLATION_STEP}'"
                log "ERROR" "Veuillez consulter les logs pour plus d'informations et corriger manuellement le probl√®me"
                log "INFO" "Vous pouvez ensuite relancer le script avec l'option --skip-init si l'initialisation a d√©j√† √©t√© effectu√©e"
                cleanup
                exit ${exit_code}
                ;;
        esac
    else
        log "ERROR" "Nombre maximal de tentatives atteint (${MAX_RETRIES})"
        log "ERROR" "Derni√®re erreur: ${LAST_ERROR}"

        # G√©n√©ration d'un rapport de diagnostic
        generate_diagnostic_report

        log "INFO" "Un rapport de diagnostic a √©t√© g√©n√©r√© dans ${BACKUP_DIR}/diagnostic-$(date +%Y%m%d-%H%M%S).txt"
        log "INFO" "Veuillez consulter ce rapport pour identifier et corriger le probl√®me"

        cleanup
        exit ${exit_code}
    fi
}

# Fonction de g√©n√©ration de rapport de diagnostic
function generate_diagnostic_report() {
    local report_file="${BACKUP_DIR}/diagnostic-$(date +%Y%m%d-%H%M%S).txt"

    log "INFO" "G√©n√©ration d'un rapport de diagnostic complet..."

    {
        echo "=== RAPPORT DE DIAGNOSTIC LIONS INFRASTRUCTURE ==="
        echo "Date: $(date)"
        echo "Environnement: ${environment}"
        echo "√âtape d'installation: ${INSTALLATION_STEP}"
        echo ""

        echo "=== INFORMATIONS SUR L'ERREUR ==="
        echo "Derni√®re commande: ${LAST_COMMAND}"
        echo "Derni√®re erreur: ${LAST_ERROR}"
        echo "Nombre de tentatives: ${RETRY_COUNT}/${MAX_RETRIES}"
        echo ""

        echo "=== INFORMATIONS SYST√àME LOCAL ==="
        echo "Syst√®me d'exploitation: $(uname -a)"
        echo "Espace disque disponible: $(df -h . | awk 'NR==2 {print $4}')"
        echo "M√©moire disponible: $(free -h | awk '/^Mem:/ {print $7}')"
        echo ""

        echo "=== INFORMATIONS SUR LE VPS ==="
        if ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "uname -a" &>/dev/null; then
            echo "Syst√®me d'exploitation: $(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "uname -a" 2>/dev/null)"
            echo "Espace disque disponible: $(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "df -h / | awk 'NR==2 {print \$4}'" 2>/dev/null)"
            echo "M√©moire disponible: $(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "free -h | awk '/^Mem:/ {print \$7}'" 2>/dev/null)"
            echo "Charge syst√®me: $(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "uptime" 2>/dev/null)"
            echo "Services actifs: $(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "systemctl list-units --state=running --type=service --no-pager | grep -v systemd | head -10" 2>/dev/null)"
        else
            echo "Impossible de se connecter au VPS pour r√©cup√©rer les informations"
        fi
        echo ""

        echo "=== √âTAT DE KUBERNETES ==="
        if command_exists kubectl && kubectl cluster-info &>/dev/null; then
            echo "Version de Kubernetes: $(kubectl version --short 2>/dev/null)"
            echo "N≈ìuds: $(kubectl get nodes -o wide 2>/dev/null)"
            echo "Pods par namespace: $(kubectl get pods --all-namespaces -o wide 2>/dev/null)"
            echo "Services: $(kubectl get services --all-namespaces 2>/dev/null)"
            echo "√âv√©nements r√©cents: $(kubectl get events --all-namespaces --sort-by='.lastTimestamp' | tail -20 2>/dev/null)"
        else
            echo "Kubernetes n'est pas accessible ou n'est pas install√©"
        fi
        echo ""

        echo "=== LOGS PERTINENTS ==="
        echo "Derni√®res lignes du log d'installation:"
        tail -50 "${LOG_FILE}" 2>/dev/null
        echo ""

        echo "=== V√âRIFICATIONS R√âSEAU ==="
        echo "Ping vers le VPS: $(ping -c 3 "${ansible_host}" 2>&1)"
        echo "Ports ouverts sur le VPS:"
        for port in "${REQUIRED_PORTS[@]}"; do
            if nc -z -w 5 "${ansible_host}" "${port}" &>/dev/null; then
                echo "  - Port ${port}: OUVERT"
            else
                echo "  - Port ${port}: FERM√â"
            fi
        done
        echo ""

        echo "=== RECOMMANDATIONS ==="
        echo "1. V√©rifiez la connectivit√© r√©seau avec le VPS"
        echo "2. Assurez-vous que tous les ports requis sont ouverts"
        echo "3. V√©rifiez l'espace disque et la m√©moire disponibles"
        echo "4. Consultez les logs pour plus de d√©tails sur l'erreur"
        echo "5. Corrigez les probl√®mes identifi√©s et relancez le script"
        echo "6. Si n√©cessaire, utilisez l'option --skip-init pour reprendre apr√®s l'initialisation"
        echo ""

        echo "=== FIN DU RAPPORT ==="
    } > "${report_file}"

    log "SUCCESS" "Rapport de diagnostic g√©n√©r√©: ${report_file}"
    return 0
}

# Fonction de nettoyage
function cleanup() {
    log "INFO" "Nettoyage des ressources temporaires..."

    # Suppression du fichier de verrouillage
    if [[ -f "${LOCK_FILE}" ]]; then
        rm -f "${LOCK_FILE}"
    fi

    # Affichage des informations de diagnostic
    log "INFO" "Informations de diagnostic:"
    log "INFO" "- Derni√®re √©tape: ${INSTALLATION_STEP}"
    log "INFO" "- Derni√®re commande: ${LAST_COMMAND}"
    log "INFO" "- Derni√®re erreur: ${LAST_ERROR}"
    log "INFO" "- Fichier de log: ${LOG_FILE}"

    log "INFO" "Nettoyage termin√©"
}

# Configuration du gestionnaire d'erreurs
trap 'handle_error ${LINENO} "${COMMAND_NAME:-unknown}"' ERR

# Configuration du gestionnaire de sortie pour s'assurer que le fichier de verrouillage est toujours supprim√©
trap 'if [[ -f "${LOCK_FILE}" ]]; then rm -f "${LOCK_FILE}"; fi' EXIT

# Fonction pour v√©rifier si une commande existe
function command_exists() {
    command -v "$1" &> /dev/null
}

# Fonction pour installer les commandes manquantes
function install_missing_commands() {
    local commands=("$@")
    local os_name=$(uname -s)
    local success=true

    log "INFO" "D√©tection du syst√®me d'exploitation: ${os_name}"

    # D√©tection du gestionnaire de paquets
    local pkg_manager=""
    local install_cmd=""

    if [[ "${os_name}" == "Linux" ]]; then
        # D√©tection de la distribution Linux
        if command_exists apt-get; then
            pkg_manager="apt"
            install_cmd="apt-get install -y"
        elif command_exists dnf; then
            pkg_manager="dnf"
            install_cmd="dnf install -y"
        elif command_exists yum; then
            pkg_manager="yum"
            install_cmd="yum install -y"
        elif command_exists pacman; then
            pkg_manager="pacman"
            install_cmd="pacman -S --noconfirm"
        elif command_exists zypper; then
            pkg_manager="zypper"
            install_cmd="zypper install -y"
        else
            log "ERROR" "Gestionnaire de paquets non reconnu sur ce syst√®me Linux"
            return 1
        fi
    elif [[ "${os_name}" == "Darwin" ]]; then
        # macOS - v√©rification de Homebrew
        if command_exists brew; then
            pkg_manager="brew"
            install_cmd="brew install"
        else
            log "ERROR" "Homebrew n'est pas install√© sur ce syst√®me macOS"
            log "INFO" "Installez Homebrew avec: /bin/bash -c \"\$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\""
            return 1
        fi
    else
        log "ERROR" "Syst√®me d'exploitation non support√© pour l'installation automatique: ${os_name}"
        return 1
    fi

    log "INFO" "Utilisation du gestionnaire de paquets: ${pkg_manager}"

    # Mise √† jour des d√©p√¥ts si n√©cessaire
    if [[ "${pkg_manager}" == "apt" ]]; then
        log "INFO" "Mise √† jour des d√©p√¥ts apt..."
        if ! sudo apt-get update &>/dev/null; then
            log "WARNING" "Impossible de mettre √† jour les d√©p√¥ts apt"
        fi
    elif [[ "${pkg_manager}" == "dnf" || "${pkg_manager}" == "yum" ]]; then
        log "INFO" "Mise √† jour des d√©p√¥ts ${pkg_manager}..."
        if ! sudo ${pkg_manager} check-update &>/dev/null; then
            log "WARNING" "Impossible de mettre √† jour les d√©p√¥ts ${pkg_manager}"
        fi
    fi

    # Installation des commandes manquantes
    for cmd in "${commands[@]}"; do
        log "INFO" "Installation de la commande: ${cmd}"

        # Mapping des noms de commandes aux noms de paquets
        local pkg_name=""
        case "${cmd}" in
            "jq")
                pkg_name="jq"
                ;;
            "ansible-playbook")
                if [[ "${pkg_manager}" == "apt" ]]; then
                    pkg_name="ansible"
                elif [[ "${pkg_manager}" == "brew" ]]; then
                    pkg_name="ansible"
                else
                    pkg_name="ansible"
                fi
                ;;
            "kubectl")
                if [[ "${pkg_manager}" == "apt" ]]; then
                    # Pour Debian/Ubuntu, kubectl n√©cessite un d√©p√¥t sp√©cial
                    log "INFO" "Configuration du d√©p√¥t Kubernetes pour apt..."
                    if ! command_exists curl; then
                        sudo apt-get install -y curl &>/dev/null
                    fi
                    curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - &>/dev/null
                    echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list &>/dev/null
                    sudo apt-get update &>/dev/null
                    pkg_name="kubectl"
                elif [[ "${pkg_manager}" == "brew" ]]; then
                    pkg_name="kubernetes-cli"
                else
                    pkg_name="kubectl"
                fi
                ;;
            "helm")
                if [[ "${pkg_manager}" == "apt" ]]; then
                    # Pour Debian/Ubuntu, helm n√©cessite un d√©p√¥t sp√©cial
                    log "INFO" "Configuration du d√©p√¥t Helm pour apt..."
                    if ! command_exists curl; then
                        sudo apt-get install -y curl &>/dev/null
                    fi
                    curl https://baltocdn.com/helm/signing.asc | sudo apt-key add - &>/dev/null
                    echo "deb https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list &>/dev/null
                    sudo apt-get update &>/dev/null
                    pkg_name="helm"
                elif [[ "${pkg_manager}" == "brew" ]]; then
                    pkg_name="helm"
                else
                    pkg_name="helm"
                fi
                ;;
            "timeout")
                if [[ "${pkg_manager}" == "apt" ]]; then
                    pkg_name="coreutils"
                elif [[ "${pkg_manager}" == "brew" ]]; then
                    pkg_name="coreutils"
                else
                    pkg_name="coreutils"
                fi
                ;;
            "nc")
                if [[ "${pkg_manager}" == "apt" ]]; then
                    pkg_name="netcat"
                elif [[ "${pkg_manager}" == "brew" ]]; then
                    pkg_name="netcat"
                else
                    pkg_name="netcat"
                fi
                ;;
            "ping")
                if [[ "${pkg_manager}" == "apt" ]]; then
                    pkg_name="iputils-ping"
                elif [[ "${pkg_manager}" == "brew" ]]; then
                    pkg_name="inetutils"
                else
                    pkg_name="iputils"
                fi
                ;;
            "ssh"|"scp")
                if [[ "${pkg_manager}" == "apt" ]]; then
                    pkg_name="openssh-client"
                elif [[ "${pkg_manager}" == "brew" ]]; then
                    pkg_name="openssh"
                else
                    pkg_name="openssh"
                fi
                ;;
            *)
                # Si la commande n'est pas dans notre mapping, on utilise le m√™me nom
                pkg_name="${cmd}"
                ;;
        esac

        # Installation du paquet
        log "INFO" "Installation du paquet: ${pkg_name}"
        if ! sudo ${install_cmd} ${pkg_name} &>/dev/null; then
            log "ERROR" "√âchec de l'installation de ${pkg_name}"
            success=false
        else
            log "SUCCESS" "Installation de ${pkg_name} r√©ussie"
            # V√©rification que la commande est maintenant disponible
            if ! command_exists "${cmd}"; then
                log "WARNING" "La commande ${cmd} n'est toujours pas disponible apr√®s l'installation"
                success=false
            fi
        fi
    done

    return $( [[ "${success}" == "true" ]] && echo 0 || echo 1 )
}

# Fonction pour v√©rifier les ressources syst√®me locales
function check_local_resources() {
    log "INFO" "V√©rification des ressources syst√®me locales..."

    # V√©rification de l'espace disque
    local available_space=$(df -m . | awk 'NR==2 {print $4}')

    if [[ ${available_space} -lt ${REQUIRED_SPACE_MB} ]]; then
        log "ERROR" "Espace disque local insuffisant: ${available_space}MB disponible, ${REQUIRED_SPACE_MB}MB requis"
        return 1
    else
        log "INFO" "Espace disque local disponible: ${available_space}MB (minimum requis: ${REQUIRED_SPACE_MB}MB)"
    fi

    # V√©rification de la m√©moire disponible
    local os_name=$(uname -s)
    local available_memory=0

    if [[ "${os_name}" == "Linux" ]]; then
        available_memory=$(free -m | awk '/^Mem:/ {print $7}')
    elif [[ "${os_name}" == "Darwin" ]]; then
        available_memory=$(vm_stat | awk '/Pages free/ {free=$3} /Pages inactive/ {inactive=$3} END {print (free+inactive)*4096/1048576}' | cut -d. -f1)
    else
        log "WARNING" "Syst√®me d'exploitation non reconnu, impossible de v√©rifier la m√©moire disponible"
        available_memory=1024  # Valeur par d√©faut
    fi

    if [[ ${available_memory} -lt 1024 ]]; then
        log "WARNING" "M√©moire locale disponible limit√©e: ${available_memory}MB (recommand√©: 1024MB minimum)"
        log "WARNING" "Des probl√®mes de performance peuvent survenir pendant l'installation"
    else
        log "INFO" "M√©moire locale disponible: ${available_memory}MB (minimum recommand√©: 1024MB)"
    fi

    # V√©rification du nombre de processeurs
    local cpu_count=0

    if [[ "${os_name}" == "Linux" ]]; then
        cpu_count=$(nproc --all 2>/dev/null || grep -c ^processor /proc/cpuinfo 2>/dev/null || echo 1)
    elif [[ "${os_name}" == "Darwin" ]]; then
        cpu_count=$(sysctl -n hw.ncpu 2>/dev/null || echo 1)
    else
        log "WARNING" "Syst√®me d'exploitation non reconnu, impossible de v√©rifier le nombre de processeurs"
        cpu_count=1  # Valeur par d√©faut
    fi

    if [[ ${cpu_count} -lt 2 ]]; then
        log "WARNING" "Nombre de processeurs limit√©: ${cpu_count} (recommand√©: 2 minimum)"
        log "WARNING" "Des probl√®mes de performance peuvent survenir pendant l'installation"
    else
        log "INFO" "Nombre de processeurs: ${cpu_count} (minimum recommand√©: 2)"
    fi

    log "SUCCESS" "V√©rification des ressources syst√®me locales termin√©e"
    return 0
}

# Fonction pour v√©rifier les ressources syst√®me du VPS
function check_vps_resources() {
    log "INFO" "V√©rification des ressources syst√®me du VPS..."

    # V√©rification de la connexion SSH
    if ! ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "echo 'Connexion SSH r√©ussie'" &>/dev/null; then
        log "ERROR" "Impossible de se connecter au VPS via SSH pour v√©rifier les ressources"
        return 1
    fi

    # V√©rification de l'espace disque
    local vps_disk_total=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "df -m / | awk 'NR==2 {print \$2}'" 2>/dev/null || echo "0")
    local vps_disk_used=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "df -m / | awk 'NR==2 {print \$3}'" 2>/dev/null || echo "0")
    local vps_disk_free=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "df -m / | awk 'NR==2 {print \$4}'" 2>/dev/null || echo "0")
    local vps_disk_use_percent=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "df -m / | awk 'NR==2 {print \$5}'" 2>/dev/null | sed 's/%//' || echo "0")

    log "INFO" "Espace disque du VPS: ${vps_disk_free}MB libre sur ${vps_disk_total}MB total (${vps_disk_use_percent}% utilis√©)"

    if [[ ${vps_disk_free} -lt ${REQUIRED_SPACE_MB} ]]; then
        log "ERROR" "Espace disque du VPS insuffisant: ${vps_disk_free}MB disponible, ${REQUIRED_SPACE_MB}MB requis"

        # V√©rification des r√©pertoires volumineux
        log "INFO" "Recherche des r√©pertoires volumineux sur le VPS..."
        local large_dirs=$(ssh -o BatchMode=yes -o ConnectTimeout=10 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "sudo du -h --max-depth=2 /var /home /opt /usr | sort -hr | head -10" 2>/dev/null || echo "Impossible de d√©terminer les r√©pertoires volumineux")
        log "INFO" "R√©pertoires volumineux sur le VPS:"
        echo "${large_dirs}"

        # Suggestion de solution
        log "INFO" "Suggestions:"
        log "INFO" "1. Lib√©rez de l'espace disque sur le VPS"
        log "INFO" "2. Augmentez la taille du disque du VPS"
        log "INFO" "3. Utilisez un autre VPS avec plus d'espace disque"

        return 1
    fi

    # V√©rification de la m√©moire
    local vps_memory_total=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "free -m | awk '/^Mem:/ {print \$2}'" 2>/dev/null || echo "0")
    local vps_memory_used=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "free -m | awk '/^Mem:/ {print \$3}'" 2>/dev/null || echo "0")
    local vps_memory_free=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "free -m | awk '/^Mem:/ {print \$4}'" 2>/dev/null || echo "0")
    local vps_memory_available=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "free -m | awk '/^Mem:/ {print \$7}'" 2>/dev/null || echo "0")

    log "INFO" "M√©moire du VPS: ${vps_memory_available}MB disponible sur ${vps_memory_total}MB total"

    # V√©rification du swap
    local vps_swap_total=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "free -m | awk '/^Swap:/ {print \$2}'" 2>/dev/null || echo "0")
    local vps_swap_used=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "free -m | awk '/^Swap:/ {print \$3}'" 2>/dev/null || echo "0")
    local vps_swap_free=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "free -m | awk '/^Swap:/ {print \$4}'" 2>/dev/null || echo "0")

    log "INFO" "Swap du VPS: ${vps_swap_free}MB libre sur ${vps_swap_total}MB total"

    # V√©rification des seuils de m√©moire
    if [[ ${vps_memory_total} -lt 4096 ]]; then
        log "WARNING" "M√©moire totale du VPS insuffisante: ${vps_memory_total}MB (recommand√©: 4096MB minimum)"
        log "WARNING" "Des probl√®mes de performance peuvent survenir pendant l'installation"

        if [[ ${vps_memory_total} -lt 2048 ]]; then
            log "ERROR" "M√©moire totale du VPS critique: ${vps_memory_total}MB (minimum absolu: 2048MB)"
            log "ERROR" "L'installation risque d'√©chouer par manque de m√©moire"

            # Suggestion de solution
            log "INFO" "Suggestions:"
            log "INFO" "1. Augmentez la m√©moire du VPS"
            log "INFO" "2. Ajoutez ou augmentez l'espace swap"
            log "INFO" "3. Utilisez un autre VPS avec plus de m√©moire"

            log "INFO" "Voulez-vous continuer malgr√© tout? (o/N)"
            read -r answer
            if [[ ! "${answer}" =~ ^[Oo]$ ]]; then
                return 1
            fi
        fi
    fi

    # V√©rification du nombre de processeurs
    local vps_cpu_cores=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "nproc --all" 2>/dev/null || echo "0")
    local vps_cpu_load=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "cat /proc/loadavg | awk '{print \$1}'" 2>/dev/null || echo "0")

    log "INFO" "CPU du VPS: ${vps_cpu_cores} c≈ìurs, charge actuelle: ${vps_cpu_load}"

    if [[ ${vps_cpu_cores} -lt 2 ]]; then
        log "WARNING" "Nombre de c≈ìurs CPU du VPS insuffisant: ${vps_cpu_cores} (recommand√©: 2 minimum)"
        log "WARNING" "Des probl√®mes de performance peuvent survenir pendant l'installation"
    fi

    # V√©rification de la charge CPU
    if (( $(echo "${vps_cpu_load} > ${vps_cpu_cores}" | bc -l) )); then
        log "WARNING" "Charge CPU du VPS √©lev√©e: ${vps_cpu_load} (nombre de c≈ìurs: ${vps_cpu_cores})"
        log "WARNING" "Le VPS est actuellement sous forte charge, ce qui peut affecter l'installation"

        # V√©rification des processus consommant le plus de CPU
        log "INFO" "Processus consommant le plus de CPU sur le VPS:"
        local top_cpu_processes=$(ssh -o BatchMode=yes -o ConnectTimeout=10 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "ps aux --sort=-%cpu | head -6" 2>/dev/null || echo "Impossible de d√©terminer les processus")
        echo "${top_cpu_processes}"
    fi

    # V√©rification des processus consommant le plus de m√©moire
    if [[ ${vps_memory_available} -lt 1024 ]]; then
        log "WARNING" "M√©moire disponible du VPS faible: ${vps_memory_available}MB"
        log "INFO" "Processus consommant le plus de m√©moire sur le VPS:"
        local top_mem_processes=$(ssh -o BatchMode=yes -o ConnectTimeout=10 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "ps aux --sort=-%mem | head -6" 2>/dev/null || echo "Impossible de d√©terminer les processus")
        echo "${top_mem_processes}"
    fi

    # V√©rification des services en cours d'ex√©cution
    log "INFO" "V√©rification des services en cours d'ex√©cution sur le VPS..."
    local running_services=$(ssh -o BatchMode=yes -o ConnectTimeout=10 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "systemctl list-units --type=service --state=running | grep -v systemd | head -10" 2>/dev/null || echo "Impossible de d√©terminer les services")
    log "INFO" "Services en cours d'ex√©cution sur le VPS (top 10):"
    echo "${running_services}" | grep -v "UNIT\|LOAD\|ACTIVE\|SUB\|DESCRIPTION\|^$\|loaded units listed"

    # V√©rification des ports ouverts
    log "INFO" "V√©rification des ports ouverts sur le VPS..."
    local open_ports=$(ssh -o BatchMode=yes -o ConnectTimeout=10 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "ss -tuln | grep LISTEN" 2>/dev/null || echo "Impossible de d√©terminer les ports ouverts")
    log "INFO" "Ports ouverts sur le VPS:"
    echo "${open_ports}"

    # V√©rification des conflits potentiels
    for port in "${REQUIRED_PORTS[@]}"; do
        if echo "${open_ports}" | grep -q ":${port} "; then
            log "WARNING" "Le port ${port} est d√©j√† utilis√© sur le VPS, ce qui peut causer des conflits"
        fi
    done

    log "SUCCESS" "V√©rification des ressources syst√®me du VPS termin√©e"
    return 0
}

# Fonction pour v√©rifier l'espace disque disponible (pour compatibilit√©)
function check_disk_space() {
    check_local_resources
    return $?
}

# Fonction pour extraire les informations d'inventaire
function extraire_informations_inventaire() {
    log "INFO" "Extraction des informations d'inventaire depuis ${inventory_file}..."

    # V√©rification de l'existence du fichier d'inventaire
    if [[ ! -f "${ANSIBLE_DIR}/${inventory_file}" ]]; then
        log "ERROR" "Fichier d'inventaire non trouv√©: ${ANSIBLE_DIR}/${inventory_file}"
        cleanup
        exit 1
    fi

    # Extraction des informations d'inventaire avec Python
    local python_script=$(cat << 'EOF'
import sys
import yaml
import os

inventory_file = sys.argv[1]

try:
    with open(inventory_file, 'r') as f:
        inventory = yaml.safe_load(f)

    # Recherche du premier h√¥te VPS
    vps_host = None
    vps_port = None
    vps_user = None

    if 'all' in inventory and 'children' in inventory['all'] and 'vps' in inventory['all']['children']:
        vps_hosts = inventory['all']['children']['vps'].get('hosts', {})
        if vps_hosts:
            first_host = next(iter(vps_hosts))
            host_info = vps_hosts[first_host]
            vps_host = host_info.get('ansible_host')
            vps_port = host_info.get('ansible_port', 22)
            vps_user = host_info.get('ansible_user')

    # Recherche dans les variables globales si non trouv√©
    if not vps_user and 'all' in inventory and 'vars' in inventory['all']:
        vps_user = inventory['all']['vars'].get('ansible_user')

    # Affichage des r√©sultats
    if vps_host:
        print(f"ansible_host={vps_host}")
    if vps_port:
        print(f"ansible_port={vps_port}")
    if vps_user:
        print(f"ansible_user={vps_user}")

except Exception as e:
    print(f"error={str(e)}", file=sys.stderr)
    sys.exit(1)
EOF
)

    # Ex√©cution du script Python avec timeout
    log "DEBUG" "Ex√©cution du script Python pour extraire les informations d'inventaire..."

    # V√©rification que Python3 est install√©
    if ! command_exists python3; then
        log "ERROR" "Python3 n'est pas install√©, impossible d'extraire les informations d'inventaire"
        log "ERROR" "Installez Python3 avec: sudo apt-get install python3 (Debian/Ubuntu)"
        log "ERROR" "ou l'√©quivalent pour votre distribution"

        # Passage directement √† la m√©thode fallback
        log "WARNING" "Tentative de fallback avec grep pour extraire les informations d'inventaire..."

        # Utilisation de grep avec timeout pour √©viter les blocages
        ansible_host=$(timeout 5 grep -A10 "hosts:" "${ANSIBLE_DIR}/${inventory_file}" | grep "ansible_host:" | head -1 | awk -F': ' '{print $2}' | tr -d ' ' 2>/dev/null || echo "")
        ansible_port=$(timeout 5 grep -A10 "hosts:" "${ANSIBLE_DIR}/${inventory_file}" | grep "ansible_port:" | head -1 | awk -F': ' '{print $2}' | tr -d ' ' 2>/dev/null || echo "22")
        ansible_user=$(timeout 5 grep -A10 "hosts:" "${ANSIBLE_DIR}/${inventory_file}" | grep "ansible_user:" | head -1 | awk -F': ' '{print $2}' | tr -d ' ' 2>/dev/null || echo "")

        # Si toujours pas trouv√©, chercher dans les variables globales
        if [[ -z "${ansible_user}" ]]; then
            ansible_user=$(timeout 5 grep -A10 "vars:" "${ANSIBLE_DIR}/${inventory_file}" | grep "ansible_user:" | head -1 | awk -F': ' '{print $2}' | tr -d ' ' 2>/dev/null || echo "")
        fi

        # V√©rification des valeurs extraites par fallback
        if [[ -n "${ansible_host}" && -n "${ansible_user}" ]]; then
            log "SUCCESS" "Extraction des informations d'inventaire r√©ussie avec la m√©thode fallback"
            log "INFO" "Informations d'inventaire extraites (fallback):"
            log "INFO" "- H√¥te: ${ansible_host}"
            log "INFO" "- Port: ${ansible_port}"
            log "INFO" "- Utilisateur: ${ansible_user}"
            return 0
        else
            log "ERROR" "√âchec de l'extraction des informations d'inventaire, m√™me avec la m√©thode fallback"
            cleanup
            exit 1
        fi
    fi

    # Affichage du contenu du fichier d'inventaire en mode debug
    if [[ "${debug_mode}" == "true" ]]; then
        log "DEBUG" "Contenu du fichier d'inventaire (${ANSIBLE_DIR}/${inventory_file}):"
        cat "${ANSIBLE_DIR}/${inventory_file}" | while IFS= read -r line; do
            log "DEBUG" "  ${line}"
        done
    fi

    # Ex√©cution avec timeout pour √©viter les blocages
    local inventory_info=$(timeout 10 python3 -c "${python_script}" "${ANSIBLE_DIR}/${inventory_file}" 2>&1)
    local exit_code=$?

    if [[ ${exit_code} -eq 124 ]]; then
        log "ERROR" "Timeout lors de l'extraction des informations d'inventaire"
        log "ERROR" "Le script Python a pris trop de temps pour s'ex√©cuter"
        log "ERROR" "V√©rifiez le fichier d'inventaire et les d√©pendances Python"
        cleanup
        exit 1
    elif [[ ${exit_code} -ne 0 ]]; then
        log "ERROR" "Impossible d'extraire les informations d'inventaire (code ${exit_code})"
        log "ERROR" "Erreur: ${inventory_info}"
        log "ERROR" "V√©rifiez le format du fichier d'inventaire et les d√©pendances Python (yaml)"

        # V√©rification de la pr√©sence du module yaml
        if ! python3 -c "import yaml" &>/dev/null; then
            log "WARNING" "Le module Python 'yaml' n'est pas install√©"
            log "INFO" "Tentative d'installation automatique du module yaml..."

            # V√©rification de pip
            if ! command_exists pip3 && ! command_exists pip; then
                log "ERROR" "pip n'est pas install√©, impossible d'installer le module yaml"
                log "ERROR" "Installez pip avec: sudo apt-get install python3-pip (Debian/Ubuntu)"
                log "ERROR" "ou l'√©quivalent pour votre distribution"
            else
                # Installation du module yaml
                local pip_cmd="pip3"
                if ! command_exists pip3; then
                    pip_cmd="pip"
                fi

                if sudo ${pip_cmd} install pyyaml &>/dev/null; then
                    log "SUCCESS" "Module yaml install√© avec succ√®s"
                    # R√©essayer l'extraction apr√®s l'installation
                    inventory_info=$(timeout 10 python3 -c "${python_script}" "${ANSIBLE_DIR}/${inventory_file}" 2>&1)
                    exit_code=$?

                    if [[ ${exit_code} -eq 0 ]]; then
                        log "SUCCESS" "Extraction des informations d'inventaire r√©ussie apr√®s installation du module yaml"
                    else
                        log "ERROR" "√âchec de l'extraction des informations d'inventaire m√™me apr√®s installation du module yaml"
                    fi
                else
                    log "ERROR" "√âchec de l'installation du module yaml"
                    log "ERROR" "Installez-le manuellement avec: sudo pip3 install pyyaml"
                fi
            fi
        fi

        # Tentative de fallback avec grep si le script Python √©choue
        log "WARNING" "Tentative de fallback avec grep pour extraire les informations d'inventaire..."

        # Utilisation de grep avec timeout pour √©viter les blocages
        ansible_host=$(timeout 5 grep -A10 "hosts:" "${ANSIBLE_DIR}/${inventory_file}" | grep "ansible_host:" | head -1 | awk -F': ' '{print $2}' | tr -d ' ' 2>/dev/null || echo "")
        ansible_port=$(timeout 5 grep -A10 "hosts:" "${ANSIBLE_DIR}/${inventory_file}" | grep "ansible_port:" | head -1 | awk -F': ' '{print $2}' | tr -d ' ' 2>/dev/null || echo "22")
        ansible_user=$(timeout 5 grep -A10 "hosts:" "${ANSIBLE_DIR}/${inventory_file}" | grep "ansible_user:" | head -1 | awk -F': ' '{print $2}' | tr -d ' ' 2>/dev/null || echo "")

        # Si toujours pas trouv√©, chercher dans les variables globales
        if [[ -z "${ansible_user}" ]]; then
            ansible_user=$(timeout 5 grep -A10 "vars:" "${ANSIBLE_DIR}/${inventory_file}" | grep "ansible_user:" | head -1 | awk -F': ' '{print $2}' | tr -d ' ' 2>/dev/null || echo "")
        fi

        # V√©rification des valeurs extraites par fallback
        if [[ -n "${ansible_host}" && -n "${ansible_user}" ]]; then
            log "SUCCESS" "Extraction des informations d'inventaire r√©ussie avec la m√©thode fallback"
            log "INFO" "Informations d'inventaire extraites (fallback):"
            log "INFO" "- H√¥te: ${ansible_host}"
            log "INFO" "- Port: ${ansible_port}"
            log "INFO" "- Utilisateur: ${ansible_user}"
            return 0
        else
            log "ERROR" "√âchec de l'extraction des informations d'inventaire, m√™me avec la m√©thode fallback"
            cleanup
            exit 1
        fi
    fi

    # Extraction des valeurs
    ansible_host=$(echo "${inventory_info}" | grep "ansible_host=" | cut -d'=' -f2)
    ansible_port=$(echo "${inventory_info}" | grep "ansible_port=" | cut -d'=' -f2)
    ansible_user=$(echo "${inventory_info}" | grep "ansible_user=" | cut -d'=' -f2)

    # Valeurs par d√©faut si non trouv√©es
    ansible_host="${ansible_host:-localhost}"
    ansible_port="${ansible_port:-22}"
    ansible_user="${ansible_user:-$(whoami)}"

    log "INFO" "Informations d'inventaire extraites:"
    log "INFO" "- H√¥te: ${ansible_host}"
    log "INFO" "- Port: ${ansible_port}"
    log "INFO" "- Utilisateur: ${ansible_user}"

    return 0
}

# Fonction pour ouvrir les ports requis sur le VPS
function open_required_ports() {
    local target_host="${ansible_host}"
    local target_port="${ansible_port}"
    local ports_to_open=("$@")
    local timeout=10
    local success=true

    log "INFO" "Tentative d'ouverture des ports requis sur ${target_host}..."

    # V√©rification que nous avons des ports √† ouvrir
    if [[ ${#ports_to_open[@]} -eq 0 ]]; then
        log "WARNING" "Aucun port √† ouvrir sp√©cifi√©"
        return 0
    fi

    # V√©rification de la connexion SSH
    if ! ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${target_port}" "${ansible_user}@${target_host}" "echo 'Test de connexion'" &>/dev/null; then
        log "ERROR" "Impossible de se connecter au VPS via SSH pour ouvrir les ports"
        return 1
    fi

    # V√©rification que UFW est install√© et actif
    if ! ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${target_port}" "${ansible_user}@${target_host}" "command -v ufw &>/dev/null && systemctl is-active --quiet ufw" &>/dev/null; then
        log "WARNING" "UFW n'est pas install√© ou n'est pas actif sur le VPS"
        log "INFO" "Tentative d'installation et d'activation de UFW..."

        # Installation de UFW si n√©cessaire
        if ! ssh -o BatchMode=yes -o ConnectTimeout=${timeout} -p "${target_port}" "${ansible_user}@${target_host}" "sudo apt-get update && sudo apt-get install -y ufw" &>/dev/null; then
            log "ERROR" "Impossible d'installer UFW sur le VPS"
            return 1
        fi

        # Activation de UFW
        if ! ssh -o BatchMode=yes -o ConnectTimeout=${timeout} -p "${target_port}" "${ansible_user}@${target_host}" "sudo ufw --force enable" &>/dev/null; then
            log "ERROR" "Impossible d'activer UFW sur le VPS"
            return 1
        fi

        log "SUCCESS" "UFW install√© et activ√© avec succ√®s"
    fi

    # Ouverture des ports
    log "INFO" "Ouverture des ports: ${ports_to_open[*]}"

    for port in "${ports_to_open[@]}"; do
        log "INFO" "Ouverture du port ${port}..."

        # V√©rification si le port est d√©j√† ouvert
        if ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${target_port}" "${ansible_user}@${target_host}" "sudo ufw status | grep -E \"^${port}/(tcp|udp)\"" &>/dev/null; then
            log "INFO" "Le port ${port} est d√©j√† ouvert dans UFW"
            continue
        fi

        # Ouverture du port TCP
        if ! ssh -o BatchMode=yes -o ConnectTimeout=${timeout} -p "${target_port}" "${ansible_user}@${target_host}" "sudo ufw allow ${port}/tcp" &>/dev/null; then
            log "ERROR" "Impossible d'ouvrir le port ${port}/tcp sur le VPS"
            success=false
            continue
        fi

        # Ouverture du port UDP
        if ! ssh -o BatchMode=yes -o ConnectTimeout=${timeout} -p "${target_port}" "${ansible_user}@${target_host}" "sudo ufw allow ${port}/udp" &>/dev/null; then
            log "WARNING" "Impossible d'ouvrir le port ${port}/udp sur le VPS"
            # Ne pas √©chouer pour UDP, car certains services n'utilisent que TCP
        fi

        log "SUCCESS" "Port ${port} ouvert avec succ√®s"
    done

    # Rechargement des r√®gles UFW
    if ! ssh -o BatchMode=yes -o ConnectTimeout=${timeout} -p "${target_port}" "${ansible_user}@${target_host}" "sudo ufw reload" &>/dev/null; then
        log "WARNING" "Impossible de recharger les r√®gles UFW"
        # Ne pas √©chouer pour le rechargement, car les r√®gles sont d√©j√† appliqu√©es
    fi

    # V√©rification que les ports sont bien ouverts
    log "INFO" "V√©rification que les ports sont bien ouverts..."
    local failed_ports=()

    for port in "${ports_to_open[@]}"; do
        if ! ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${target_port}" "${ansible_user}@${target_host}" "sudo ufw status | grep -E \"^${port}/(tcp|udp)\"" &>/dev/null; then
            log "WARNING" "Le port ${port} ne semble pas √™tre correctement ouvert dans UFW"
            failed_ports+=("${port}")
            success=false
        fi
    done

    if [[ ${#failed_ports[@]} -gt 0 ]]; then
        log "WARNING" "Les ports suivants n'ont pas pu √™tre ouverts: ${failed_ports[*]}"
    fi

    # Affichage du statut UFW
    local ufw_status=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${target_port}" "${ansible_user}@${target_host}" "sudo ufw status" 2>/dev/null || echo "Impossible de r√©cup√©rer le statut UFW")
    log "INFO" "Statut UFW actuel:"
    echo "${ufw_status}"

    if [[ "${success}" == "true" ]]; then
        log "SUCCESS" "Tous les ports ont √©t√© ouverts avec succ√®s"
        return 0
    else
        log "WARNING" "Certains ports n'ont pas pu √™tre ouverts"
        return 1
    fi
}

# Fonction pour v√©rifier la connectivit√© r√©seau de mani√®re approfondie
function check_network() {
    local target_host="${ansible_host}"
    local target_port="${ansible_port}"
    local retry_count=3
    local timeout=5
    local success=false

    log "INFO" "V√©rification approfondie de la connectivit√© r√©seau vers ${target_host}..."

    if [[ -z "${target_host}" ]]; then
        log "ERROR" "Impossible de d√©terminer l'adresse du VPS"
        return 1
    fi

    # V√©rification de la r√©solution DNS
    log "INFO" "V√©rification de la r√©solution DNS pour ${target_host}..."
    if [[ "${target_host}" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
        log "INFO" "L'adresse ${target_host} est une adresse IP, pas besoin de r√©solution DNS"
    else
        # Tentative de r√©solution DNS
        local resolved_ip=""
        for ((i=1; i<=retry_count; i++)); do
            resolved_ip=$(dig +short "${target_host}" 2>/dev/null || host "${target_host}" 2>/dev/null | grep "has address" | awk '{print $4}' || nslookup "${target_host}" 2>/dev/null | grep "Address:" | tail -n1 | awk '{print $2}')

            if [[ -n "${resolved_ip}" ]]; then
                log "INFO" "R√©solution DNS r√©ussie: ${target_host} -> ${resolved_ip}"
                success=true
                break
            else
                log "WARNING" "Tentative ${i}/${retry_count}: √âchec de la r√©solution DNS pour ${target_host}"
                sleep 2
            fi
        done

        if [[ "${success}" != "true" ]]; then
            log "ERROR" "Impossible de r√©soudre l'adresse DNS pour ${target_host}"
            log "ERROR" "V√©rifiez votre connexion Internet et la configuration DNS"

            # V√©rification des serveurs DNS
            log "INFO" "V√©rification des serveurs DNS..."
            local dns_servers=$(cat /etc/resolv.conf | grep "nameserver" | awk '{print $2}')

            if [[ -z "${dns_servers}" ]]; then
                log "ERROR" "Aucun serveur DNS configur√©"
            else
                log "INFO" "Serveurs DNS configur√©s: ${dns_servers}"

                # Test de connectivit√© vers les serveurs DNS
                for dns in ${dns_servers}; do
                    if ping -c 1 -W 5 "${dns}" &>/dev/null; then
                        log "INFO" "Serveur DNS ${dns} accessible"
                    else
                        log "WARNING" "Serveur DNS ${dns} inaccessible"
                    fi
                done
            fi

            # Suggestion de solution
            log "INFO" "Suggestions:"
            log "INFO" "1. V√©rifiez votre connexion Internet"
            log "INFO" "2. V√©rifiez que le nom d'h√¥te ${target_host} est correct"
            log "INFO" "3. Essayez d'utiliser une adresse IP directement dans le fichier d'inventaire"

            return 1
        fi
    fi

    # V√©rification de la connectivit√© ICMP (ping)
    log "INFO" "V√©rification de la connectivit√© ICMP vers ${target_host}..."
    success=false

    for ((i=1; i<=retry_count; i++)); do
        if ping -c 3 -W ${timeout} "${target_host}" &>/dev/null; then
            log "INFO" "Connectivit√© ICMP vers ${target_host} v√©rifi√©e avec succ√®s"
            success=true
            break
        else
            log "WARNING" "Tentative ${i}/${retry_count}: √âchec de la connectivit√© ICMP vers ${target_host}"
            sleep 2
        fi
    done

    if [[ "${success}" != "true" ]]; then
        log "WARNING" "Impossible de joindre le VPS par ICMP (ping) √† l'adresse ${target_host}"
        log "WARNING" "Le pare-feu du VPS bloque peut-√™tre les pings, tentative de connexion TCP..."
    fi

    # V√©rification de la connectivit√© TCP (SSH)
    log "INFO" "V√©rification de la connectivit√© TCP (SSH) vers ${target_host}:${target_port}..."
    success=false

    for ((i=1; i<=retry_count; i++)); do
        if nc -z -w ${timeout} "${target_host}" "${target_port}" &>/dev/null; then
            log "INFO" "Connectivit√© TCP (SSH) vers ${target_host}:${target_port} v√©rifi√©e avec succ√®s"
            success=true
            break
        else
            log "WARNING" "Tentative ${i}/${retry_count}: √âchec de la connectivit√© TCP vers ${target_host}:${target_port}"
            sleep 2
        fi
    done

    if [[ "${success}" != "true" ]]; then
        log "ERROR" "Impossible de joindre le VPS par TCP (SSH) √† l'adresse ${target_host}:${target_port}"
        log "ERROR" "V√©rifiez que le VPS est en ligne et que le port SSH est ouvert"

        # V√©rification de la route r√©seau
        log "INFO" "V√©rification de la route r√©seau vers ${target_host}..."
        local traceroute_output=$(traceroute -m 15 "${target_host}" 2>/dev/null || tracepath -m 15 "${target_host}" 2>/dev/null || true)

        if [[ -n "${traceroute_output}" ]]; then
            log "INFO" "Route r√©seau vers ${target_host}:"
            echo "${traceroute_output}" | head -10
        else
            log "WARNING" "Impossible de d√©terminer la route r√©seau vers ${target_host}"
        fi

        # Suggestion de solution
        log "INFO" "Suggestions:"
        log "INFO" "1. V√©rifiez que le VPS est en ligne"
        log "INFO" "2. V√©rifiez que le port SSH (${target_port}) est ouvert sur le VPS"
        log "INFO" "3. V√©rifiez les r√®gles de pare-feu sur le VPS et sur votre r√©seau local"

        return 1
    fi

    # V√©rification des ports requis
    log "INFO" "V√©rification des ports requis sur ${target_host}..."
    local open_ports=()
    local closed_ports=()

    for port in "${REQUIRED_PORTS[@]}"; do
        if nc -z -w ${timeout} "${target_host}" "${port}" &>/dev/null; then
            log "INFO" "Port ${port} accessible sur ${target_host}"
            open_ports+=("${port}")
        else
            log "WARNING" "Port ${port} non accessible sur ${target_host}"
            closed_ports+=("${port}")
        fi
    done

    # R√©sum√© des ports
    if [[ ${#open_ports[@]} -eq ${#REQUIRED_PORTS[@]} ]]; then
        log "SUCCESS" "Tous les ports requis sont accessibles sur ${target_host}"
    else
        log "WARNING" "Certains ports requis ne sont pas accessibles sur ${target_host}"
        log "INFO" "Ports ouverts: ${open_ports[*]}"
        log "WARNING" "Ports ferm√©s: ${closed_ports[*]}"

        # Demande √† l'utilisateur s'il souhaite ouvrir les ports automatiquement
        log "INFO" "Des ports requis sont ferm√©s. Souhaitez-vous les ouvrir automatiquement? (o/N)"
        read -r answer

        if [[ "${answer}" =~ ^[Oo]$ ]]; then
            # Tentative d'ouverture des ports ferm√©s
            log "INFO" "Tentative d'ouverture automatique des ports ferm√©s..."
            if open_required_ports "${closed_ports[@]}"; then
                log "SUCCESS" "Ports ouverts avec succ√®s"

                # V√©rification que les ports sont maintenant accessibles
                local still_closed_ports=()
                for port in "${closed_ports[@]}"; do
                    if ! nc -z -w ${timeout} "${target_host}" "${port}" &>/dev/null; then
                        still_closed_ports+=("${port}")
                    else
                        open_ports+=("${port}")
                    fi
                done

                if [[ ${#still_closed_ports[@]} -eq 0 ]]; then
                    log "SUCCESS" "Tous les ports sont maintenant accessibles"
                    closed_ports=()
                else
                    log "WARNING" "Certains ports sont toujours inaccessibles malgr√© l'ouverture dans le pare-feu"
                    log "WARNING" "Cela peut √™tre d√ª √† un pare-feu externe ou √† des services non d√©marr√©s"
                    closed_ports=("${still_closed_ports[@]}")
                    log "INFO" "Ports toujours ferm√©s: ${closed_ports[*]}"
                fi
            else
                log "WARNING" "Impossible d'ouvrir automatiquement certains ports"
                log "WARNING" "Vous devrez peut-√™tre les ouvrir manuellement"
            fi
        else
            log "INFO" "Ouverture automatique des ports annul√©e par l'utilisateur"
        fi

        # V√©rification si le port SSH est ouvert (seul port vraiment essentiel)
        if ! nc -z -w ${timeout} "${target_host}" "${target_port}" &>/dev/null; then
            log "ERROR" "Le port SSH (${target_port}) n'est pas accessible, impossible de continuer"
            log "INFO" "Suggestions:"
            log "INFO" "1. V√©rifiez les r√®gles de pare-feu sur le VPS"
            log "INFO" "2. V√©rifiez que le service SSH est en cours d'ex√©cution sur le VPS"
            return 1
        else
            log "WARNING" "Certains ports non essentiels ne sont pas accessibles, l'installation peut continuer mais certaines fonctionnalit√©s pourraient ne pas fonctionner correctement"
            # Continuer automatiquement si seuls des ports non essentiels sont inaccessibles
            log "INFO" "Continuation automatique de l'installation..."
        fi
    fi

    # V√©rification de la latence r√©seau
    log "INFO" "V√©rification de la latence r√©seau vers ${target_host}..."
    local ping_output=$(ping -c 5 -W ${timeout} "${target_host}" 2>/dev/null || echo "Ping failed")
    local avg_latency=$(echo "${ping_output}" | grep "avg" | awk -F'/' '{print $5}')

    if [[ -n "${avg_latency}" ]]; then
        log "INFO" "Latence moyenne vers ${target_host}: ${avg_latency} ms"

        if (( $(echo "${avg_latency} > 300" | bc -l) )); then
            log "WARNING" "Latence √©lev√©e vers ${target_host}, les performances peuvent √™tre d√©grad√©es"
        fi
    else
        log "WARNING" "Impossible de mesurer la latence vers ${target_host}"
    fi

    log "SUCCESS" "V√©rification de la connectivit√© r√©seau termin√©e avec succ√®s"
    return 0
}

# Fonction pour sauvegarder l'√©tat avant modification
function backup_state() {
    local backup_name="${1:-backup-$(date +%Y%m%d-%H%M%S)}"
    local optional="${2:-false}"  # New parameter to make backup optional
    local backup_file="${BACKUP_DIR}/${backup_name}.tar.gz"
    local metadata_file="${BACKUP_DIR}/${backup_name}.json"

    log "INFO" "Sauvegarde de l'√©tat actuel dans ${backup_file}..."

    # Cr√©ation du fichier de m√©tadonn√©es
    cat > "${metadata_file}" << EOF
{
  "backup_name": "${backup_name}",
  "backup_date": "$(date -Iseconds)",
  "environment": "${environment}",
  "installation_step": "${INSTALLATION_STEP}",
  "ansible_host": "${ansible_host}",
  "ansible_port": "${ansible_port}",
  "ansible_user": "${ansible_user}",
  "script_version": "1.0.0",
  "description": "Sauvegarde automatique avant l'√©tape ${INSTALLATION_STEP}"
}
EOF

    # Liste des r√©pertoires √† sauvegarder
    local backup_dirs=(
        "/etc/rancher"
        "/var/lib/rancher/k3s/server/manifests"
        "/home/${ansible_user}/.kube"
        "/etc/systemd/system/k3s.service"
        "/var/log/lions"
    )

    # Liste des fichiers √† exclure
    local exclude_patterns=(
        "*.log"
        "*.tmp"
        "*.bak"
        "*.old"
        "*.swp"
    )

    # Construction de la commande d'exclusion
    local exclude_args=""
    for pattern in "${exclude_patterns[@]}"; do
        exclude_args="${exclude_args} --exclude='${pattern}'"
    done

    # V√©rification de l'existence des r√©pertoires avant la sauvegarde
    local existing_dirs=()
    for dir in "${backup_dirs[@]}"; do
        if ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "[ -d \"${dir}\" ]" &>/dev/null; then
            existing_dirs+=("${dir}")
            log "DEBUG" "R√©pertoire trouv√© pour sauvegarde: ${dir}"
        else
            log "DEBUG" "R√©pertoire non trouv√©, ignor√© pour la sauvegarde: ${dir}"
        fi
    done

    # Si aucun r√©pertoire n'existe, log un avertissement et retourne 0 si optionnel
    if [[ ${#existing_dirs[@]} -eq 0 ]]; then
        log "WARNING" "Aucun r√©pertoire √† sauvegarder n'existe encore sur le VPS"
        if [[ "${optional}" == "true" ]]; then
            log "INFO" "Sauvegarde ignor√©e (optionnelle)"
            rm -f "${metadata_file}"
            return 0
        else
            log "WARNING" "Impossible de cr√©er une sauvegarde de l'√©tat actuel sur le VPS"
            rm -f "${metadata_file}"
            return 1
        fi
    fi

    # Construction de la commande de sauvegarde avec les r√©pertoires existants
    local backup_cmd="sudo tar -czf /tmp/${backup_name}.tar.gz ${exclude_args}"
    for dir in "${existing_dirs[@]}"; do
        backup_cmd="${backup_cmd} ${dir}"
    done
    backup_cmd="${backup_cmd} 2>/dev/null || true"

    # Ex√©cution de la commande de sauvegarde
    if ssh -o BatchMode=yes -o ConnectTimeout=10 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "${backup_cmd}"; then
        # R√©cup√©ration du fichier de sauvegarde
        if scp -P "${ansible_port}" "${ansible_user}@${ansible_host}:/tmp/${backup_name}.tar.gz" "${backup_file}" &>/dev/null; then
            # Nettoyage du fichier temporaire sur le VPS
            ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "rm -f /tmp/${backup_name}.tar.gz"

            # V√©rification de la taille du fichier de sauvegarde
            local backup_size=$(du -h "${backup_file}" | awk '{print $1}')

            # Ajout de la taille du fichier aux m√©tadonn√©es
            local tmp_file=$(mktemp)
            jq ".backup_size = \"${backup_size}\"" "${metadata_file}" > "${tmp_file}" && mv "${tmp_file}" "${metadata_file}"

            log "SUCCESS" "Sauvegarde de l'√©tat cr√©√©e: ${backup_file} (${backup_size})"

            # Nettoyage des anciennes sauvegardes (garder les 5 plus r√©centes)
            local old_backups=($(ls -t "${BACKUP_DIR}"/*.tar.gz 2>/dev/null | tail -n +6))
            if [[ ${#old_backups[@]} -gt 0 ]]; then
                log "INFO" "Nettoyage des anciennes sauvegardes..."
                for old_backup in "${old_backups[@]}"; do
                    local old_name=$(basename "${old_backup}" .tar.gz)
                    rm -f "${old_backup}" "${BACKUP_DIR}/${old_name}.json"
                    log "INFO" "Sauvegarde supprim√©e: ${old_backup}"
                done
            fi

            # Enregistrement du nom de la derni√®re sauvegarde
            echo "${backup_name}" > "${BACKUP_DIR}/.last_backup"

            return 0
        else
            log "WARNING" "Impossible de r√©cup√©rer le fichier de sauvegarde depuis le VPS"
            rm -f "${metadata_file}"
            if [[ "${optional}" == "true" ]]; then
                log "INFO" "Continuation de l'installation malgr√© l'√©chec de la sauvegarde (optionnelle)"
                return 0
            else
                return 1
            fi
        fi
    else
        log "WARNING" "Impossible de cr√©er une sauvegarde de l'√©tat actuel sur le VPS"
        rm -f "${metadata_file}"
        if [[ "${optional}" == "true" ]]; then
            log "INFO" "Continuation de l'installation malgr√© l'√©chec de la sauvegarde (optionnelle)"
            return 0
        else
            return 1
        fi
    fi
}

# Fonction pour restaurer l'√©tat √† partir d'une sauvegarde
function restore_state() {
    local backup_name="$1"

    # Si aucun nom de sauvegarde n'est fourni, utiliser la derni√®re sauvegarde
    if [[ -z "${backup_name}" && -f "${BACKUP_DIR}/.last_backup" ]]; then
        backup_name=$(cat "${BACKUP_DIR}/.last_backup")
    fi

    # V√©rification de l'existence de la sauvegarde
    if [[ -z "${backup_name}" || ! -f "${BACKUP_DIR}/${backup_name}.tar.gz" ]]; then
        log "ERROR" "Sauvegarde non trouv√©e: ${backup_name}"
        return 1
    fi

    local backup_file="${BACKUP_DIR}/${backup_name}.tar.gz"
    local metadata_file="${BACKUP_DIR}/${backup_name}.json"

    log "INFO" "Restauration de l'√©tat √† partir de ${backup_file}..."

    # Lecture des m√©tadonn√©es
    if [[ -f "${metadata_file}" ]]; then
        local backup_date=$(jq -r '.backup_date' "${metadata_file}")
        local backup_step=$(jq -r '.installation_step' "${metadata_file}")
        local backup_env=$(jq -r '.environment' "${metadata_file}")

        log "INFO" "Sauvegarde du ${backup_date}, √©tape: ${backup_step}, environnement: ${backup_env}"

        # V√©rification de la compatibilit√© de l'environnement
        if [[ "${backup_env}" != "${environment}" ]]; then
            log "WARNING" "L'environnement de la sauvegarde (${backup_env}) ne correspond pas √† l'environnement actuel (${environment})"
            log "INFO" "Voulez-vous continuer malgr√© tout? (o/N)"
            read -r answer
            if [[ ! "${answer}" =~ ^[Oo]$ ]]; then
                return 1
            fi
        fi
    else
        log "WARNING" "Fichier de m√©tadonn√©es non trouv√©: ${metadata_file}"
        log "INFO" "Voulez-vous continuer malgr√© tout? (o/N)"
        read -r answer
        if [[ ! "${answer}" =~ ^[Oo]$ ]]; then
            return 1
        fi
    fi

    # Copie du fichier de sauvegarde vers le VPS
    log "INFO" "Copie du fichier de sauvegarde vers le VPS..."
    if ! scp -P "${ansible_port}" "${backup_file}" "${ansible_user}@${ansible_host}:/tmp/${backup_name}.tar.gz" &>/dev/null; then
        log "ERROR" "Impossible de copier le fichier de sauvegarde vers le VPS"
        return 1
    fi

    # Arr√™t des services avant restauration
    log "INFO" "Arr√™t des services avant restauration..."
    ssh -o BatchMode=yes -o ConnectTimeout=10 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "sudo systemctl stop k3s || true" &>/dev/null

    # Restauration des fichiers
    log "INFO" "Restauration des fichiers..."
    if ! ssh -o BatchMode=yes -o ConnectTimeout=30 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "sudo tar -xzf /tmp/${backup_name}.tar.gz -C / 2>/dev/null"; then
        log "ERROR" "√âchec de la restauration des fichiers"

        # Red√©marrage des services en cas d'√©chec
        ssh -o BatchMode=yes -o ConnectTimeout=10 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "sudo systemctl start k3s || true" &>/dev/null

        return 1
    fi

    # Nettoyage du fichier temporaire
    ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "rm -f /tmp/${backup_name}.tar.gz" &>/dev/null

    # Red√©marrage des services
    log "INFO" "Red√©marrage des services..."
    if ! ssh -o BatchMode=yes -o ConnectTimeout=30 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "sudo systemctl daemon-reload && sudo systemctl start k3s"; then
        log "WARNING" "√âchec du red√©marrage des services"
        log "WARNING" "Vous devrez peut-√™tre red√©marrer manuellement le VPS"
        return 1
    fi

    # Attente que K3s soit pr√™t
    log "INFO" "Attente que K3s soit pr√™t..."
    local timeout=60
    local start_time=$(date +%s)
    local k3s_ready=false

    while [[ "${k3s_ready}" == "false" ]]; do
        local current_time=$(date +%s)
        local elapsed_time=$((current_time - start_time))

        if [[ ${elapsed_time} -gt ${timeout} ]]; then
            log "WARNING" "Timeout atteint en attendant que K3s soit pr√™t"
            break
        fi

        if ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "kubectl get nodes" &>/dev/null; then
            k3s_ready=true
            log "SUCCESS" "K3s est pr√™t"
        else
            log "INFO" "En attente que K3s soit pr√™t... (${elapsed_time}s)"
            sleep 5
        fi
    done

    log "SUCCESS" "Restauration termin√©e avec succ√®s"

    # Mise √† jour de l'√©tat actuel
    if [[ -f "${metadata_file}" ]]; then
        local backup_step=$(jq -r '.installation_step' "${metadata_file}")
        INSTALLATION_STEP="${backup_step}"
        echo "${INSTALLATION_STEP}" > "${STATE_FILE}"
        log "INFO" "√âtat actuel mis √† jour: ${INSTALLATION_STEP}"
    fi

    return 0
}

# Fonction pour ex√©cuter une commande avec timeout
function run_with_timeout() {
    local cmd="$1"
    local timeout="${2:-${TIMEOUT_SECONDS}}"
    local cmd_type="${3:-generic}"
    local max_retries=3
    local retry_count=0
    local backoff_time=5
    local interactive=false

    # V√©rifier si la commande est interactive (n√©cessite une entr√©e utilisateur)
    if [[ "${cmd}" == *"--ask-become-pass"* || "${cmd}" == *"--ask-pass"* || "${cmd}" == *"-K"* || "${cmd}" == *"-k"* ]]; then
        interactive=true
        log "INFO" "Commande interactive d√©tect√©e, l'entr√©e utilisateur sera requise"
    fi

    log "INFO" "Ex√©cution de la commande avec timeout ${timeout}s: ${cmd}"
    LAST_COMMAND="${cmd}"

    # D√©finition du type de commande pour la gestion des erreurs
    COMMAND_NAME="${cmd_type}"

    # Sauvegarde de l'√©tat avant l'ex√©cution pour permettre une reprise
    echo "${INSTALLATION_STEP}" > "${STATE_FILE}"

    # Fonction pour v√©rifier si l'erreur est li√©e au r√©seau
    function is_network_error() {
        local output="$1"
        local exit_code="$2"

        # Codes d'erreur typiques des probl√®mes r√©seau
        if [[ ${exit_code} -eq 124 || ${exit_code} -eq 255 ]]; then
            return 0
        fi

        # Messages d'erreur typiques des probl√®mes r√©seau
        if echo "${output}" | grep -q -E "Connection refused|Connection timed out|Network is unreachable|Unable to connect|Connection reset by peer|Temporary failure in name resolution|Could not resolve host|Network error"; then
            return 0
        fi

        return 1
    }

    while true; do
        # V√©rification de la connectivit√© avant l'ex√©cution
        if [[ "${cmd_type}" == "ansible_playbook" || "${cmd_type}" == "ssh" ]]; then
            if ! ping -c 1 -W 5 "${ansible_host}" &>/dev/null; then
                if [[ ${retry_count} -lt ${max_retries} ]]; then
                    retry_count=$((retry_count + 1))
                    log "WARNING" "Connectivit√© r√©seau perdue avec le VPS (${ansible_host}). Tentative ${retry_count}/${max_retries} dans ${backoff_time} secondes..."
                    sleep ${backoff_time}
                    backoff_time=$((backoff_time * 2))  # Backoff exponentiel
                    continue
                else
                    log "ERROR" "Connectivit√© r√©seau perdue avec le VPS (${ansible_host})"
                    log "ERROR" "Impossible d'ex√©cuter la commande sans connectivit√© r√©seau apr√®s ${max_retries} tentatives"
                    return 1
                fi
            fi
        fi

        # Ex√©cution de la commande avec timeout
        log "DEBUG" "D√©but de l'ex√©cution de la commande..."

        local exit_code=0
        local command_output=""

        if [[ "${interactive}" == "true" ]]; then
            # Pour les commandes interactives, ex√©cuter sans redirection pour permettre l'entr√©e utilisateur
            log "INFO" "Ex√©cution de la commande interactive, veuillez r√©pondre aux invites si n√©cessaire..."
            timeout ${timeout} bash -c "${cmd}"
            exit_code=$?
        else
            # Pour les commandes non interactives, capturer la sortie
            local output_file=$(mktemp)
            timeout ${timeout} bash -c "${cmd}" > "${output_file}" 2>&1
            exit_code=$?
            command_output=$(cat "${output_file}")
            rm -f "${output_file}"
        fi

        # Journalisation de la sortie si en mode debug et si la commande n'√©tait pas interactive
        if [[ "${debug_mode}" == "true" && -n "${command_output}" ]]; then
            log "DEBUG" "Sortie de la commande:"
            echo "${command_output}" | while IFS= read -r line; do
                log "DEBUG" "  ${line}"
            done
        fi

        # V√©rification si l'erreur est li√©e au r√©seau et si on doit r√©essayer
        if [[ ${exit_code} -ne 0 ]]; then
            # Pour les commandes interactives, on ne peut pas analyser la sortie
            if [[ "${interactive}" == "true" ]]; then
                # Si c'est une erreur de timeout, on consid√®re que c'est une erreur r√©seau
                if [[ ${exit_code} -eq 124 || ${exit_code} -eq 255 ]]; then
                    if [[ ${retry_count} -lt ${max_retries} ]]; then
                        retry_count=$((retry_count + 1))
                        log "WARNING" "Erreur possible de r√©seau pour la commande interactive (code ${exit_code}). Tentative ${retry_count}/${max_retries} dans ${backoff_time} secondes..."
                        sleep ${backoff_time}
                        backoff_time=$((backoff_time * 2))  # Backoff exponentiel
                        continue
                    fi
                fi
            # Pour les commandes non interactives, on peut analyser la sortie
            elif is_network_error "${command_output}" ${exit_code}; then
                if [[ ${retry_count} -lt ${max_retries} ]]; then
                    retry_count=$((retry_count + 1))
                    log "WARNING" "Erreur r√©seau d√©tect√©e (code ${exit_code}). Tentative ${retry_count}/${max_retries} dans ${backoff_time} secondes..."
                    sleep ${backoff_time}
                    backoff_time=$((backoff_time * 2))  # Backoff exponentiel
                    continue
                fi
            fi
        fi

        # Analyse du code de retour
        if [[ ${exit_code} -eq 124 ]]; then
            log "ERROR" "La commande a d√©pass√© le d√©lai d'attente (${timeout}s)"

            # Tentative de diagnostic pour les timeouts
            case "${cmd_type}" in
                "ansible_playbook")
                    log "INFO" "V√©rification de la connectivit√© SSH..."
                    if ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "echo 'Test de connexion'" &>/dev/null; then
                        log "INFO" "La connexion SSH fonctionne, le probl√®me pourrait √™tre li√© √† Ansible ou √† une op√©ration longue"
                    else
                        log "ERROR" "La connexion SSH ne fonctionne pas, v√©rifiez les param√®tres de connexion"
                    fi
                    ;;
                "kubectl_apply")
                    log "INFO" "V√©rification de l'acc√®s √† l'API Kubernetes..."
                    if kubectl cluster-info &>/dev/null; then
                        log "INFO" "L'acc√®s √† l'API Kubernetes fonctionne, le probl√®me pourrait √™tre li√© √† une op√©ration longue"
                    else
                        log "ERROR" "L'acc√®s √† l'API Kubernetes ne fonctionne pas, v√©rifiez la configuration de kubectl"
                    fi
                    ;;
            esac

            return 1
        elif [[ ${exit_code} -ne 0 ]]; then
            log "ERROR" "La commande a √©chou√© avec le code ${exit_code}"

            # Analyse de la sortie pour des erreurs connues (seulement pour les commandes non interactives)
            if [[ "${interactive}" == "false" && -n "${command_output}" ]]; then
                if echo "${command_output}" | grep -q "Connection refused"; then
                    log "ERROR" "Connexion refus√©e - v√©rifiez que le service est en cours d'ex√©cution et accessible"
                elif echo "${command_output}" | grep -q "Permission denied"; then
                    log "ERROR" "Permission refus√©e - v√©rifiez les droits d'acc√®s"
                elif echo "${command_output}" | grep -q "No space left on device"; then
                    log "ERROR" "Plus d'espace disque disponible - lib√©rez de l'espace et r√©essayez"
                elif echo "${command_output}" | grep -q "Unable to connect to the server"; then
                    log "ERROR" "Impossible de se connecter au serveur Kubernetes - v√©rifiez que K3s est en cours d'ex√©cution"
                fi
            elif [[ "${interactive}" == "true" ]]; then
                log "INFO" "La commande interactive a √©chou√©. V√©rifiez les erreurs affich√©es ci-dessus."

                # Suggestions sp√©cifiques pour les commandes interactives
                if [[ "${cmd}" == *"ansible-playbook"* && "${cmd}" == *"--ask-become-pass"* ]]; then
                    log "INFO" "Suggestions pour les erreurs Ansible avec --ask-become-pass:"
                    log "INFO" "1. V√©rifiez que vous avez entr√© le bon mot de passe sudo"
                    log "INFO" "2. V√©rifiez que l'utilisateur a les droits sudo sur le VPS"
                    log "INFO" "3. V√©rifiez la configuration de sudoers sur le VPS"
                fi
            fi

            return ${exit_code}
        fi

        # Si on arrive ici, c'est que la commande a r√©ussi
        if [[ ${retry_count} -gt 0 ]]; then
            log "SUCCESS" "Commande ex√©cut√©e avec succ√®s apr√®s ${retry_count} tentatives"
        else
            if [[ "${interactive}" == "true" ]]; then
                log "SUCCESS" "Commande interactive ex√©cut√©e avec succ√®s"
            else
                log "DEBUG" "Commande ex√©cut√©e avec succ√®s"
            fi
        fi
        return 0
    done
}

# Fonction d'affichage de l'aide
function afficher_aide() {
    cat << EOF
Script d'Installation de l'Infrastructure LIONS sur VPS

Ce script orchestre l'installation compl√®te de l'infrastructure LIONS sur un VPS.

Usage:
    $0 [options]

Options:
    -e, --environment <env>   Environnement cible (production, staging, development)
                             Par d√©faut: development
    -i, --inventory <file>    Fichier d'inventaire Ansible sp√©cifique
                             Par d√©faut: inventories/development/hosts.yml
    -s, --skip-init           Ignorer l'initialisation du VPS (si d√©j√† effectu√©e)
    -d, --debug               Active le mode debug
    -h, --help                Affiche cette aide

Exemples:
    $0
    $0 --environment staging
    $0 --skip-init --debug
EOF
}

# Fonction de v√©rification des pr√©requis
function verifier_prerequis() {
    log "INFO" "V√©rification des pr√©requis..."
    INSTALLATION_STEP="prerequis"
    LAST_COMMAND="verifier_prerequis"
    COMMAND_NAME="verifier_prerequis"

    # V√©rification du verrouillage
    if [[ -f "${LOCK_FILE}" ]]; then
        log "WARNING" "Une autre instance du script semble √™tre en cours d'ex√©cution"

        # V√©rification de l'√¢ge du fichier de verrouillage
        local lock_file_age=$(( $(date +%s) - $(stat -c %Y "${LOCK_FILE}" 2>/dev/null || echo $(date +%s)) ))

        # V√©rification de l'uptime du syst√®me
        local uptime_seconds=$(cat /proc/uptime 2>/dev/null | awk '{print int($1)}' || echo 999999)

        # V√©rification des processus en cours d'ex√©cution
        local script_name=$(basename "$0")
        local script_count=$(ps aux | grep -v grep | grep -c "${script_name}" || echo 1)

        # Si le syst√®me a red√©marr√© apr√®s la cr√©ation du fichier de verrouillage
        # ou si le fichier de verrouillage existe depuis plus d'une heure
        # ou si aucun autre processus du script n'est en cours d'ex√©cution
        if [[ ${uptime_seconds} -lt ${lock_file_age} || ${lock_file_age} -gt 3600 || ${script_count} -le 1 ]]; then
            log "INFO" "Le syst√®me a red√©marr√© ou le fichier de verrouillage est obsol√®te (√¢ge: ${lock_file_age}s, uptime: ${uptime_seconds}s) ou aucune autre instance n'est en cours d'ex√©cution"
            log "INFO" "Suppression automatique du fichier de verrouillage obsol√®te"
            rm -f "${LOCK_FILE}"
        else
            log "WARNING" "Si ce n'est pas le cas, supprimez le fichier ${LOCK_FILE} et r√©essayez"
            log "INFO" "Commande pour supprimer le fichier de verrouillage: sudo rm -f ${LOCK_FILE}"
            exit 1
        fi
    fi

    # Cr√©ation du fichier de verrouillage
    touch "${LOCK_FILE}"

    # V√©rification de la version du syst√®me d'exploitation
    log "INFO" "V√©rification du syst√®me d'exploitation..."
    local os_name=$(uname -s)
    local os_version=$(uname -r)

    if [[ "${os_name}" != "Linux" && "${os_name}" != "Darwin" ]]; then
        log "WARNING" "Syst√®me d'exploitation non test√©: ${os_name} ${os_version}"
        log "WARNING" "Ce script est con√ßu pour fonctionner sur Linux ou macOS"
        log "INFO" "Voulez-vous continuer malgr√© tout? (o/N)"
        read -r answer
        if [[ ! "${answer}" =~ ^[Oo]$ ]]; then
            cleanup
            exit 1
        fi
    else
        log "INFO" "Syst√®me d'exploitation: ${os_name} ${os_version}"
    fi

    # V√©rification de l'espace disque
    if ! check_disk_space; then
        log "ERROR" "V√©rification de l'espace disque √©chou√©e"
        cleanup
        exit 1
    fi

    # V√©rification de la m√©moire disponible
    log "INFO" "V√©rification de la m√©moire disponible..."
    local available_memory=0
    if [[ "${os_name}" == "Linux" ]]; then
        available_memory=$(free -m | awk '/^Mem:/ {print $7}')
    elif [[ "${os_name}" == "Darwin" ]]; then
        available_memory=$(vm_stat | awk '/Pages free/ {free=$3} /Pages inactive/ {inactive=$3} END {print (free+inactive)*4096/1048576}' | cut -d. -f1)
    fi

    if [[ ${available_memory} -lt 1024 ]]; then
        log "WARNING" "M√©moire disponible limit√©e: ${available_memory}MB (recommand√©: 1024MB minimum)"
        log "WARNING" "Des probl√®mes de performance peuvent survenir pendant l'installation"
        log "INFO" "Voulez-vous continuer malgr√© tout? (o/N)"
        read -r answer
        if [[ ! "${answer}" =~ ^[Oo]$ ]]; then
            cleanup
            exit 1
        fi
    else
        log "INFO" "M√©moire disponible: ${available_memory}MB (minimum recommand√©: 1024MB)"
    fi

    # V√©rification des commandes requises avec versions minimales
    log "INFO" "V√©rification des commandes requises..."
    local required_commands=(
        "ansible-playbook:2.9.0"
        "ssh:7.0"
        "scp:7.0"
        "kubectl:1.20.0"
        "helm:3.5.0"
        "timeout:0"
        "nc:0"
        "ping:0"
        "jq:0"
    )
    local missing_commands=()
    local outdated_commands=()

    for cmd_with_version in "${required_commands[@]}"; do
        local cmd="${cmd_with_version%%:*}"
        local min_version="${cmd_with_version#*:}"

        if ! command_exists "${cmd}"; then
            missing_commands+=("${cmd}")
            continue
        fi

        # V√©rification des versions pour les commandes critiques
        if [[ "${min_version}" != "0" ]]; then
            local current_version=""
            case "${cmd}" in
                "ansible-playbook")
                    # Add timeout to prevent hanging and handle errors better
                    current_version=$(timeout 5 ansible-playbook --version 2>/dev/null | head -n1 | awk '{print $2}' | cut -d[ -f1 || echo "${min_version}")
                    ;;
                "kubectl")
                    # Add timeout to prevent hanging and handle errors better
                    current_version=$(timeout 5 kubectl version --client --short 2>/dev/null | awk '{print $3}' | sed 's/v//' || echo "${min_version}")
                    ;;
                "helm")
                    # Add timeout to prevent hanging and handle errors better
                    current_version=$(timeout 5 helm version --short 2>/dev/null | sed 's/v//' | cut -d+ -f1 || echo "${min_version}")
                    ;;
                *)
                    # Pour les autres commandes, on ne v√©rifie pas la version
                    current_version="${min_version}"
                    ;;
            esac

            if [[ -n "${current_version}" && "${current_version}" != "${min_version}" ]]; then
                if ! version_greater_equal "${current_version}" "${min_version}"; then
                    outdated_commands+=("${cmd} (actuelle: ${current_version}, requise: ${min_version})")
                fi
            fi
        fi
    done

    if [[ ${#missing_commands[@]} -gt 0 ]]; then
        log "WARNING" "Commandes requises non trouv√©es: ${missing_commands[*]}"
        log "INFO" "Tentative d'installation automatique des commandes manquantes..."

        if install_missing_commands "${missing_commands[@]}"; then
            log "SUCCESS" "Installation des commandes manquantes r√©ussie"
            # V√©rifier √† nouveau les commandes
            missing_commands=()
            for cmd_with_version in "${required_commands[@]}"; do
                local cmd="${cmd_with_version%%:*}"
                if ! command_exists "${cmd}"; then
                    missing_commands+=("${cmd}")
                fi
            done

            if [[ ${#missing_commands[@]} -gt 0 ]]; then
                log "ERROR" "Certaines commandes n'ont pas pu √™tre install√©es: ${missing_commands[*]}"
                log "ERROR" "Veuillez installer ces commandes manuellement avant de continuer"
                cleanup
                exit 1
            fi
        else
            log "ERROR" "√âchec de l'installation automatique des commandes manquantes"
            log "ERROR" "Veuillez installer ces commandes manuellement avant de continuer"
            cleanup
            exit 1
        fi
    fi

    if [[ ${#outdated_commands[@]} -gt 0 ]]; then
        log "WARNING" "Commandes avec versions obsol√®tes: ${outdated_commands[*]}"
        log "WARNING" "Il est recommand√© de mettre √† jour ces commandes avant de continuer"
        log "INFO" "Voulez-vous continuer malgr√© tout? (o/N)"
        read -r answer
        if [[ ! "${answer}" =~ ^[Oo]$ ]]; then
            cleanup
            exit 1
        fi
    fi

    # V√©rification des fichiers Ansible
    log "INFO" "V√©rification des fichiers Ansible..."
    if [[ ! -d "${ANSIBLE_DIR}/inventories/${environment}" ]]; then
        log "ERROR" "Le r√©pertoire d'inventaire pour l'environnement ${environment} n'existe pas: ${ANSIBLE_DIR}/inventories/${environment}"
        cleanup
        exit 1
    fi

    if [[ ! -f "${ANSIBLE_DIR}/${inventory_file}" ]]; then
        log "ERROR" "Le fichier d'inventaire n'existe pas: ${ANSIBLE_DIR}/${inventory_file}"
        cleanup
        exit 1
    fi

    if [[ ! -f "${ANSIBLE_DIR}/playbooks/init-vps.yml" ]]; then
        log "ERROR" "Le playbook d'initialisation du VPS n'existe pas: ${ANSIBLE_DIR}/playbooks/init-vps.yml"
        cleanup
        exit 1
    fi

    if [[ ! -f "${ANSIBLE_DIR}/playbooks/install-k3s.yml" ]]; then
        log "ERROR" "Le playbook d'installation de K3s n'existe pas: ${ANSIBLE_DIR}/playbooks/install-k3s.yml"
        cleanup
        exit 1
    fi

    # V√©rification des fichiers Kubernetes
    log "INFO" "V√©rification des fichiers Kubernetes..."
    if [[ ! -d "${PROJECT_ROOT}/kubernetes/overlays/${environment}" ]]; then
        log "ERROR" "Le r√©pertoire d'overlay Kubernetes pour l'environnement ${environment} n'existe pas: ${PROJECT_ROOT}/kubernetes/overlays/${environment}"
        cleanup
        exit 1
    fi

    if [[ ! -f "${PROJECT_ROOT}/kubernetes/overlays/${environment}/kustomization.yaml" ]]; then
        log "ERROR" "Le fichier kustomization.yaml pour l'environnement ${environment} n'existe pas: ${PROJECT_ROOT}/kubernetes/overlays/${environment}/kustomization.yaml"
        cleanup
        exit 1
    fi

    # Extraction des informations de connexion
    log "INFO" "Extraction des informations de connexion..."

    # Utilisation de la fonction robuste d'extraction d'informations d'inventaire
    if ! extraire_informations_inventaire; then
        log "ERROR" "√âchec de l'extraction des informations de connexion"
        cleanup
        exit 1
    fi

    if [[ -z "${ansible_host}" || -z "${ansible_port}" || -z "${ansible_user}" ]]; then
        log "ERROR" "Impossible d'extraire les informations de connexion du fichier d'inventaire"
        log "ERROR" "V√©rifiez que le fichier d'inventaire contient les variables ansible_host, ansible_port et ansible_user"
        cleanup
        exit 1
    fi

    log "INFO" "Informations de connexion: ${ansible_user}@${ansible_host}:${ansible_port}"

    # V√©rification de la connectivit√© r√©seau
    log "INFO" "V√©rification de la connectivit√© r√©seau..."
    if ! check_network; then
        log "ERROR" "V√©rification de la connectivit√© r√©seau √©chou√©e"
        cleanup
        exit 1
    fi

    # V√©rification de la connexion SSH
    log "INFO" "V√©rification de la connexion SSH..."
    if ! ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "echo 'Connexion SSH r√©ussie'" &>/dev/null; then
        log "ERROR" "Impossible de se connecter au VPS via SSH (${ansible_user}@${ansible_host}:${ansible_port})"
        log "ERROR" "V√©rifiez vos cl√©s SSH et les param√®tres de connexion"

        # V√©rification des cl√©s SSH
        if [[ ! -f ~/.ssh/id_rsa && ! -f ~/.ssh/id_ed25519 ]]; then
            log "ERROR" "Aucune cl√© SSH trouv√©e dans ~/.ssh/"
            log "ERROR" "G√©n√©rez une paire de cl√©s avec: ssh-keygen -t ed25519"
        fi

        # V√©rification du fichier known_hosts
        if ! grep -q "${ansible_host}" ~/.ssh/known_hosts 2>/dev/null; then
            log "WARNING" "L'h√¥te ${ansible_host} n'est pas dans le fichier known_hosts"
            log "WARNING" "Essayez d'abord de vous connecter manuellement: ssh -p ${ansible_port} ${ansible_user}@${ansible_host}"
        fi

        cleanup
        exit 1
    fi

    # V√©rification des ressources du VPS
    log "INFO" "V√©rification des ressources du VPS..."
    local vps_cpu_cores=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "nproc --all" 2>/dev/null || echo "0")
    local vps_memory_total=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "free -m | awk '/^Mem:/ {print \$2}'" 2>/dev/null || echo "0")
    local vps_disk_free=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "df -m / | awk 'NR==2 {print \$4}'" 2>/dev/null || echo "0")

    log "INFO" "Ressources du VPS: ${vps_cpu_cores} c≈ìurs CPU, ${vps_memory_total}MB RAM, ${vps_disk_free}MB espace disque libre"

    if [[ ${vps_cpu_cores} -lt 2 ]]; then
        log "WARNING" "Le VPS a moins de 2 c≈ìurs CPU (${vps_cpu_cores}), ce qui peut affecter les performances"
    fi

    if [[ ${vps_memory_total} -lt 4096 ]]; then
        log "WARNING" "Le VPS a moins de 4GB de RAM (${vps_memory_total}MB), ce qui peut affecter les performances"
    fi

    if [[ ${vps_disk_free} -lt 20000 ]]; then
        log "WARNING" "Le VPS a moins de 20GB d'espace disque libre (${vps_disk_free}MB), ce qui peut √™tre insuffisant"
    fi

    log "SUCCESS" "Tous les pr√©requis sont satisfaits"

    # V√©rification de l'√©tat pr√©c√©dent
    if [[ -f "${STATE_FILE}" ]]; then
        local previous_step=$(cat "${STATE_FILE}")
        log "INFO" "√âtat pr√©c√©dent d√©tect√©: ${previous_step}"
        log "INFO" "Voulez-vous reprendre √† partir de cette √©tape? (o/N)"

        read -r answer
        if [[ "${answer}" =~ ^[Oo]$ ]]; then
            log "INFO" "Reprise √† partir de l'√©tape: ${previous_step}"

            case "${previous_step}" in
                "init_vps")
                    initialiser_vps
                    installer_k3s
                    deployer_infrastructure_base
                    deployer_monitoring
                    verifier_installation
                    ;;
                "install_k3s")
                    installer_k3s
                    deployer_infrastructure_base
                    deployer_monitoring
                    verifier_installation
                    ;;
                "deploy_infra")
                    deployer_infrastructure_base
                    deployer_monitoring
                    verifier_installation
                    ;;
                "deploy_monitoring")
                    deployer_monitoring
                    verifier_installation
                    ;;
                "verify")
                    verifier_installation
                    ;;
                *)
                    log "WARNING" "√âtape inconnue: ${previous_step}, reprise depuis le d√©but"
                    ;;
            esac

            # Nettoyage et sortie
            cleanup
            exit 0
        else
            log "INFO" "D√©marrage d'une nouvelle installation"
            rm -f "${STATE_FILE}"
        fi
    fi
}

# Fonction pour comparer des versions
function version_greater_equal() {
    local version1=$1
    local version2=$2

    # Normalisation des versions pour la comparaison
    local v1_parts=(${version1//./ })
    local v2_parts=(${version2//./ })

    # Compl√©ter les tableaux avec des z√©ros si n√©cessaire
    local max_length=$(( ${#v1_parts[@]} > ${#v2_parts[@]} ? ${#v1_parts[@]} : ${#v2_parts[@]} ))
    for ((i=${#v1_parts[@]}; i<max_length; i++)); do
        v1_parts[i]=0
    done
    for ((i=${#v2_parts[@]}; i<max_length; i++)); do
        v2_parts[i]=0
    done

    # Comparaison des parties de version
    for ((i=0; i<max_length; i++)); do
        if [[ ${v1_parts[i]} -gt ${v2_parts[i]} ]]; then
            return 0  # version1 > version2
        elif [[ ${v1_parts[i]} -lt ${v2_parts[i]} ]]; then
            return 1  # version1 < version2
        fi
    done

    return 0  # version1 == version2
}

# Fonction d'initialisation du VPS
function initialiser_vps() {
    log "INFO" "Initialisation du VPS..."
    INSTALLATION_STEP="init_vps"

    # Sauvegarde de l'√©tat actuel
    echo "${INSTALLATION_STEP}" > "${STATE_FILE}"

    # Sauvegarde de l'√©tat du VPS avant modification (optionnelle)
    backup_state "pre-init-vps" "true"

    # Construction de la commande Ansible
    local ansible_cmd="ansible-playbook -i ${ANSIBLE_DIR}/${inventory_file} ${ANSIBLE_DIR}/playbooks/init-vps.yml --ask-become-pass"

    if [[ "${debug_mode}" == "true" ]]; then
        ansible_cmd="${ansible_cmd} -vvv"
    fi

    log "INFO" "Ex√©cution de la commande: ${ansible_cmd}"
    LAST_COMMAND="${ansible_cmd}"

    # Ex√©cution de la commande avec timeout
    if run_with_timeout "${ansible_cmd}" "${TIMEOUT_SECONDS}" "ansible_playbook"; then
        log "SUCCESS" "Initialisation du VPS termin√©e avec succ√®s"

        # V√©rification de l'√©tat du VPS apr√®s initialisation
        if ! ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "systemctl is-active --quiet sshd && systemctl is-active --quiet fail2ban && systemctl is-active --quiet ufw" &>/dev/null; then
            log "WARNING" "Certains services essentiels ne sont pas actifs apr√®s l'initialisation"
            log "WARNING" "V√©rifiez manuellement l'√©tat des services sur le VPS"
        else
            log "INFO" "Services essentiels actifs et fonctionnels"
        fi
    else
        log "ERROR" "√âchec de l'initialisation du VPS"

        # V√©rification des erreurs courantes
        if ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "grep -i 'failed=' /var/log/ansible.log 2>/dev/null | tail -10" &>/dev/null; then
            log "INFO" "Derni√®res erreurs Ansible sur le VPS:"
            ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "grep -i 'failed=' /var/log/ansible.log 2>/dev/null | tail -10" 2>/dev/null || true
        fi

        # Tentative de diagnostic
        log "INFO" "Tentative de diagnostic des probl√®mes..."

        # V√©rification des droits sudo
        if ! ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "sudo -n true" &>/dev/null; then
            log "ERROR" "L'utilisateur ${ansible_user} n'a pas les droits sudo sans mot de passe"
            log "ERROR" "Assurez-vous que l'utilisateur est configur√© correctement dans le fichier sudoers"
        fi

        # V√©rification de l'espace disque sur le VPS
        local disk_info=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "df -h /" 2>/dev/null || echo "Impossible de v√©rifier l'espace disque")
        log "INFO" "Espace disque sur le VPS:"
        echo "${disk_info}"

        cleanup
        exit 1
    fi
}

# Fonction d'installation de K3s
function installer_k3s() {
    log "INFO" "Installation de K3s..."
    INSTALLATION_STEP="install_k3s"

    # Sauvegarde de l'√©tat actuel
    echo "${INSTALLATION_STEP}" > "${STATE_FILE}"

    # Sauvegarde de l'√©tat du VPS avant modification (optionnelle)
    backup_state "pre-install-k3s" "true"

    # Construction de la commande Ansible
    local ansible_cmd="ansible-playbook -i ${ANSIBLE_DIR}/${inventory_file} ${ANSIBLE_DIR}/playbooks/install-k3s.yml --ask-become-pass"

    if [[ "${debug_mode}" == "true" ]]; then
        ansible_cmd="${ansible_cmd} -vvv"
    fi

    log "INFO" "Ex√©cution de la commande: ${ansible_cmd}"
    LAST_COMMAND="${ansible_cmd}"

    # Ex√©cution de la commande avec timeout
    if run_with_timeout "${ansible_cmd}" 3600 "ansible_playbook"; then  # Timeout plus long (1h) pour l'installation de K3s
        log "SUCCESS" "Installation de K3s termin√©e avec succ√®s"

        # V√©rification de l'installation de K3s
        if ! ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "systemctl is-active --quiet k3s" &>/dev/null; then
            log "WARNING" "Le service K3s ne semble pas √™tre actif apr√®s l'installation"
            log "WARNING" "V√©rifiez manuellement l'√©tat du service sur le VPS"
        else
            log "INFO" "Service K3s actif et fonctionnel"

            # V√©rification des pods syst√®me
            local pods_status=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "kubectl get pods -n kube-system -o wide" 2>/dev/null || echo "Impossible de v√©rifier les pods")
            log "INFO" "√âtat des pods syst√®me:"
            echo "${pods_status}"

            # V√©rification de l'acc√®s au cluster depuis la machine locale
            if ! kubectl cluster-info &>/dev/null; then
                log "WARNING" "Impossible d'acc√©der au cluster K3s depuis la machine locale"
                log "WARNING" "V√©rifiez votre configuration kubectl et le fichier kubeconfig"

                # Tentative de r√©cup√©ration du fichier kubeconfig
                local kubeconfig_dir="${HOME}/.kube"
                mkdir -p "${kubeconfig_dir}"

                if scp -P "${ansible_port}" "${ansible_user}@${ansible_host}:/home/${ansible_user}/.kube/config" "${kubeconfig_dir}/config.k3s" &>/dev/null; then
                    log "INFO" "Fichier kubeconfig r√©cup√©r√© dans ${kubeconfig_dir}/config.k3s"
                    log "INFO" "Utilisez la commande: export KUBECONFIG=${kubeconfig_dir}/config.k3s"
                else
                    log "ERROR" "Impossible de r√©cup√©rer le fichier kubeconfig"
                fi
            else
                log "INFO" "Acc√®s au cluster K3s depuis la machine locale v√©rifi√© avec succ√®s"
            fi
        fi
    else
        log "ERROR" "√âchec de l'installation de K3s"

        # V√©rification des erreurs courantes
        if ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "grep -i 'failed=' /var/log/ansible.log 2>/dev/null | tail -10" &>/dev/null; then
            log "INFO" "Derni√®res erreurs Ansible sur le VPS:"
            ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "grep -i 'failed=' /var/log/ansible.log 2>/dev/null | tail -10" 2>/dev/null || true
        fi

        # V√©rification des logs de K3s
        local k3s_logs=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "journalctl -u k3s --no-pager -n 50" 2>/dev/null || echo "Impossible de r√©cup√©rer les logs de K3s")
        log "INFO" "Derniers logs de K3s:"
        echo "${k3s_logs}"

        # V√©rification des ports requis pour K3s
        log "INFO" "V√©rification des ports requis pour K3s..."
        local k3s_ports=(6443 10250 10251 10252 8472 4789 51820 51821)

        for port in "${k3s_ports[@]}"; do
            if ! ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "ss -tuln | grep :${port}" &>/dev/null; then
                log "WARNING" "Le port ${port} n'est pas ouvert sur le VPS, ce qui peut causer des probl√®mes avec K3s"
            fi
        done

        # V√©rification des pr√©requis syst√®me pour K3s
        log "INFO" "V√©rification des pr√©requis syst√®me pour K3s..."
        local system_info=$(ssh -o BatchMode=yes -o ConnectTimeout=5 -p "${ansible_port}" "${ansible_user}@${ansible_host}" "uname -a && cat /etc/os-release | grep PRETTY_NAME && free -h && df -h / && sysctl -a | grep -E 'vm.max_map_count|net.ipv4.ip_forward'" 2>/dev/null || echo "Impossible de r√©cup√©rer les informations syst√®me")
        log "INFO" "Informations syst√®me:"
        echo "${system_info}"

        cleanup
        exit 1
    fi
}

# Fonction de d√©ploiement de l'infrastructure de base
function deployer_infrastructure_base() {
    log "INFO" "D√©ploiement de l'infrastructure de base..."
    INSTALLATION_STEP="deploy_infra"

    # Sauvegarde de l'√©tat actuel
    echo "${INSTALLATION_STEP}" > "${STATE_FILE}"

    # V√©rification de l'acc√®s au cluster Kubernetes
    if ! kubectl cluster-info &>/dev/null; then
        log "ERROR" "Impossible d'acc√©der au cluster Kubernetes"
        log "ERROR" "V√©rifiez votre configuration kubectl et le fichier kubeconfig"

        # Tentative de r√©cup√©ration du fichier kubeconfig
        local kubeconfig_dir="${HOME}/.kube"
        mkdir -p "${kubeconfig_dir}"

        if scp -P "${ansible_port}" "${ansible_user}@${ansible_host}:/home/${ansible_user}/.kube/config" "${kubeconfig_dir}/config.k3s" &>/dev/null; then
            log "INFO" "Fichier kubeconfig r√©cup√©r√© dans ${kubeconfig_dir}/config.k3s"
            log "INFO" "Tentative d'utilisation du nouveau fichier kubeconfig..."

            # Sauvegarde du KUBECONFIG actuel
            local old_kubeconfig="${KUBECONFIG}"
            export KUBECONFIG="${kubeconfig_dir}/config.k3s"

            if ! kubectl cluster-info &>/dev/null; then
                log "ERROR" "Impossible d'acc√©der au cluster Kubernetes m√™me avec le nouveau fichier kubeconfig"
                # Restauration du KUBECONFIG
                if [[ -n "${old_kubeconfig}" ]]; then
                    export KUBECONFIG="${old_kubeconfig}"
                else
                    unset KUBECONFIG
                fi
                cleanup
                exit 1
            else
                log "SUCCESS" "Acc√®s au cluster Kubernetes r√©tabli avec le nouveau fichier kubeconfig"
            fi
        else
            log "ERROR" "Impossible de r√©cup√©rer le fichier kubeconfig"
            cleanup
            exit 1
        fi
    fi

    # Cr√©ation du namespace pour l'infrastructure
    log "INFO" "Cr√©ation du namespace lions-infrastructure..."
    LAST_COMMAND="kubectl create namespace lions-infrastructure --dry-run=client -o yaml | kubectl apply -f -"

    if ! run_with_timeout "kubectl create namespace lions-infrastructure --dry-run=client -o yaml | kubectl apply -f -"; then
        log "ERROR" "√âchec de la cr√©ation du namespace lions-infrastructure"

        # V√©rification si le namespace existe d√©j√†
        if kubectl get namespace lions-infrastructure &>/dev/null; then
            log "WARNING" "Le namespace lions-infrastructure existe d√©j√†"
        else
            # Tentative de diagnostic
            log "INFO" "Tentative de diagnostic des probl√®mes..."
            kubectl get namespaces
            kubectl describe namespace lions-infrastructure 2>/dev/null || true

            cleanup
            exit 1
        fi
    fi

    # D√©ploiement des composants de base via kustomize
    log "INFO" "D√©ploiement des composants de base via kustomize..."
    LAST_COMMAND="kubectl apply -k \"${PROJECT_ROOT}/kubernetes/overlays/${environment}\""

    # V√©rification pr√©alable de la configuration kustomize
    log "INFO" "V√©rification de la configuration kustomize..."
    if ! run_with_timeout "kubectl kustomize \"${PROJECT_ROOT}/kubernetes/overlays/${environment}\" > /dev/null"; then
        log "ERROR" "La configuration kustomize contient des erreurs"

        # Affichage des erreurs de kustomize
        kubectl kustomize "${PROJECT_ROOT}/kubernetes/overlays/${environment}" 2>&1 || true

        # Tentative de diagnostic
        log "INFO" "Tentative de diagnostic des probl√®mes de kustomize..."

        # V√©rification des fichiers r√©f√©renc√©s
        log "INFO" "V√©rification des fichiers r√©f√©renc√©s dans kustomization.yaml..."
        grep -r "resources:" "${PROJECT_ROOT}/kubernetes/overlays/${environment}" --include="*.yaml" -A 10

        cleanup
        exit 1
    fi

    # Application de la configuration kustomize
    if ! run_with_timeout "kubectl apply -k \"${PROJECT_ROOT}/kubernetes/overlays/${environment}\" --timeout=5m"; then
        log "ERROR" "√âchec du d√©ploiement des composants de base via kustomize"

        # Tentative de diagnostic
        log "INFO" "Tentative de diagnostic des probl√®mes..."

        # V√©rification des erreurs courantes
        log "INFO" "V√©rification des erreurs courantes..."

        # V√©rification des ressources d√©ploy√©es
        kubectl get all -n "${environment}" 2>/dev/null || true

        # V√©rification des √©v√©nements
        kubectl get events --sort-by='.lastTimestamp' --field-selector type=Warning -n "${environment}" 2>/dev/null || true

        # Tentative de d√©ploiement avec validation d√©sactiv√©e
        log "INFO" "Tentative de d√©ploiement avec validation d√©sactiv√©e..."
        if ! run_with_timeout "kubectl apply -k \"${PROJECT_ROOT}/kubernetes/overlays/${environment}\" --validate=false --timeout=5m"; then
            log "ERROR" "√âchec du d√©ploiement m√™me avec validation d√©sactiv√©e"
            cleanup
            exit 1
        else
            log "WARNING" "D√©ploiement r√©ussi avec validation d√©sactiv√©e, mais des probl√®mes peuvent subsister"
        fi
    fi

    # V√©rification du d√©ploiement
    log "INFO" "V√©rification du d√©ploiement..."

    # V√©rification des namespaces
    if ! kubectl get namespace "${environment}" &>/dev/null; then
        log "WARNING" "Le namespace ${environment} n'a pas √©t√© cr√©√©"
    else
        log "INFO" "Namespace ${environment} cr√©√© avec succ√®s"
    fi

    # V√©rification des quotas de ressources
    if ! kubectl get resourcequotas -n "${environment}" &>/dev/null; then
        log "WARNING" "Les quotas de ressources n'ont pas √©t√© cr√©√©s dans le namespace ${environment}"
    else
        log "INFO" "Quotas de ressources cr√©√©s avec succ√®s dans le namespace ${environment}"
    fi

    # V√©rification des politiques r√©seau
    if ! kubectl get networkpolicies -n "${environment}" &>/dev/null; then
        log "WARNING" "Les politiques r√©seau n'ont pas √©t√© cr√©√©es dans le namespace ${environment}"
    else
        log "INFO" "Politiques r√©seau cr√©√©es avec succ√®s dans le namespace ${environment}"
    fi

    log "SUCCESS" "D√©ploiement de l'infrastructure de base termin√© avec succ√®s"
}

# Fonction de d√©ploiement du monitoring
function deployer_monitoring() {
    log "INFO" "D√©ploiement du syst√®me de monitoring..."
    INSTALLATION_STEP="deploy_monitoring"

    # Sauvegarde de l'√©tat actuel
    echo "${INSTALLATION_STEP}" > "${STATE_FILE}"

    # V√©rification de l'acc√®s au cluster Kubernetes
    if ! kubectl cluster-info &>/dev/null; then
        log "ERROR" "Impossible d'acc√©der au cluster Kubernetes"
        log "ERROR" "V√©rifiez votre configuration kubectl et le fichier kubeconfig"
        cleanup
        exit 1
    fi

    # Cr√©ation du namespace pour le monitoring
    log "INFO" "Cr√©ation du namespace monitoring..."
    LAST_COMMAND="kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -"

    if ! run_with_timeout "kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -"; then
        log "ERROR" "√âchec de la cr√©ation du namespace monitoring"

        # V√©rification si le namespace existe d√©j√†
        if kubectl get namespace monitoring &>/dev/null; then
            log "WARNING" "Le namespace monitoring existe d√©j√†"
        else
            # Tentative de diagnostic
            log "INFO" "Tentative de diagnostic des probl√®mes..."
            kubectl get namespaces
            kubectl describe namespace monitoring 2>/dev/null || true

            cleanup
            exit 1
        fi
    fi

    # D√©ploiement de Prometheus et Grafana via Helm
    log "INFO" "D√©ploiement de Prometheus et Grafana..."

    # V√©rification de Helm
    if ! command_exists "helm"; then
        log "ERROR" "Helm n'est pas install√© ou n'est pas dans le PATH"
        cleanup
        exit 1
    fi

    # Ajout du d√©p√¥t Helm de Prometheus
    LAST_COMMAND="helm repo add prometheus-community https://prometheus-community.github.io/helm-charts"
    if ! run_with_timeout "helm repo add prometheus-community https://prometheus-community.github.io/helm-charts"; then
        log "ERROR" "√âchec de l'ajout du d√©p√¥t Helm de Prometheus"

        # Tentative de diagnostic
        log "INFO" "Tentative de diagnostic des probl√®mes..."
        helm repo list

        cleanup
        exit 1
    fi

    LAST_COMMAND="helm repo update"
    if ! run_with_timeout "helm repo update"; then
        log "ERROR" "√âchec de la mise √† jour des d√©p√¥ts Helm"
        cleanup
        exit 1
    fi

    # Cr√©ation d'un fichier de valeurs temporaire pour Prometheus
    local values_file=$(mktemp)
    cat > "${values_file}" << EOF
grafana:
  adminPassword: admin
  service:
    type: NodePort
    nodePort: 30000
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 200m
      memory: 512Mi
prometheus:
  prometheusSpec:
    retention: 15d
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 500m
        memory: 1Gi
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi
alertmanager:
  alertmanagerSpec:
    resources:
      requests:
        cpu: 50m
        memory: 128Mi
      limits:
        cpu: 100m
        memory: 256Mi
EOF

    # D√©ploiement de Prometheus
    LAST_COMMAND="helm upgrade --install prometheus prometheus-community/kube-prometheus-stack --namespace monitoring --values ${values_file}"

    if ! run_with_timeout "helm upgrade --install prometheus prometheus-community/kube-prometheus-stack --namespace monitoring --values ${values_file}" 1800; then
        log "ERROR" "√âchec du d√©ploiement de Prometheus et Grafana"

        # Tentative de diagnostic
        log "INFO" "Tentative de diagnostic des probl√®mes..."

        # V√©rification des pods
        kubectl get pods -n monitoring

        # V√©rification des √©v√©nements
        kubectl get events --sort-by='.lastTimestamp' --field-selector type=Warning -n monitoring

        # V√©rification des logs des pods en erreur
        local failed_pods=$(kubectl get pods -n monitoring --field-selector status.phase!=Running,status.phase!=Succeeded -o jsonpath='{.items[*].metadata.name}')
        if [[ -n "${failed_pods}" ]]; then
            for pod in ${failed_pods}; do
                log "INFO" "Logs du pod ${pod}:"
                kubectl logs -n monitoring "${pod}" --tail=50 || true
            done
        fi

        # V√©rification des ressources disponibles
        kubectl describe nodes

        # Nettoyage du fichier de valeurs temporaire
        rm -f "${values_file}"

        cleanup
        exit 1
    fi

    # Nettoyage du fichier de valeurs temporaire
    rm -f "${values_file}"

    # V√©rification du d√©ploiement
    log "INFO" "V√©rification du d√©ploiement du monitoring..."

    # Attente que les pods soient pr√™ts
    log "INFO" "Attente que les pods de monitoring soient pr√™ts..."
    local timeout=300  # 5 minutes
    local start_time=$(date +%s)
    local all_pods_ready=false

    while [[ "${all_pods_ready}" == "false" ]]; do
        local current_time=$(date +%s)
        local elapsed_time=$((current_time - start_time))

        if [[ ${elapsed_time} -gt ${timeout} ]]; then
            log "WARNING" "Timeout atteint en attendant que les pods de monitoring soient pr√™ts"
            break
        fi

        local not_ready_pods=$(kubectl get pods -n monitoring --field-selector status.phase!=Running,status.phase!=Succeeded -o jsonpath='{.items[*].metadata.name}')
        if [[ -z "${not_ready_pods}" ]]; then
            all_pods_ready=true
            log "SUCCESS" "Tous les pods de monitoring sont pr√™ts"
        else
            log "INFO" "En attente que les pods suivants soient pr√™ts: ${not_ready_pods}"
            sleep 10
        fi
    done

    # V√©rification de l'acc√®s √† Grafana
    log "INFO" "V√©rification de l'acc√®s √† Grafana..."
    local grafana_service=$(kubectl get service -n monitoring prometheus-grafana -o jsonpath='{.spec.ports[0].nodePort}' 2>/dev/null)

    if [[ -n "${grafana_service}" ]]; then
        log "INFO" "Grafana est accessible √† l'adresse: http://${ansible_host}:${grafana_service}"
        log "INFO" "Identifiant: admin"
        log "INFO" "Mot de passe: admin"
    else
        log "WARNING" "Impossible de d√©terminer l'adresse d'acc√®s √† Grafana"
    fi

    log "SUCCESS" "D√©ploiement du syst√®me de monitoring termin√© avec succ√®s"
}

# Fonction de v√©rification finale
function verifier_installation() {
    log "INFO" "V√©rification de l'installation..."
    INSTALLATION_STEP="verify"

    # V√©rification de l'acc√®s au cluster Kubernetes
    if ! kubectl cluster-info &>/dev/null; then
        log "ERROR" "Impossible d'acc√©der au cluster Kubernetes"
        log "ERROR" "V√©rifiez votre configuration kubectl et le fichier kubeconfig"
        cleanup
        exit 1
    fi

    # V√©rification des n≈ìuds
    log "INFO" "V√©rification des n≈ìuds Kubernetes..."
    LAST_COMMAND="kubectl get nodes -o wide"

    local nodes_output=$(kubectl get nodes -o wide 2>&1)
    echo "${nodes_output}"

    # V√©rification de l'√©tat des n≈ìuds
    if ! echo "${nodes_output}" | grep -q "Ready"; then
        log "WARNING" "Aucun n≈ìud n'est en √©tat 'Ready'"
        log "WARNING" "V√©rifiez l'√©tat des n≈ìuds et les logs de K3s"
    else
        log "SUCCESS" "Au moins un n≈ìud est en √©tat 'Ready'"
    fi

    # V√©rification des namespaces
    log "INFO" "V√©rification des namespaces..."
    LAST_COMMAND="kubectl get namespaces"

    local namespaces_output=$(kubectl get namespaces 2>&1)
    echo "${namespaces_output}"

    # V√©rification des namespaces requis
    local required_namespaces=("kube-system" "lions-infrastructure" "${environment}" "monitoring")
    local missing_namespaces=()

    for ns in "${required_namespaces[@]}"; do
        if ! echo "${namespaces_output}" | grep -q "${ns}"; then
            missing_namespaces+=("${ns}")
        fi
    done

    if [[ ${#missing_namespaces[@]} -gt 0 ]]; then
        log "WARNING" "Namespaces requis manquants: ${missing_namespaces[*]}"
    else
        log "SUCCESS" "Tous les namespaces requis sont pr√©sents"
    fi

    # V√©rification des pods syst√®me
    log "INFO" "V√©rification des pods syst√®me..."
    LAST_COMMAND="kubectl get pods -n kube-system"

    local system_pods_output=$(kubectl get pods -n kube-system 2>&1)
    echo "${system_pods_output}"

    # V√©rification des pods syst√®me essentiels
    local essential_system_pods=("coredns" "metrics-server" "local-path-provisioner")
    local missing_system_pods=()

    for pod in "${essential_system_pods[@]}"; do
        if ! echo "${system_pods_output}" | grep -q "${pod}"; then
            missing_system_pods+=("${pod}")
        fi
    done

    if [[ ${#missing_system_pods[@]} -gt 0 ]]; then
        log "WARNING" "Pods syst√®me essentiels manquants: ${missing_system_pods[*]}"
    else
        log "SUCCESS" "Tous les pods syst√®me essentiels sont pr√©sents"
    fi

    # V√©rification des pods d'infrastructure
    log "INFO" "V√©rification des pods d'infrastructure..."
    LAST_COMMAND="kubectl get pods -n lions-infrastructure"

    local infra_pods_output=$(kubectl get pods -n lions-infrastructure 2>&1)
    echo "${infra_pods_output}"

    # V√©rification des pods de monitoring
    log "INFO" "V√©rification des pods de monitoring..."
    LAST_COMMAND="kubectl get pods -n monitoring"

    local monitoring_pods_output=$(kubectl get pods -n monitoring 2>&1)
    echo "${monitoring_pods_output}"

    # V√©rification des pods de monitoring essentiels
    local essential_monitoring_pods=("prometheus" "grafana" "alertmanager")
    local missing_monitoring_pods=()

    for pod in "${essential_monitoring_pods[@]}"; do
        if ! echo "${monitoring_pods_output}" | grep -q "${pod}"; then
            missing_monitoring_pods+=("${pod}")
        fi
    done

    if [[ ${#missing_monitoring_pods[@]} -gt 0 ]]; then
        log "WARNING" "Pods de monitoring essentiels manquants: ${missing_monitoring_pods[*]}"
    else
        log "SUCCESS" "Tous les pods de monitoring essentiels sont pr√©sents"
    fi

    # V√©rification des pods du Kubernetes Dashboard
    log "INFO" "V√©rification des pods du Kubernetes Dashboard..."
    LAST_COMMAND="kubectl get pods -n kubernetes-dashboard"

    local dashboard_pods_output=$(kubectl get pods -n kubernetes-dashboard 2>&1)
    echo "${dashboard_pods_output}"

    # V√©rification des services
    log "INFO" "V√©rification des services expos√©s..."

    # V√©rification de Grafana
    local grafana_service=$(kubectl get service -n monitoring prometheus-grafana -o jsonpath='{.spec.ports[0].nodePort}' 2>/dev/null)
    if [[ -n "${grafana_service}" ]]; then
        log "INFO" "Grafana est expos√© sur le port ${grafana_service}"

        # Tentative de connexion √† Grafana
        if command_exists "curl"; then
            if curl -s -o /dev/null -w "%{http_code}" "http://${ansible_host}:${grafana_service}" | grep -q "200\|302"; then
                log "SUCCESS" "Grafana est accessible √† l'adresse: http://${ansible_host}:${grafana_service}"
            else
                log "WARNING" "Grafana n'est pas accessible √† l'adresse: http://${ansible_host}:${grafana_service}"
                log "WARNING" "V√©rifiez les r√®gles de pare-feu et l'√©tat du service"
            fi
        fi
    else
        log "WARNING" "Service Grafana non trouv√© ou non expos√©"
    fi

    # V√©rification du Kubernetes Dashboard
    local dashboard_service=$(kubectl get service -n kubernetes-dashboard kubernetes-dashboard-nodeport -o jsonpath='{.spec.ports[0].nodePort}' 2>/dev/null)
    if [[ -n "${dashboard_service}" ]]; then
        log "INFO" "Kubernetes Dashboard est expos√© sur le port ${dashboard_service}"

        # Tentative de connexion au Dashboard
        if command_exists "curl"; then
            if curl -s -k -o /dev/null -w "%{http_code}" "https://${ansible_host}:${dashboard_service}" | grep -q "200\|302\|401"; then
                log "SUCCESS" "Kubernetes Dashboard est accessible √† l'adresse: https://${ansible_host}:${dashboard_service}"
            else
                log "WARNING" "Kubernetes Dashboard n'est pas accessible √† l'adresse: https://${ansible_host}:${dashboard_service}"
                log "WARNING" "V√©rifiez les r√®gles de pare-feu et l'√©tat du service"
            fi
        fi
    else
        log "WARNING" "Service Kubernetes Dashboard non trouv√© ou non expos√©"
    fi

    # V√©rification de Traefik
    log "INFO" "V√©rification de Traefik..."
    local traefik_pods=$(kubectl get pods -n kube-system -l app=traefik -o jsonpath='{.items[*].metadata.name}' 2>/dev/null)

    if [[ -n "${traefik_pods}" ]]; then
        log "SUCCESS" "Traefik est install√© et en cours d'ex√©cution"

        # V√©rification des services Traefik
        local traefik_service=$(kubectl get service -n kube-system traefik -o jsonpath='{.spec.ports[?(@.name=="web")].nodePort}' 2>/dev/null)
        if [[ -n "${traefik_service}" ]]; then
            log "INFO" "Traefik est expos√© sur le port ${traefik_service}"

            # Tentative de connexion √† Traefik
            if command_exists "curl"; then
                if curl -s -o /dev/null -w "%{http_code}" "http://${ansible_host}:${traefik_service}" | grep -q "200\|302\|404"; then
                    log "SUCCESS" "Traefik est accessible √† l'adresse: http://${ansible_host}:${traefik_service}"
                else
                    log "WARNING" "Traefik n'est pas accessible √† l'adresse: http://${ansible_host}:${traefik_service}"
                    log "WARNING" "V√©rifiez les r√®gles de pare-feu et l'√©tat du service"
                fi
            fi
        else
            log "WARNING" "Service Traefik non trouv√© ou non expos√©"
        fi
    else
        log "WARNING" "Traefik n'est pas install√© ou n'est pas en cours d'ex√©cution"
        log "WARNING" "V√©rifiez l'installation de K3s et les logs"
    fi

    # V√©rification des quotas de ressources
    log "INFO" "V√©rification des quotas de ressources..."
    LAST_COMMAND="kubectl get resourcequotas --all-namespaces"

    local quotas_output=$(kubectl get resourcequotas --all-namespaces 2>&1)
    echo "${quotas_output}"

    if ! echo "${quotas_output}" | grep -q "compute-resources"; then
        log "WARNING" "Quotas de ressources non configur√©s"
        log "WARNING" "V√©rifiez la configuration des quotas de ressources"
    else
        log "SUCCESS" "Quotas de ressources configur√©s correctement"
    fi

    # V√©rification des politiques r√©seau
    log "INFO" "V√©rification des politiques r√©seau..."
    LAST_COMMAND="kubectl get networkpolicies --all-namespaces"

    local netpol_output=$(kubectl get networkpolicies --all-namespaces 2>&1)
    echo "${netpol_output}"

    local essential_netpols=("default-network-policy" "allow-dns" "allow-monitoring")
    local missing_netpols=()

    for netpol in "${essential_netpols[@]}"; do
        if ! echo "${netpol_output}" | grep -q "${netpol}"; then
            missing_netpols+=("${netpol}")
        fi
    done

    if [[ ${#missing_netpols[@]} -gt 0 ]]; then
        log "WARNING" "Politiques r√©seau essentielles manquantes: ${missing_netpols[*]}"
    else
        log "SUCCESS" "Toutes les politiques r√©seau essentielles sont pr√©sentes"
    fi

    # V√©rification des classes de stockage
    log "INFO" "V√©rification des classes de stockage..."
    LAST_COMMAND="kubectl get storageclasses"

    local sc_output=$(kubectl get storageclasses 2>&1)
    echo "${sc_output}"

    if ! echo "${sc_output}" | grep -q "local-path"; then
        log "WARNING" "Classe de stockage local-path non trouv√©e"
        log "WARNING" "V√©rifiez l'installation du provisioner de stockage local"
    else
        log "SUCCESS" "Classe de stockage local-path trouv√©e"
    fi

    # V√©rification des CRDs
    log "INFO" "V√©rification des d√©finitions de ressources personnalis√©es (CRDs)..."
    LAST_COMMAND="kubectl get crds"

    local crd_output=$(kubectl get crds 2>&1)

    local essential_crds=("servicemonitors.monitoring.coreos.com" "prometheusrules.monitoring.coreos.com" "ingressroutes.traefik.containo.us")
    local missing_crds=()

    for crd in "${essential_crds[@]}"; do
        if ! echo "${crd_output}" | grep -q "${crd}"; then
            missing_crds+=("${crd}")
        fi
    done

    if [[ ${#missing_crds[@]} -gt 0 ]]; then
        log "WARNING" "CRDs essentielles manquantes: ${missing_crds[*]}"
    else
        log "SUCCESS" "Toutes les CRDs essentielles sont pr√©sentes"
    fi

    # V√©rification des r√¥les RBAC
    log "INFO" "V√©rification des r√¥les RBAC..."
    LAST_COMMAND="kubectl get clusterroles | grep lions"

    local rbac_output=$(kubectl get clusterroles | grep lions 2>&1)
    echo "${rbac_output}"

    local essential_roles=("lions-admin" "lions-developer" "lions-monitoring")
    local missing_roles=()

    for role in "${essential_roles[@]}"; do
        if ! echo "${rbac_output}" | grep -q "${role}"; then
            missing_roles+=("${role}")
        fi
    done

    if [[ ${#missing_roles[@]} -gt 0 ]]; then
        log "WARNING" "R√¥les RBAC essentiels manquants: ${missing_roles[*]}"
    else
        log "SUCCESS" "Tous les r√¥les RBAC essentiels sont pr√©sents"
    fi

    # V√©rification des volumes persistants
    log "INFO" "V√©rification des volumes persistants..."
    LAST_COMMAND="kubectl get pv"

    local pv_output=$(kubectl get pv 2>&1)
    echo "${pv_output}"

    # R√©sum√© de l'installation
    log "INFO" "R√©sum√© de l'installation:"

    # V√©rification des pods non pr√™ts
    local not_ready_pods=$(kubectl get pods --all-namespaces --field-selector status.phase!=Running,status.phase!=Succeeded -o jsonpath='{range .items[*]}{.metadata.namespace}/{.metadata.name}{"\n"}{end}' 2>/dev/null)

    if [[ -n "${not_ready_pods}" ]]; then
        log "WARNING" "Pods non pr√™ts:"
        echo "${not_ready_pods}"
    else
        log "SUCCESS" "Tous les pods sont pr√™ts"
    fi

    # V√©rification des pods en √©tat d'erreur
    local error_pods=$(kubectl get pods --all-namespaces | grep -v "Running\|Completed\|NAME" 2>/dev/null)

    if [[ -n "${error_pods}" ]]; then
        log "WARNING" "Pods en √©tat d'erreur:"
        echo "${error_pods}"

        # R√©cup√©ration des logs des pods en erreur
        log "INFO" "Logs des pods en √©tat d'erreur:"
        echo "${error_pods}" | while read -r line; do
            local ns=$(echo "${line}" | awk '{print $1}')
            local pod=$(echo "${line}" | awk '{print $2}')

            log "INFO" "Logs du pod ${ns}/${pod}:"
            kubectl logs -n "${ns}" "${pod}" --tail=20 2>/dev/null || echo "Impossible de r√©cup√©rer les logs"
            echo "---"
        done
    else
        log "SUCCESS" "Aucun pod en √©tat d'erreur"
    fi

    # V√©rification des √©v√©nements r√©cents
    log "INFO" "√âv√©nements r√©cents (derni√®res 5 minutes):"
    kubectl get events --all-namespaces --sort-by='.lastTimestamp' --field-selector type=Warning --since=5m

    # V√©rification de la connectivit√© externe
    log "INFO" "V√©rification de la connectivit√© externe..."

    # V√©rification de l'acc√®s aux services expos√©s
    local services_to_check=(
        "http://${ansible_host}:30000|Grafana"
        "https://${ansible_host}:30001|Kubernetes Dashboard"
        "http://${ansible_host}:80|Traefik HTTP"
        "https://${ansible_host}:443|Traefik HTTPS"
    )

    for service_info in "${services_to_check[@]}"; do
        local service_url=$(echo "${service_info}" | cut -d'|' -f1)
        local service_name=$(echo "${service_info}" | cut -d'|' -f2)

        if command_exists "curl"; then
            local protocol=$(echo "${service_url}" | cut -d':' -f1)
            local curl_opts="-s -o /dev/null -w %{http_code} --connect-timeout 5"

            if [[ "${protocol}" == "https" ]]; then
                curl_opts="${curl_opts} -k"
            fi

            local status=$(curl ${curl_opts} "${service_url}" 2>/dev/null || echo "000")

            if [[ "${status}" =~ ^(200|301|302|401|403)$ ]]; then
                log "SUCCESS" "${service_name} est accessible √† l'adresse ${service_url} (code ${status})"
            else
                log "WARNING" "${service_name} n'est pas accessible √† l'adresse ${service_url} (code ${status})"
                log "WARNING" "V√©rifiez les r√®gles de pare-feu et l'√©tat du service"
            fi
        else
            log "WARNING" "curl n'est pas install√©, impossible de v√©rifier l'acc√®s √† ${service_name}"
        fi
    done

    log "SUCCESS" "V√©rification de l'installation termin√©e avec succ√®s"

    # G√©n√©ration d'un rapport de v√©rification
    local report_file="${LOG_DIR}/verification-report-$(date +%Y%m%d-%H%M%S).txt"

    {
        echo "=== RAPPORT DE V√âRIFICATION DE L'INFRASTRUCTURE LIONS ==="
        echo "Date: $(date)"
        echo "Environnement: ${environment}"
        echo ""

        echo "=== N≈íUDS KUBERNETES ==="
        kubectl get nodes -o wide
        echo ""

        echo "=== NAMESPACES ==="
        kubectl get namespaces
        echo ""

        echo "=== PODS PAR NAMESPACE ==="
        kubectl get pods --all-namespaces
        echo ""

        echo "=== SERVICES EXPOS√âS ==="
        kubectl get services --all-namespaces -o wide | grep NodePort
        echo ""

        echo "=== INGRESS ==="
        kubectl get ingress --all-namespaces
        echo ""

        echo "=== √âV√âNEMENTS R√âCENTS ==="
        kubectl get events --all-namespaces --sort-by='.lastTimestamp' | tail -20
        echo ""

        echo "=== UTILISATION DES RESSOURCES ==="
        kubectl top nodes 2>/dev/null || echo "Metrics-server non disponible"
        echo ""
        kubectl top pods --all-namespaces 2>/dev/null || echo "Metrics-server non disponible"
        echo ""

        echo "=== √âTAT DE SANT√â GLOBAL ==="
        if [[ -n "${not_ready_pods}" ]] || [[ -n "${error_pods}" ]]; then
            echo "‚ö†Ô∏è Des probl√®mes ont √©t√© d√©tect√©s, consultez les logs pour plus de d√©tails."
        else
            echo "‚úÖ L'infrastructure semble √™tre en bon √©tat."
        fi
        echo ""

        echo "=== INSTRUCTIONS D'ACC√àS ==="
        echo "Grafana: http://${ansible_host}:30000 (admin/admin)"
        echo "Kubernetes Dashboard: https://${ansible_host}:30001 (token requis)"
        echo ""

        echo "=== FIN DU RAPPORT ==="
    } > "${report_file}"

    log "INFO" "Rapport de v√©rification g√©n√©r√©: ${report_file}"

    # Nettoyage du fichier de verrouillage et d'√©tat
    rm -f "${LOCK_FILE}" "${STATE_FILE}"
}

# Fonction pour tester la robustesse du script
function test_robustesse() {
    log "INFO" "Ex√©cution des tests de robustesse..."

    # Sauvegarde de l'√©tat actuel (optionnelle)
    backup_state "pre-test-robustesse" "true"

    # Test 1: Simulation d'une erreur de connexion SSH
    log "INFO" "Test 1: Simulation d'une erreur de connexion SSH..."
    local original_host="${ansible_host}"
    ansible_host="invalid.host.example.com"

    # Tentative d'ex√©cution d'une commande qui n√©cessite SSH
    if ! check_vps_resources; then
        log "SUCCESS" "Test 1 r√©ussi: L'erreur de connexion SSH a √©t√© correctement d√©tect√©e et g√©r√©e"
    else
        log "ERROR" "Test 1 √©chou√©: L'erreur de connexion SSH n'a pas √©t√© correctement d√©tect√©e"
    fi

    # Restauration de l'h√¥te original
    ansible_host="${original_host}"

    # Test 2: Simulation d'une erreur de commande kubectl
    log "INFO" "Test 2: Simulation d'une erreur de commande kubectl..."
    local original_kubeconfig="${KUBECONFIG}"
    export KUBECONFIG="/tmp/invalid_kubeconfig_file"

    # Tentative d'ex√©cution d'une commande kubectl
    if ! kubectl get nodes &>/dev/null; then
        log "SUCCESS" "Test 2 r√©ussi: L'erreur de commande kubectl a √©t√© correctement d√©tect√©e"
    else
        log "ERROR" "Test 2 √©chou√©: L'erreur de commande kubectl n'a pas √©t√© correctement d√©tect√©e"
    fi

    # Restauration du kubeconfig original
    export KUBECONFIG="${original_kubeconfig}"

    # Test 3: Simulation d'une erreur de timeout
    log "INFO" "Test 3: Simulation d'une erreur de timeout..."
    local original_timeout="${TIMEOUT_SECONDS}"
    TIMEOUT_SECONDS=1

    # Tentative d'ex√©cution d'une commande avec un timeout tr√®s court
    if ! run_with_timeout "sleep 5" 1 "sleep"; then
        log "SUCCESS" "Test 3 r√©ussi: L'erreur de timeout a √©t√© correctement d√©tect√©e et g√©r√©e"
    else
        log "ERROR" "Test 3 √©chou√©: L'erreur de timeout n'a pas √©t√© correctement d√©tect√©e"
    fi

    # Restauration du timeout original
    TIMEOUT_SECONDS="${original_timeout}"

    # Test 4: Test du m√©canisme de retry pour les erreurs r√©seau
    log "INFO" "Test 4: Test du m√©canisme de retry pour les erreurs r√©seau..."

    # Cr√©ation d'un script temporaire qui √©choue les premi√®res fois puis r√©ussit
    local temp_script=$(mktemp)
    cat > "${temp_script}" << 'EOF'
#!/bin/bash
COUNTER_FILE="/tmp/retry_test_counter"

# Initialiser le compteur s'il n'existe pas
if [[ ! -f "${COUNTER_FILE}" ]]; then
    echo "0" > "${COUNTER_FILE}"
fi

# Lire le compteur actuel
COUNTER=$(cat "${COUNTER_FILE}")

# Incr√©menter le compteur
COUNTER=$((COUNTER + 1))
echo "${COUNTER}" > "${COUNTER_FILE}"

# √âchouer les 2 premi√®res fois avec une erreur r√©seau
if [[ ${COUNTER} -le 2 ]]; then
    echo "Connection timed out"
    exit 1
fi

# R√©ussir la 3√®me fois
echo "Op√©ration r√©ussie"
exit 0
EOF

    chmod +x "${temp_script}"

    # R√©initialiser le compteur
    echo "0" > "/tmp/retry_test_counter"

    # Ex√©cuter la commande avec le m√©canisme de retry
    if run_with_timeout "${temp_script}" 10 "network_test"; then
        # V√©rifier que le compteur est √† 3 (2 √©checs + 1 succ√®s)
        local final_counter=$(cat "/tmp/retry_test_counter")
        if [[ "${final_counter}" -eq 3 ]]; then
            log "SUCCESS" "Test 4 r√©ussi: Le m√©canisme de retry a fonctionn√© correctement (${final_counter} tentatives)"
        else
            log "ERROR" "Test 4 √©chou√©: Le nombre de tentatives (${final_counter}) ne correspond pas √† l'attendu (3)"
        fi
    else
        log "ERROR" "Test 4 √©chou√©: La commande n'a pas r√©ussi malgr√© le m√©canisme de retry"
    fi

    # Nettoyage
    rm -f "${temp_script}" "/tmp/retry_test_counter"

    # Test 5: Simulation d'une erreur de ressources insuffisantes
    log "INFO" "Test 5: Simulation d'une erreur de ressources insuffisantes..."
    local original_required_space="${REQUIRED_SPACE_MB}"
    REQUIRED_SPACE_MB=999999999

    # Tentative de v√©rification des ressources
    if ! check_disk_space; then
        log "SUCCESS" "Test 4 r√©ussi: L'erreur de ressources insuffisantes a √©t√© correctement d√©tect√©e et g√©r√©e"
    else
        log "ERROR" "Test 4 √©chou√©: L'erreur de ressources insuffisantes n'a pas √©t√© correctement d√©tect√©e"
    fi

    # Restauration de l'espace requis original
    REQUIRED_SPACE_MB="${original_required_space}"

    # Test 5: Test de la fonction de restauration
    log "INFO" "Test 5: Test de la fonction de restauration..."

    # Tentative de restauration de l'√©tat sauvegard√©
    if restore_state; then
        log "SUCCESS" "Test 5 r√©ussi: La restauration de l'√©tat a fonctionn√© correctement"
    else
        log "WARNING" "Test 5 √©chou√©: La restauration de l'√©tat n'a pas fonctionn√© correctement"
    fi

    log "INFO" "Tests de robustesse termin√©s"
    return 0
}

# Parsing des arguments
environment="${DEFAULT_ENV}"
inventory_file="inventories/${DEFAULT_ENV}/hosts.yml"
skip_init="false"
debug_mode="false"
test_mode="false"

while [[ $# -gt 0 ]]; do
    case "$1" in
        -e|--environment)
            environment="$2"
            inventory_file="inventories/${environment}/hosts.yml"
            shift 2
            ;;
        -i|--inventory)
            inventory_file="$2"
            shift 2
            ;;
        -s|--skip-init)
            skip_init="true"
            shift
            ;;
        -d|--debug)
            debug_mode="true"
            shift
            ;;
        -t|--test)
            test_mode="true"
            shift
            ;;
        -h|--help)
            afficher_aide
            exit 0
            ;;
        *)
            log "ERROR" "Argument inconnu: $1"
            afficher_aide
            exit 1
            ;;
    esac
done

# Affichage du titre
echo -e "${COLOR_CYAN}${COLOR_BOLD}"
echo -e "  _     ___ ___  _   _ ___    ___ _   _ _____ ___    _    "
echo -e " | |   |_ _/ _ \| \ | / __|  |_ _| \ | |  ___/ _ \  / \   "
echo -e " | |    | | | | |  \| \__ \   | ||  \| | |_ | | | |/ _ \  "
echo -e " | |___ | | |_| | |\  |__) |  | || |\  |  _|| |_| / ___ \ "
echo -e " |_____|___\___/|_| \_|____/  |___|_| \_|_|   \___/_/   \_\\"
echo -e "${COLOR_RESET}"
echo -e "${COLOR_YELLOW}${COLOR_BOLD}  Installation de l'Infrastructure sur VPS - v1.0.0${COLOR_RESET}"
echo -e "${COLOR_CYAN}  ------------------------------------------------${COLOR_RESET}\n"

# Affichage des param√®tres
log "INFO" "Environnement: ${environment}"
log "INFO" "Fichier d'inventaire: ${inventory_file}"
log "INFO" "Ignorer l'initialisation: ${skip_init}"
log "INFO" "Mode debug: ${debug_mode}"
log "INFO" "Mode test: ${test_mode}"
log "INFO" "Fichier de log: ${LOG_FILE}"

# La v√©rification du fichier de verrouillage est d√©j√† effectu√©e dans la fonction verifier_prerequis
# Ne pas cr√©er de fichier de verrouillage ici pour √©viter les conflits

# Ex√©cution des tests de robustesse si demand√©
if [[ "${test_mode}" == "true" ]]; then
    log "INFO" "Ex√©cution en mode test..."

    # V√©rification des pr√©requis
    log "INFO" "V√©rification des pr√©requis..."
    verifier_prerequis

    # Extraction des informations d'inventaire
    extraire_informations_inventaire

    # Ex√©cution des tests de robustesse
    test_robustesse

    log "INFO" "Mode test termin√©"

    # Suppression du fichier de verrouillage
    rm -f "${LOCK_FILE}"

    exit 0
fi

# Ex√©cution des √©tapes d'installation
verifier_prerequis

# Extraction des informations d'inventaire
extraire_informations_inventaire

# Sauvegarde de l'√©tat initial (optionnelle)
backup_state "pre-installation" "true"

if [[ "${skip_init}" == "false" ]]; then
    initialiser_vps
else
    log "INFO" "Initialisation du VPS ignor√©e"
fi

installer_k3s

# Sauvegarde de l'√©tat apr√®s installation de K3s (optionnelle)
backup_state "post-k3s" "true"

deployer_infrastructure_base

# Sauvegarde de l'√©tat apr√®s d√©ploiement de l'infrastructure (optionnelle)
backup_state "post-infrastructure" "true"

deployer_monitoring

# Sauvegarde de l'√©tat apr√®s d√©ploiement du monitoring (optionnelle)
backup_state "post-monitoring" "true"

verifier_installation

# Affichage du r√©sum√©
echo -e "\n${COLOR_GREEN}${COLOR_BOLD}===========================================================${COLOR_RESET}"
echo -e "${COLOR_GREEN}${COLOR_BOLD}  Installation de l'infrastructure LIONS termin√©e avec succ√®s !${COLOR_RESET}"
echo -e "${COLOR_GREEN}${COLOR_BOLD}===========================================================${COLOR_RESET}\n"

log "INFO" "Pour acc√©der √† Grafana, utilisez l'URL: http://${ansible_host}:30000"
log "INFO" "Identifiant: admin"
log "INFO" "Mot de passe: admin"

log "INFO" "Pour acc√©der au Kubernetes Dashboard, utilisez l'URL: https://${ansible_host}:30001"
log "INFO" "Utilisez le token affich√© dans les logs d'installation pour vous connecter"
log "INFO" "Vous pouvez √©galement g√©n√©rer un nouveau token avec: kubectl create token dashboard-admin -n kubernetes-dashboard"

log "INFO" "Pour d√©ployer des applications, utilisez le script deploy.sh"

# G√©n√©ration d'un rapport final
report_file="${LOG_DIR}/installation-report-$(date +%Y%m%d-%H%M%S).txt"

{
    echo "=== RAPPORT D'INSTALLATION DE L'INFRASTRUCTURE LIONS ==="
    echo "Date: $(date)"
    echo "Environnement: ${environment}"
    echo ""

    echo "=== R√âSUM√â DE L'INSTALLATION ==="
    echo "‚úÖ Initialisation du VPS: R√©ussie"
    echo "‚úÖ Installation de K3s: R√©ussie"
    echo "‚úÖ D√©ploiement de l'infrastructure de base: R√©ussie"
    echo "‚úÖ D√©ploiement du monitoring: R√©ussie"
    echo "‚úÖ V√©rification de l'installation: R√©ussie"
    echo ""

    echo "=== INFORMATIONS D'ACC√àS ==="
    echo "Grafana: http://${ansible_host}:30000 (admin/admin)"
    echo "Kubernetes Dashboard: https://${ansible_host}:30001 (token requis)"
    echo ""

    echo "=== PROCHAINES √âTAPES ==="
    echo "1. Changer le mot de passe par d√©faut de Grafana"
    echo "2. Configurer les alertes dans Prometheus/Alertmanager"
    echo "3. D√©ployer vos applications avec le script deploy.sh"
    echo ""

    echo "=== FIN DU RAPPORT ==="
} > "${report_file}"

log "INFO" "Rapport d'installation g√©n√©r√©: ${report_file}"

# Suppression du fichier de verrouillage
rm -f "${LOCK_FILE}"

exit 0
