#!/bin/bash
# Titre: Script d'installation de l'infrastructure LIONS sur VPS
# Description: Orchestre l'installation compl√®te de l'infrastructure LIONS sur un VPS
# Auteur: √âquipe LIONS Infrastructure
# Date: 2023-05-15
# Version: 1.2.0
# Mise √† jour: Am√©lioration des performances, s√©curit√© et robustesse

# Configuration stricte
set -o errexit    # Arr√™t sur erreur
set -o pipefail   # Propagation des erreurs dans les pipes
set -o nounset    # Erreur sur variable non d√©finie

# Configuration des chemins et fichiers
readonly SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
readonly PROJECT_ROOT="$(cd "${SCRIPT_DIR}/.." && pwd)"
readonly ANSIBLE_DIR="${PROJECT_ROOT}/ansible"
readonly LOG_DIR="./logs/infrastructure"
readonly LOG_FILE="${LOG_DIR}/install-$(date +%Y%m%d-%H%M%S).log"
readonly DEFAULT_ENV="development"
readonly BACKUP_DIR="${LOG_DIR}/backups"
readonly STATE_FILE="${LOG_DIR}/.installation_state"
readonly LOCK_FILE="/tmp/lions_install.lock"
readonly CACHE_DIR="/tmp/.lions_cache"
readonly SSH_CONTROL_PATH="/tmp/ssh_control_master_${RANDOM}"

# Configuration des ressources
readonly REQUIRED_SPACE_MB=5000  # 5 Go d'espace disque requis
readonly TIMEOUT_SECONDS=1800    # 30 minutes de timeout pour les commandes longues
readonly SSH_TIMEOUT=10          # 10 secondes pour les op√©rations SSH
readonly PARALLEL_LIMIT=4        # Limite pour les op√©rations parall√®les

# Ports requis
readonly REQUIRED_PORTS=(22 22225 80 443 6443 30000 30001)

# Couleurs pour l'affichage
readonly COLOR_RESET="\033[0m"
readonly COLOR_RED="\033[0;31m"
readonly COLOR_GREEN="\033[0;32m"
readonly COLOR_YELLOW="\033[0;33m"
readonly COLOR_BLUE="\033[0;34m"
readonly COLOR_MAGENTA="\033[0;35m"
readonly COLOR_CYAN="\033[0;36m"
readonly COLOR_WHITE="\033[0;37m"
readonly COLOR_BOLD="\033[1m"

# Variables globales
INSTALLATION_STEP=""
LAST_COMMAND=""
LAST_ERROR=""
RETRY_COUNT=0
MAX_RETRIES=3
START_TIME=$(date +%s)
SSH_MASTER_STARTED=false

# Tableaux associatifs pour le cache
declare -A CACHE_SSH_COMMANDS
declare -A CACHE_KUBECTL_COMMANDS
declare -A PERFORMANCE_METRICS

# Cr√©ation des r√©pertoires n√©cessaires
mkdir -p "${LOG_DIR}" "${BACKUP_DIR}" "${CACHE_DIR}"

# Gestionnaire de signaux am√©lior√©
trap 'handle_signal TERM' TERM
trap 'handle_signal INT' INT
trap 'handle_signal EXIT' EXIT
trap 'handle_error ${LINENO} "${COMMAND_NAME:-unknown}"' ERR

# Fonction de gestion des signaux
function handle_signal() {
    local signal="$1"

    case "${signal}" in
        "TERM"|"INT")
            log "WARNING" "Signal ${signal} re√ßu, nettoyage en cours..."
            cleanup
            exit 1
            ;;
        "EXIT")
            cleanup
            ;;
    esac
}

# Fonction de nettoyage am√©lior√©e
function cleanup() {
    # D√©sactivation temporaire du mode strict pour le nettoyage
    set +e

    # Fermeture des connexions SSH persistantes
    if [[ "${SSH_MASTER_STARTED}" == "true" ]]; then
        ssh -O exit -S "${SSH_CONTROL_PATH}" dummy 2>/dev/null || true
    fi

    # Nettoyage des fichiers temporaires
    rm -f "${SSH_CONTROL_PATH}"*
    rm -rf "${CACHE_DIR}"

    # Suppression du fichier de verrouillage
    if [[ -f "${LOCK_FILE}" ]]; then
        if ! rm -f "${LOCK_FILE}" 2>/dev/null; then
            sudo rm -f "${LOCK_FILE}" 2>/dev/null || true
        fi
    fi

    # Calcul du temps total d'ex√©cution
    local end_time=$(date +%s)
    local total_time=$((end_time - START_TIME))
    log "INFO" "Dur√©e totale d'ex√©cution: $((total_time / 60)) minutes et $((total_time % 60)) secondes"

    # Affichage des informations de diagnostic
    log "INFO" "Informations de diagnostic:"
    log "INFO" "- Derni√®re √©tape: ${INSTALLATION_STEP}"
    log "INFO" "- Derni√®re commande: ${LAST_COMMAND}"
    log "INFO" "- Derni√®re erreur: ${LAST_ERROR}"
    log "INFO" "- Fichier de log: ${LOG_FILE}"

    # Affichage des m√©triques de performance
    if [[ ${#PERFORMANCE_METRICS[@]} -gt 0 ]]; then
        log "INFO" "M√©triques de performance:"
        for key in "${!PERFORMANCE_METRICS[@]}"; do
            log "INFO" "  - ${key}: ${PERFORMANCE_METRICS[${key}]}ms"
        done
    fi

    log "INFO" "Nettoyage termin√©"

    # R√©activation du mode strict
    set -euo pipefail
}

# Fonction de logging am√©lior√©e avec filtrage des informations sensibles
function log() {
    local level="$1"
    local message="$2"
    local timestamp="$(date +"%Y-%m-%d %H:%M:%S")"
    local caller_info=""
    local log_color="${COLOR_RESET}"
    local log_prefix=""

    # Filtrage des informations sensibles
    local filtered_message="${message}"
    filtered_message="${filtered_message//:[0-9]{1,5}@/:****@}"  # Masquage des ports dans les URLs
    filtered_message="${filtered_message//--password [^ ]*/--password ****}"  # Masquage des mots de passe
    filtered_message="${filtered_message//token=[^ ]*/token=****}"  # Masquage des tokens

    # D√©termination de la fonction appelante et du num√©ro de ligne
    if [[ "${debug_mode:-false}" == "true" ]]; then
        local caller_function=$(caller 0 | awk '{print $2}')
        local caller_line=$(caller 0 | awk '{print $1}')

        if [[ -n "${caller_function}" && "${caller_function}" != "main" ]]; then
            caller_info=" [${caller_function}:${caller_line}]"
        else
            caller_info=" [ligne:${caller_line}]"
        fi
    fi

    # S√©lection de la couleur et du pr√©fixe en fonction du niveau
    case "${level}" in
        "INFO")     log_color="${COLOR_BLUE}"; log_prefix="‚ÑπÔ∏è " ;;
        "WARNING")  log_color="${COLOR_YELLOW}"; log_prefix="‚ö†Ô∏è " ;;
        "ERROR")    log_color="${COLOR_RED}"; log_prefix="‚ùå " ;;
        "DEBUG")    log_color="${COLOR_MAGENTA}"; log_prefix="üîç " ;;
        "SUCCESS")  log_color="${COLOR_GREEN}"; log_prefix="‚úÖ " ;;
        "STEP")     log_color="${COLOR_CYAN}${COLOR_BOLD}"; log_prefix="üîÑ " ;;
        "PERF")     log_color="${COLOR_WHITE}"; log_prefix="üìä " ;;
    esac

    # Affichage du message avec formatage
    echo -e "${log_color}${log_prefix}[${timestamp}] [${level}]${caller_info}${COLOR_RESET} ${filtered_message}"

    # Enregistrement dans le fichier de log (sans filtrage pour le diagnostic)
    echo "[${timestamp}] [${level}]${caller_info} ${message}" >> "${LOG_FILE}"

    # Enregistrement des messages importants dans des fichiers s√©par√©s
    case "${level}" in
        "ERROR")
            echo "[${timestamp}] [${level}]${caller_info} ${message}" >> "${LOG_DIR}/errors.log"
            ;;
        "WARNING")
            echo "[${timestamp}] [${level}]${caller_info} ${message}" >> "${LOG_DIR}/warnings.log"
            ;;
        "STEP")
            echo "[${timestamp}] [${level}]${caller_info} ${message}" >> "${LOG_DIR}/steps.log"
            ;;
        "PERF")
            echo "[${timestamp}] [${level}]${caller_info} ${message}" >> "${LOG_DIR}/performance.log"
            ;;
    esac
}

# Fonction pour mesurer les performances
function measure_performance() {
    local operation_name="$1"
    local start_time=$(date +%s%3N)

    # Ex√©cuter la commande pass√©e en argument
    shift
    "$@"
    local exit_code=$?

    local end_time=$(date +%s%3N)
    local duration=$((end_time - start_time))

    PERFORMANCE_METRICS["${operation_name}"]="${duration}"
    log "PERF" "${operation_name}: ${duration}ms"

    return ${exit_code}
}

# Configuration SSH optimis√©e avec connexions persistantes
function setup_ssh_connection() {
    local host="${ansible_host}"
    local port="${ansible_port}"
    local user="${ansible_user}"

    if [[ -n "${host}" && -n "${port}" && -n "${user}" ]]; then
        log "INFO" "Configuration de la connexion SSH persistante vers ${user}@${host}:${port}"

        # D√©marrage du master SSH
        ssh -o ControlMaster=yes \
            -o ControlPath="${SSH_CONTROL_PATH}" \
            -o ControlPersist=10m \
            -o BatchMode=yes \
            -o ConnectTimeout=${SSH_TIMEOUT} \
            -p "${port}" \
            "${user}@${host}" \
            "echo 'Master SSH √©tabli'" &>/dev/null &

        # Attendre que la connexion soit √©tablie
        local retry=0
        while [[ ${retry} -lt 30 ]]; do
            if ssh -o ControlPath="${SSH_CONTROL_PATH}" \
                   -o BatchMode=yes \
                   -p "${port}" \
                   "${user}@${host}" \
                   "exit" &>/dev/null; then
                SSH_MASTER_STARTED=true
                log "SUCCESS" "Connexion SSH persistante √©tablie"
                return 0
            fi
            sleep 0.2
            ((retry++))
        done

        log "WARNING" "Impossible d'√©tablir une connexion SSH persistante"
    fi

    return 1
}

# Fonction SSH optimis√©e avec cache et r√©utilisation des connexions
function ssh_exec() {
    local command="$1"
    local cache_key="${command:0:50}"
    local use_cache="${2:-true}"
    local timeout="${3:-${SSH_TIMEOUT}}"

    # V√©rification du cache si demand√©
    if [[ "${use_cache}" == "true" && -n "${CACHE_SSH_COMMANDS[${cache_key}]}" ]]; then
        log "DEBUG" "Utilisation du cache pour: ${cache_key}"
        echo "${CACHE_SSH_COMMANDS[${cache_key}]}"
        return 0
    fi

    # Configuration SSH optimis√©e
    local ssh_opts=(
        "-o" "ControlPath=${SSH_CONTROL_PATH}"
        "-o" "BatchMode=yes"
        "-o" "ConnectTimeout=${timeout}"
        "-o" "ServerAliveInterval=30"
        "-o" "ServerAliveCountMax=3"
        "-p" "${ansible_port}"
    )

    # Ex√©cution avec gestion d'erreur
    local output
    local exit_code

    if [[ "${SSH_MASTER_STARTED}" == "true" ]]; then
        # Utilisation de la connexion persistante
        output=$(ssh "${ssh_opts[@]}" "${ansible_user}@${ansible_host}" "${command}" 2>/dev/null)
        exit_code=$?
    else
        # Fallback sans connexion persistante
        output=$(ssh "${ssh_opts[@]}" "${ansible_user}@${ansible_host}" "${command}" 2>/dev/null)
        exit_code=$?
    fi

    # Mise en cache du r√©sultat si succ√®s
    if [[ ${exit_code} -eq 0 && "${use_cache}" == "true" ]]; then
        CACHE_SSH_COMMANDS[${cache_key}]="${output}"
    fi

    echo "${output}"
    return ${exit_code}
}

# Fonction pour ex√©cuter des commandes en parall√®le avec limite
function parallel_exec() {
    local limit="${1:-${PARALLEL_LIMIT}}"
    local pids=()
    local commands=("${@:2}")
    local count=0

    for cmd in "${commands[@]}"; do
        # Ex√©cution en arri√®re-plan
        eval "${cmd}" &
        pids+=($!)

        ((count++))

        # V√©rification de la limite de processus parall√®les
        if [[ ${count} -ge ${limit} ]]; then
            # Attendre qu'au moins un processus se termine
            wait -n

            # Nettoyage des PID termin√©s
            local new_pids=()
            for pid in "${pids[@]}"; do
                if kill -0 "${pid}" 2>/dev/null; then
                    new_pids+=("${pid}")
                fi
            done
            pids=("${new_pids[@]}")

            count=${#pids[@]}
        fi
    done

    # Attendre que tous les processus se terminent
    for pid in "${pids[@]}"; do
        wait "${pid}" || log "WARNING" "Processus ${pid} a √©chou√©"
    done
}

# Fonction optimis√©e pour v√©rifier si une commande existe
function command_exists() {
    local cmd="$1"
    command -v "${cmd}" &>/dev/null
}

# Fonction am√©lior√©e pour installer les commandes manquantes avec parall√©lisation
function install_missing_commands() {
    local commands=("$@")
    local os_name=$(uname -s)
    local success=true

    log "INFO" "D√©tection du syst√®me d'exploitation: ${os_name}"

    # D√©tection du gestionnaire de paquets avec cache
    local pkg_manager
    local install_cmd

    # Utilisation du cache pour la d√©tection du gestionnaire de paquets
    if [[ -f "${CACHE_DIR}/pkg_manager" ]]; then
        pkg_manager=$(cat "${CACHE_DIR}/pkg_manager")
        install_cmd=$(cat "${CACHE_DIR}/install_cmd")
    else
        # D√©tection et mise en cache
        if [[ "${os_name}" == "Linux" ]]; then
            for manager in "apt-get" "dnf" "yum" "pacman" "zypper"; do
                if command_exists "${manager}"; then
                    case "${manager}" in
                        "apt-get") pkg_manager="apt"; install_cmd="apt-get install -y" ;;
                        "dnf") pkg_manager="dnf"; install_cmd="dnf install -y" ;;
                        "yum") pkg_manager="yum"; install_cmd="yum install -y" ;;
                        "pacman") pkg_manager="pacman"; install_cmd="pacman -S --noconfirm" ;;
                        "zypper") pkg_manager="zypper"; install_cmd="zypper install -y" ;;
                    esac
                    echo "${pkg_manager}" > "${CACHE_DIR}/pkg_manager"
                    echo "${install_cmd}" > "${CACHE_DIR}/install_cmd"
                    break
                fi
            done
        elif [[ "${os_name}" == "Darwin" ]]; then
            if command_exists brew; then
                pkg_manager="brew"
                install_cmd="brew install"
                echo "${pkg_manager}" > "${CACHE_DIR}/pkg_manager"
                echo "${install_cmd}" > "${CACHE_DIR}/install_cmd"
            fi
        fi

        if [[ -z "${pkg_manager}" ]]; then
            log "ERROR" "Gestionnaire de paquets non reconnu sur ce syst√®me"
            return 1
        fi
    fi

    log "INFO" "Utilisation du gestionnaire de paquets: ${pkg_manager}"

    # Mise √† jour des d√©p√¥ts avec cache
    if [[ ! -f "${CACHE_DIR}/repos_updated" ]]; then
        log "INFO" "Mise √† jour des d√©p√¥ts ${pkg_manager}..."
        case "${pkg_manager}" in
            "apt")
                sudo apt-get update &>/dev/null
                ;;
            "dnf"|"yum")
                sudo ${pkg_manager} check-update &>/dev/null || true
                ;;
            "brew")
                brew update &>/dev/null
                ;;
        esac
        touch "${CACHE_DIR}/repos_updated"
    fi

    # Installation des commandes manquantes avec parall√©lisation limit√©e
    local install_commands=()
    for cmd in "${commands[@]}"; do
        local pkg_name=$(get_package_name "${cmd}" "${pkg_manager}")

        log "INFO" "Pr√©paration de l'installation de: ${pkg_name}"
        install_commands+=("sudo ${install_cmd} ${pkg_name} &>/dev/null")
    done

    # Ex√©cution parall√®le avec limite
    parallel_exec 2 "${install_commands[@]}"

    # V√©rification post-installation
    for cmd in "${commands[@]}"; do
        if ! command_exists "${cmd}"; then
            log "ERROR" "√âchec de l'installation de ${cmd}"
            success=false
        else
            log "SUCCESS" "Installation de ${cmd} r√©ussie"
        fi
    done

    return $( [[ "${success}" == "true" ]] && echo 0 || echo 1 )
}

# Fonction pour obtenir le nom du paquet selon le gestionnaire
function get_package_name() {
    local cmd="$1"
    local pkg_manager="$2"

    case "${cmd}" in
        "jq") echo "jq" ;;
        "ansible-playbook") echo "ansible" ;;
        "kubectl")
            if [[ "${pkg_manager}" == "apt" ]]; then
                # Configuration du d√©p√¥t Kubernetes pour apt
                if [[ ! -f "${CACHE_DIR}/kubectl_repo_configured" ]]; then
                    sudo curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
                    echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
                    sudo apt-get update
                    touch "${CACHE_DIR}/kubectl_repo_configured"
                fi
                echo "kubectl"
            elif [[ "${pkg_manager}" == "brew" ]]; then
                echo "kubernetes-cli"
            else
                echo "kubectl"
            fi
            ;;
        "helm")
            if [[ "${pkg_manager}" == "apt" ]]; then
                # Configuration du d√©p√¥t Helm pour apt
                if [[ ! -f "${CACHE_DIR}/helm_repo_configured" ]]; then
                    curl https://baltocdn.com/helm/signing.asc | sudo apt-key add -
                    echo "deb https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
                    sudo apt-get update
                    touch "${CACHE_DIR}/helm_repo_configured"
                fi
                echo "helm"
            else
                echo "helm"
            fi
            ;;
        "timeout") echo "coreutils" ;;
        "nc") echo "netcat" ;;
        "ping")
            if [[ "${pkg_manager}" == "apt" ]]; then
                echo "iputils-ping"
            else
                echo "iputils"
            fi
            ;;
        "ssh"|"scp") echo "openssh-client" ;;
        *) echo "${cmd}" ;;
    esac
}

# Fonction pour extraire les informations d'inventaire avec cache
function extraire_informations_inventaire() {
    local inventory_path="${ANSIBLE_DIR}/${inventory_file}"
    local cache_file="${CACHE_DIR}/inventory_info_${inventory_file//\//_}"

    log "INFO" "Extraction des informations d'inventaire depuis ${inventory_file}..."

    # V√©rification du cache
    if [[ -f "${cache_file}" && "${inventory_path}" -ot "${cache_file}" ]]; then
        log "DEBUG" "Utilisation du cache pour les informations d'inventaire"
        source "${cache_file}"
        log "INFO" "Informations d'inventaire extraites (cache):"
        log "INFO" "- H√¥te: ${ansible_host}"
        log "INFO" "- Port: ${ansible_port}"
        log "INFO" "- Utilisateur: ${ansible_user}"
        return 0
    fi

    # V√©rification de l'existence du fichier d'inventaire
    if [[ ! -f "${inventory_path}" ]]; then
        log "ERROR" "Fichier d'inventaire non trouv√©: ${inventory_path}"
        cleanup
        exit 1
    fi

    # Extraction optimis√©e avec Python
    local python_script=$(cat << 'EOF'
import sys
import yaml
import json

try:
    with open(sys.argv[1], 'r') as f:
        inventory = yaml.safe_load(f)

    result = {"ansible_host": None, "ansible_port": 22, "ansible_user": None}

    # Recherche dans la structure d'inventaire
    if 'all' in inventory:
        if 'children' in inventory['all'] and 'vps' in inventory['all']['children']:
            vps_hosts = inventory['all']['children']['vps'].get('hosts', {})
            if vps_hosts:
                first_host = next(iter(vps_hosts))
                host_info = vps_hosts[first_host]
                result["ansible_host"] = host_info.get('ansible_host')
                result["ansible_port"] = host_info.get('ansible_port', 22)
                result["ansible_user"] = host_info.get('ansible_user')

        # Variables globales
        if 'vars' in inventory['all'] and not result["ansible_user"]:
            result["ansible_user"] = inventory['all']['vars'].get('ansible_user')

    # Sortie format√©e pour le cache
    for key, value in result.items():
        if value:
            print(f"{key}={value}")

except Exception as e:
    print(f"error={str(e)}", file=sys.stderr)
    sys.exit(1)
EOF
)

    # Ex√©cution avec gestion d'erreur am√©lior√©e
    local output
    if command_exists python3; then
        output=$(timeout 10 python3 -c "${python_script}" "${inventory_path}" 2>/dev/null)
    else
        # Fallback avec grep et awk
        log "WARNING" "Python3 non disponible, utilisation du fallback grep/awk"
        output="ansible_host=$(grep -A10 'hosts:' "${inventory_path}" | grep 'ansible_host:' | head -1 | awk -F': ' '{print $2}' | tr -d ' ')
ansible_port=$(grep -A10 'hosts:' "${inventory_path}" | grep 'ansible_port:' | head -1 | awk -F': ' '{print $2}' | tr -d ' ')
ansible_user=$(grep -A10 'hosts:' "${inventory_path}" | grep 'ansible_user:' | head -1 | awk -F': ' '{print $2}' | tr -d ' ')"
    fi

    # Traitement de la sortie
    eval "${output}"

    # Valeurs par d√©faut
    ansible_host="${ansible_host:-localhost}"
    ansible_port="${ansible_port:-22}"
    ansible_user="${ansible_user:-$(whoami)}"

    # Mise en cache
    cat > "${cache_file}" << EOF
ansible_host="${ansible_host}"
ansible_port="${ansible_port}"
ansible_user="${ansible_user}"
EOF

    log "INFO" "Informations d'inventaire extraites:"
    log "INFO" "- H√¥te: ${ansible_host}"
    log "INFO" "- Port: ${ansible_port}"
    log "INFO" "- Utilisateur: ${ansible_user}"

    return 0
}

# Fonction pour ex√©cuter une commande avec timeout et retry am√©lior√©
function run_with_timeout() {
    local cmd="$1"
    local timeout="${2:-${TIMEOUT_SECONDS}}"
    local cmd_type="${3:-generic}"
    local max_retries=3
    local retry_count=0
    local backoff_time=5
    local interactive=false

    # D√©tection des commandes interactives
    if [[ "${cmd}" =~ (--(ask-become-pass|ask-pass)|[-]K|[-]k) ]]; then
        interactive=true
        log "INFO" "Commande interactive d√©tect√©e"
    fi

    log "INFO" "Ex√©cution de la commande avec timeout ${timeout}s: $(echo "${cmd}" | head -c 100)..."
    LAST_COMMAND="${cmd}"
    COMMAND_NAME="${cmd_type}"

    # Sauvegarde de l'√©tat
    echo "${INSTALLATION_STEP}" > "${STATE_FILE}"

    # Fonction de v√©rification des erreurs r√©seau
    function is_network_error() {
        local output="$1"
        local exit_code="$2"

        [[ ${exit_code} -eq 124 || ${exit_code} -eq 255 ]] && return 0
        echo "${output}" | grep -qE "(Connection (refused|timed out|reset by peer)|Network is unreachable|Unable to connect|Temporary failure in name resolution|Could not resolve host|Network error)"
    }

    # Boucle avec retry
    while true; do
        # V√©rification de la connectivit√© avant l'ex√©cution pour les commandes SSH/Ansible
        if [[ "${cmd_type}" =~ (ansible_playbook|ssh) ]]; then
            if ! measure_performance "network_check" ping -c 1 -W 5 "${ansible_host}" &>/dev/null; then
                if [[ ${retry_count} -lt ${max_retries} ]]; then
                    ((retry_count++))
                    log "WARNING" "Connectivit√© r√©seau perdue avec le VPS. Tentative ${retry_count}/${max_retries} dans ${backoff_time}s..."
                    sleep ${backoff_time}
                    backoff_time=$((backoff_time * 2))
                    continue
                else
                    log "ERROR" "Connectivit√© r√©seau perdue apr√®s ${max_retries} tentatives"
                    return 1
                fi
            fi
        fi

        # Ex√©cution de la commande
        log "DEBUG" "D√©but de l'ex√©cution..."

        local exit_code=0
        local command_output=""

        # Mesure de performance
        local start_time=$(date +%s%3N)

        if [[ "${interactive}" == "true" ]]; then
            # Commandes interactives
            log "INFO" "Ex√©cution de la commande interactive..."
            timeout ${timeout} bash -c "${cmd}"
            exit_code=$?
        else
            # Commandes non-interactives
            local temp_output=$(mktemp)
            timeout ${timeout} bash -c "${cmd}" &> "${temp_output}"
            exit_code=$?
            command_output=$(cat "${temp_output}")
            rm -f "${temp_output}"
        fi

        local end_time=$(date +%s%3N)
        local duration=$((end_time - start_time))
        PERFORMANCE_METRICS["${cmd_type}_execution"]="${duration}"

        # Logging de la sortie en mode debug
        if [[ "${debug_mode:-false}" == "true" && -n "${command_output}" ]]; then
            log "DEBUG" "Sortie de la commande:"
            echo "${command_output}" | while IFS= read -r line; do
                log "DEBUG" "  ${line}"
            done
        fi

        # Gestion des erreurs avec retry pour les erreurs r√©seau
        if [[ ${exit_code} -ne 0 ]]; then
            if [[ "${interactive}" == "false" && $(is_network_error "${command_output}" ${exit_code}) ]]; then
                if [[ ${retry_count} -lt ${max_retries} ]]; then
                    ((retry_count++))
                    log "WARNING" "Erreur r√©seau d√©tect√©e (code ${exit_code}). Tentative ${retry_count}/${max_retries} dans ${backoff_time}s..."
                    sleep ${backoff_time}
                    backoff_time=$((backoff_time * 2))
                    continue
                fi
            fi

            # Analyse des erreurs
            case ${exit_code} in
                124)
                    log "ERROR" "Timeout atteint (${timeout}s)"
                    ;;
                *)
                    log "ERROR" "Commande √©chou√©e avec le code ${exit_code}"

                    # Diagnostic sp√©cifique pour les commandes non-interactives
                    if [[ "${interactive}" == "false" && -n "${command_output}" ]]; then
                        case "${command_output}" in
                            *"Connection refused"*)
                                log "ERROR" "Service non accessible"
                                ;;
                            *"Permission denied"*)
                                log "ERROR" "Permissions insuffisantes"
                                ;;
                            *"No space left on device"*)
                                log "ERROR" "Espace disque insuffisant"
                                ;;
                            *"Unable to connect to the server"*)
                                log "ERROR" "Serveur Kubernetes inaccessible"
                                ;;
                        esac
                    fi
                    ;;
            esac

            return ${exit_code}
        fi

        # Succ√®s
        if [[ ${retry_count} -gt 0 ]]; then
            log "SUCCESS" "Commande r√©ussie apr√®s ${retry_count} tentatives"
        else
            log "DEBUG" "Commande r√©ussie"
        fi

        return 0
    done
}

# Fonction pour v√©rifier les ressources syst√®me (optimis√©e)
function check_system_resources() {
    local system_type="$1"  # "local" ou "vps"
    local host="${ansible_host:-localhost}"

    log "INFO" "V√©rification des ressources ${system_type}..."

    # Fonction pour ex√©cuter des commandes selon le syst√®me
    function exec_command() {
        local cmd="$1"
        if [[ "${system_type}" == "local" ]]; then
            eval "${cmd}"
        else
            ssh_exec "${cmd}" false 5
        fi
    }

    # V√©rification des ressources en parall√®le
    local checks=(
        "memory_check"
        "disk_check"
        "cpu_check"
    )

    for check in "${checks[@]}"; do
        case "${check}" in
            "memory_check")
                local memory_info=$(exec_command "free -m")
                local total_memory=$(echo "${memory_info}" | awk '/^Mem:/ {print $2}')
                local available_memory=$(echo "${memory_info}" | awk '/^Mem:/ {print $7}')

                log "INFO" "M√©moire ${system_type}: ${available_memory}MB disponible sur ${total_memory}MB total"

                # Seuils adapt√©s selon le syst√®me
                local min_memory=$( [[ "${system_type}" == "local" ]] && echo 1024 || echo 2048 )

                if [[ ${available_memory} -lt ${min_memory} ]]; then
                    log "WARNING" "M√©moire ${system_type} insuffisante: ${available_memory}MB (minimum: ${min_memory}MB)"
                fi
                ;;

            "disk_check")
                local disk_info=$(exec_command "df -m /")
                local available_disk=$(echo "${disk_info}" | awk 'NR==2 {print $4}')

                log "INFO" "Espace disque ${system_type}: ${available_disk}MB disponible"

                if [[ ${available_disk} -lt ${REQUIRED_SPACE_MB} ]]; then
                    log "ERROR" "Espace disque ${system_type} insuffisant: ${available_disk}MB (minimum: ${REQUIRED_SPACE_MB}MB)"
                    return 1
                fi
                ;;

            "cpu_check")
                local cpu_count=$(exec_command "nproc --all")
                local cpu_load=$(exec_command "cat /proc/loadavg | awk '{print \$1}'")

                log "INFO" "CPU ${system_type}: ${cpu_count} c≈ìurs, charge: ${cpu_load}"

                if [[ ${cpu_count} -lt 2 ]]; then
                    log "WARNING" "Nombre de c≈ìurs ${system_type} insuffisant: ${cpu_count}"
                fi

                # V√©rification de la charge CPU
                if (( $(echo "${cpu_load} > ${cpu_count}" | bc -l) )); then
                    log "WARNING" "Charge CPU ${system_type} √©lev√©e: ${cpu_load}"
                fi
                ;;
        esac
    done &

    wait

    log "SUCCESS" "V√©rification des ressources ${system_type} termin√©e"
    return 0
}

# Fonction optimis√©e pour v√©rifier la connectivit√© r√©seau
function check_network() {
    local target_host="${ansible_host}"
    local target_port="${ansible_port}"
    local retry_count=3
    local timeout=5

    log "INFO" "V√©rification de la connectivit√© r√©seau vers ${target_host}:${target_port}"

    # V√©rifications en parall√®le
    declare -A network_checks
    network_checks["dns"]=""
    network_checks["icmp"]=""
    network_checks["tcp"]=""

    # R√©solution DNS
    if [[ ! "${target_host}" =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
        for ((i=1; i<=retry_count; i++)); do
            if resolved_ip=$(dig +short "${target_host}" 2>/dev/null) && [[ -n "${resolved_ip}" ]]; then
                network_checks["dns"]="OK - ${target_host} -> ${resolved_ip}"
                break
            else
                if [[ ${i} -eq ${retry_count} ]]; then
                    network_checks["dns"]="FAILED - Unable to resolve ${target_host}"
                fi
                sleep 2
            fi
        done
    else
        network_checks["dns"]="SKIPPED - IP address used"
    fi

    # Test ICMP en parall√®le
    {
        for ((i=1; i<=retry_count; i++)); do
            if ping -c 1 -W ${timeout} "${target_host}" &>/dev/null; then
                network_checks["icmp"]="OK"
                break
            else
                if [[ ${i} -eq ${retry_count} ]]; then
                    network_checks["icmp"]="FAILED"
                fi
                sleep 1
            fi
        done
    } &

    # Test TCP en parall√®le
    {
        for ((i=1; i<=retry_count; i++)); do
            if nc -z -w ${timeout} "${target_host}" "${target_port}" &>/dev/null; then
                network_checks["tcp"]="OK"
                break
            else
                if [[ ${i} -eq ${retry_count} ]]; then
                    network_checks["tcp"]="FAILED"
                fi
                sleep 1
            fi
        done
    } &

    wait

    # V√©rification des ports requis en parall√®le
    declare -a port_checks=()
    for port in "${REQUIRED_PORTS[@]}"; do
        {
            if nc -z -w ${timeout} "${target_host}" "${port}" &>/dev/null; then
                port_checks[${port}]="OK"
            else
                port_checks[${port}]="FAILED"
            fi
        } &
    done

    wait

    # Rapport des r√©sultats
    log "INFO" "R√©sultats des v√©rifications r√©seau:"
    log "INFO" "  - DNS: ${network_checks["dns"]}"
    log "INFO" "  - ICMP: ${network_checks["icmp"]}"
    log "INFO" "  - TCP SSH: ${network_checks["tcp"]}"

    # V√©rification des ports
    local failed_ports=()
    for port in "${REQUIRED_PORTS[@]}"; do
        if [[ "${port_checks[${port}]}" == "FAILED" ]]; then
            failed_ports+=("${port}")
        fi
    done

    if [[ ${#failed_ports[@]} -gt 0 ]]; then
        log "WARNING" "Ports ferm√©s: ${failed_ports[*]}"

        # Proposition d'ouverture automatique
        log "INFO" "Souhaitez-vous ouvrir automatiquement ces ports? (o/N)"
        read -r answer
        if [[ "${answer}" =~ ^[Oo]$ ]]; then
            open_required_ports "${failed_ports[@]}"
        fi
    fi

    # V√©rification du port SSH (critique)
    if [[ "${network_checks["tcp"]}" == "FAILED" ]]; then
        log "ERROR" "Port SSH (${target_port}) inaccessible - impossible de continuer"
        return 1
    fi

    log "SUCCESS" "V√©rification de la connectivit√© r√©seau termin√©e"
    return 0
}

# Fonction am√©lior√©e pour sauvegarder l'√©tat
function backup_state() {
    local backup_name="${1:-backup-$(date +%Y%m%d-%H%M%S)}"
    local optional="${2:-false}"
    local backup_file="${BACKUP_DIR}/${backup_name}.tar.gz"
    local metadata_file="${BACKUP_DIR}/${backup_name}.json"

    log "INFO" "Sauvegarde de l'√©tat actuel dans ${backup_file}..."

    # Cr√©ation des m√©tadonn√©es d√©taill√©es
    cat > "${metadata_file}" << EOF
{
  "backup_name": "${backup_name}",
  "backup_date": "$(date -Iseconds)",
  "environment": "${environment}",
  "installation_step": "${INSTALLATION_STEP}",
  "ansible_host": "${ansible_host}",
  "ansible_port": "${ansible_port}",
  "ansible_user": "${ansible_user}",
  "script_version": "1.2.0",
  "description": "Sauvegarde automatique avant l'√©tape ${INSTALLATION_STEP}",
  "performance_metrics": $(echo "${PERFORMANCE_METRICS[@]}" | jq -R -s -c 'split(" ") | map(select(length > 0))')
}
EOF

    # Liste des r√©pertoires √† sauvegarder avec priorit√©s
    local backup_items=(
        "/etc/rancher:high"
        "/var/lib/rancher/k3s/server/manifests:high"
        "/home/${ansible_user}/.kube:medium"
        "/etc/systemd/system/k3s.service:medium"
        "/var/log/lions:low"
    )

    # Patterns d'exclusion optimis√©s
    local exclude_args=(
        "--exclude=*.log"
        "--exclude=*.tmp"
        "--exclude=*.swp"
        "--exclude=*/cache/*"
        "--exclude=*/temp/*"
    )

    # V√©rification de l'existence des r√©pertoires de mani√®re optimis√©e
    local existing_items=()
    local total_size=0

    for item in "${backup_items[@]}"; do
        local path="${item%%:*}"
        local priority="${item##*:}"

        # V√©rification en parall√®le
        {
            if ssh_exec "sudo test -d ${path}" false 5; then
                local size=$(ssh_exec "sudo du -s ${path} | awk '{print \$1}'" false 5)
                existing_items+=("${path}:${priority}:${size}")
                ((total_size+=size))
            fi
        } &
    done

    wait

    # Tri des items par priorit√© et taille
    IFS=$'\n' sorted_items=($(sort -t: -k2,2r -k3,3nr <<<"${existing_items[*]}"))
    unset IFS

    # Construction de la commande de sauvegarde optimis√©e
    local backup_cmd="sudo tar ${exclude_args[*]} -czf /tmp/${backup_name}.tar.gz"
    for item in "${sorted_items[@]}"; do
        backup_cmd="${backup_cmd} ${item%%:*}"
    done

    # Ajout d'informations compl√©mentaires
    backup_cmd="${backup_cmd} && sudo tar -rf /tmp/${backup_name}.tar.gz --transform 's,^,metadata/,' ${metadata_file}"

    # Estimation du temps de sauvegarde
    local estimated_time=$((total_size / 1000 / 10))  # ~10MB/s
    log "INFO" "Estimation: ~${estimated_time}s pour ${total_size}KB"

    # Ex√©cution de la sauvegarde avec barre de progression
    if measure_performance "backup_create" ssh_exec "${backup_cmd}" false 120; then
        # Transfert du fichier avec optimisation
        log "INFO" "Transfert du fichier de sauvegarde..."

        if measure_performance "backup_transfer" scp -C -P "${ansible_port}" \
           "${ansible_user}@${ansible_host}:/tmp/${backup_name}.tar.gz" "${backup_file}" 2>/dev/null; then

            # V√©rification de l'int√©grit√©
            local local_checksum=$(sha256sum "${backup_file}" | awk '{print $1}')
            local remote_checksum=$(ssh_exec "sha256sum /tmp/${backup_name}.tar.gz" false 5 | awk '{print $1}')

            if [[ "${local_checksum}" == "${remote_checksum}" ]]; then
                log "SUCCESS" "Sauvegarde cr√©√©e et v√©rifi√©e: ${backup_file}"

                # Nettoyage du fichier temporaire
                ssh_exec "sudo rm -f /tmp/${backup_name}.tar.gz" false 5

                # Ajout de la taille du fichier aux m√©tadonn√©es
                local backup_size=$(du -h "${backup_file}" | awk '{print $1}')
                jq ".backup_size = \"${backup_size}\"" "${metadata_file}" > "${metadata_file}.tmp" && mv "${metadata_file}.tmp" "${metadata_file}"

                # Nettoyage des anciennes sauvegardes (garder les 10 plus r√©centes)
                local old_backups=($(ls -t "${BACKUP_DIR}"/*.tar.gz 2>/dev/null | tail -n +11))
                if [[ ${#old_backups[@]} -gt 0 ]]; then
                    for old_backup in "${old_backups[@]}"; do
                        rm -f "${old_backup}" "${old_backup%.tar.gz}.json"
                    done
                    log "INFO" "Nettoyage de ${#old_backups[@]} anciennes sauvegardes"
                fi

                echo "${backup_name}" > "${BACKUP_DIR}/.last_backup"
                return 0
            else
                log "ERROR" "Corruption d√©tect√©e lors du transfert"
            fi
        fi
    fi

    # Nettoyage en cas d'erreur
    ssh_exec "sudo rm -f /tmp/${backup_name}.tar.gz" false 5
    rm -f "${backup_file}" "${metadata_file}"

    if [[ "${optional}" == "true" ]]; then
        log "WARNING" "Sauvegarde optionnelle √©chou√©e, continuation"
        return 0
    else
        return 1
    fi
}

# Fonction de v√©rification des pr√©requis (optimis√©e)
function verifier_prerequis() {
    log "STEP" "V√©rification des pr√©requis..."
    INSTALLATION_STEP="prerequis"

    # Gestion du verrouillage avec PID
    if [[ -f "${LOCK_FILE}" ]]; then
        local lock_pid=$(cat "${LOCK_FILE}" 2>/dev/null || echo "")

        if [[ -n "${lock_pid}" ]] && kill -0 "${lock_pid}" 2>/dev/null; then
            log "ERROR" "Une autre instance est en cours d'ex√©cution (PID: ${lock_pid})"
            exit 1
        else
            log "INFO" "Fichier de verrouillage obsol√®te, suppression"
            sudo rm -f "${LOCK_FILE}" 2>/dev/null || rm -f "${LOCK_FILE}"
        fi
    fi

    # Cr√©ation du fichier de verrouillage avec PID
    echo $$ > "${LOCK_FILE}"

    # V√©rifications syst√®me locales
    check_system_resources "local"

    # V√©rification des commandes requises avec versions
    local required_commands=(
        "ansible-playbook:2.9.0"
        "ssh:7.0"
        "kubectl:1.20.0"
        "helm:3.5.0"
        "jq:1.6"
        "timeout"
        "nc"
        "ping"
    )

    local missing_commands=()
    for cmd_spec in "${required_commands[@]}"; do
        local cmd="${cmd_spec%%:*}"
        if ! command_exists "${cmd}"; then
            missing_commands+=("${cmd}")
        fi
    done

    if [[ ${#missing_commands[@]} -gt 0 ]]; then
        log "WARNING" "Commandes manquantes: ${missing_commands[*]}"
        install_missing_commands "${missing_commands[@]}"
    fi

    # Extraction des informations d'inventaire avec cache
    extraire_informations_inventaire

    # Configuration de la connexion SSH persistante
    setup_ssh_connection

    # V√©rification de la connectivit√© r√©seau
    check_network

    # V√©rification des ressources du VPS
    check_system_resources "vps"

    # Gestion de la reprise
    if [[ -f "${STATE_FILE}" ]]; then
        local previous_step=$(cat "${STATE_FILE}")
        log "INFO" "√âtat pr√©c√©dent d√©tect√©: ${previous_step}"
        log "INFO" "Voulez-vous reprendre √† partir de cette √©tape? (o/N)"

        read -r answer
        if [[ "${answer}" =~ ^[Oo]$ ]]; then
            log "INFO" "Reprise √† partir de l'√©tape: ${previous_step}"
            resume_installation "${previous_step}"
        else
            log "INFO" "Nouvelle installation"
            rm -f "${STATE_FILE}"
        fi
    fi

    log "SUCCESS" "Pr√©requis v√©rifi√©s avec succ√®s"
}

# Fonction pour reprendre l'installation
function resume_installation() {
    local step="$1"

    case "${step}" in
        "init_vps")
            initialiser_vps
            installer_k3s
            deployer_infrastructure_base
            deployer_monitoring
            verifier_installation
            ;;
        "install_k3s")
            installer_k3s
            deployer_infrastructure_base
            deployer_monitoring
            verifier_installation
            ;;
        "deploy_infra")
            deployer_infrastructure_base
            deployer_monitoring
            verifier_installation
            ;;
        "deploy_monitoring")
            deployer_monitoring
            verifier_installation
            ;;
        "deploy_services")
            deployer_services_infrastructure
            verifier_installation
            ;;
        "verify")
            verifier_installation
            ;;
        *)
            log "WARNING" "√âtape inconnue: ${step}, reprise depuis le d√©but"
            ;;
    esac

    exit 0
}

# Fonction d'initialisation du VPS (optimis√©e)
function initialiser_vps() {
    log "STEP" "Initialisation du VPS..."
    INSTALLATION_STEP="init_vps"
    echo "${INSTALLATION_STEP}" > "${STATE_FILE}"

    # Sauvegarde de l'√©tat actuel
    backup_state "pre-init-vps" "true"

    # Construction et ex√©cution de la commande Ansible
    local ansible_cmd="ansible-playbook -i ${ANSIBLE_DIR}/${inventory_file} ${ANSIBLE_DIR}/playbooks/init-vps.yml --ask-become-pass"

    [[ "${debug_mode:-false}" == "true" ]] && ansible_cmd="${ansible_cmd} -vvv"

    log "INFO" "Ex√©cution: ${ansible_cmd}"
    LAST_COMMAND="${ansible_cmd}"

    if measure_performance "vps_init" run_with_timeout "${ansible_cmd}" "${TIMEOUT_SECONDS}" "ansible_playbook"; then
        log "SUCCESS" "Initialisation du VPS termin√©e avec succ√®s"

        # V√©rification post-installation
        local services_to_check=("sshd" "fail2ban" "ufw")
        local failed_services=()

        for service in "${services_to_check[@]}"; do
            if ! ssh_exec "sudo systemctl is-active --quiet ${service}" false 5; then
                failed_services+=("${service}")
            fi
        done

        if [[ ${#failed_services[@]} -gt 0 ]]; then
            log "WARNING" "Services non actifs: ${failed_services[*]}"
        else
            log "SUCCESS" "Tous les services essentiels sont actifs"
        fi
    else
        log "ERROR" "√âchec de l'initialisation du VPS"
        collect_logs
        exit 1
    fi
}

# Fonction d'installation de K3s (optimis√©e)
function installer_k3s() {
    log "STEP" "Installation de K3s..."
    INSTALLATION_STEP="install_k3s"
    echo "${INSTALLATION_STEP}" > "${STATE_FILE}"

    # Sauvegarde de l'√©tat actuel
    backup_state "pre-install-k3s" "true"

    # Construction et ex√©cution de la commande Ansible
    local ansible_cmd="ansible-playbook -i ${ANSIBLE_DIR}/${inventory_file} ${ANSIBLE_DIR}/playbooks/install-k3s.yml --ask-become-pass"

    [[ "${debug_mode:-false}" == "true" ]] && ansible_cmd="${ansible_cmd} -vvv"

    log "INFO" "Ex√©cution: ${ansible_cmd}"
    LAST_COMMAND="${ansible_cmd}"

    if measure_performance "k3s_install" run_with_timeout "${ansible_cmd}" 3600 "ansible_playbook"; then
        log "SUCCESS" "Installation de K3s termin√©e avec succ√®s"

        # V√©rification de K3s
        if ssh_exec "sudo systemctl is-active --quiet k3s" false 5; then
            log "SUCCESS" "Service K3s actif"

            # R√©cup√©ration du kubeconfig si n√©cessaire
            local kubeconfig_dir="${HOME}/.kube"
            mkdir -p "${kubeconfig_dir}"

            if ! kubectl cluster-info &>/dev/null; then
                log "INFO" "R√©cup√©ration du fichier kubeconfig..."
                if scp -C -P "${ansible_port}" "${ansible_user}@${ansible_host}:/home/${ansible_user}/.kube/config" "${kubeconfig_dir}/config.k3s" &>/dev/null; then
                    export KUBECONFIG="${kubeconfig_dir}/config.k3s"
                    log "SUCCESS" "Kubeconfig configur√©"
                else
                    log "WARNING" "Impossible de r√©cup√©rer le kubeconfig"
                fi
            fi
        else
            log "ERROR" "Service K3s inactif"
            ssh_exec "sudo journalctl -u k3s --no-pager -n 50"
            exit 1
        fi
    else
        log "ERROR" "√âchec de l'installation de K3s"
        collect_logs
        exit 1
    fi
}

# Fonction de d√©ploiement de l'infrastructure de base (optimis√©e)
function deployer_infrastructure_base() {
    log "STEP" "D√©ploiement de l'infrastructure de base..."
    INSTALLATION_STEP="deploy_infra"
    echo "${INSTALLATION_STEP}" > "${STATE_FILE}"

    # V√©rification de l'acc√®s √† Kubernetes
    if ! kubectl cluster-info &>/dev/null; then
        log "ERROR" "Impossible d'acc√©der au cluster Kubernetes"
        exit 1
    fi

    # Cr√©ation du namespace
    kubectl create namespace lions-infrastructure --dry-run=client -o yaml | kubectl apply -f - || true

    # Validation et application de kustomize
    log "INFO" "Validation de la configuration kustomize..."
    if kubectl kustomize "${PROJECT_ROOT}/kubernetes/overlays/${environment}" > /dev/null; then
        log "INFO" "D√©ploiement des ressources..."

        if measure_performance "infra_deploy" kubectl apply -k "${PROJECT_ROOT}/kubernetes/overlays/${environment}" --timeout=5m; then
            log "SUCCESS" "Infrastructure de base d√©ploy√©e"

            # V√©rification des ressources essentielles
            local essential_resources=(
                "namespace/${environment}"
                "resourcequota/compute-resources"
                "networkpolicy/default-network-policy"
            )

            for resource in "${essential_resources[@]}"; do
                if kubectl get "${resource}" &>/dev/null; then
                    log "SUCCESS" "Ressource ${resource} cr√©√©e"
                else
                    log "WARNING" "Ressource ${resource} manquante"
                fi
            done
        else
            log "ERROR" "√âchec du d√©ploiement de l'infrastructure"
            exit 1
        fi
    else
        log "ERROR" "Configuration kustomize invalide"
        exit 1
    fi
}

# Fonction de d√©ploiement du monitoring (optimis√©e)
function deployer_monitoring() {
    log "STEP" "D√©ploiement du syst√®me de monitoring..."
    INSTALLATION_STEP="deploy_monitoring"
    echo "${INSTALLATION_STEP}" > "${STATE_FILE}"

    # Cr√©ation du namespace monitoring
    kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f - || true

    # Ajout du d√©p√¥t Helm
    helm repo add prometheus-community https://prometheus-community.github.io/helm-charts || true
    helm repo update

    # Configuration Prometheus optimis√©e
    local values_file="${CACHE_DIR}/prometheus-values.yaml"
    cat > "${values_file}" << EOF
grafana:
  adminPassword: admin
  service:
    type: NodePort
    nodePort: 30000
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 200m
      memory: 512Mi
  persistence:
    enabled: true
    size: 2Gi

prometheus:
  prometheusSpec:
    retention: 15d
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 500m
        memory: 1Gi
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi

alertmanager:
  alertmanagerSpec:
    resources:
      requests:
        cpu: 50m
        memory: 128Mi
      limits:
        cpu: 100m
        memory: 256Mi
    storage:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 2Gi
EOF

    # D√©ploiement de Prometheus
    log "INFO" "D√©ploiement de Prometheus/Grafana..."

    if measure_performance "monitoring_deploy" helm upgrade --install prometheus prometheus-community/kube-prometheus-stack \
       --namespace monitoring \
       --values "${values_file}" \
       --timeout=20m \
       --atomic; then

        log "SUCCESS" "Monitoring d√©ploy√© avec succ√®s"

        # Attente que les pods soient pr√™ts avec timeout
        log "INFO" "Attente que les pods soient pr√™ts..."

        if kubectl wait --for=condition=Ready pod -l app=prometheus -n monitoring --timeout=300s && \
           kubectl wait --for=condition=Ready pod -l app.kubernetes.io/name=grafana -n monitoring --timeout=300s; then

            # R√©cup√©ration des informations d'acc√®s
            local grafana_port=$(kubectl get service -n monitoring prometheus-grafana -o jsonpath='{.spec.ports[0].nodePort}')

            log "SUCCESS" "Monitoring pr√™t"
            log "INFO" "Grafana: http://${ansible_host}:${grafana_port} (admin/admin)"
        else
            log "WARNING" "Certains pods ne sont pas pr√™ts, mais le d√©ploiement est termin√©"
        fi
    else
        log "ERROR" "√âchec du d√©ploiement du monitoring"
        exit 1
    fi
}

# Fonction de d√©ploiement des services infrastructure (optimis√©e)
function deployer_services_infrastructure() {
    log "STEP" "D√©ploiement des services d'infrastructure..."
    INSTALLATION_STEP="deploy_services"
    echo "${INSTALLATION_STEP}" > "${STATE_FILE}"

    # Construction et ex√©cution de la commande Ansible
    local ansible_cmd="ansible-playbook ${ANSIBLE_DIR}/playbooks/deploy-infrastructure-services.yml --extra-vars \"environment=${environment}\" --ask-become-pass"

    [[ "${debug_mode:-false}" == "true" ]] && ansible_cmd="${ansible_cmd} -vvv"

    log "INFO" "Ex√©cution: ${ansible_cmd}"
    LAST_COMMAND="${ansible_cmd}"

    if measure_performance "services_deploy" run_with_timeout "${ansible_cmd}" 1800 "ansible_playbook"; then
        log "SUCCESS" "Services d'infrastructure d√©ploy√©s"
    else
        log "WARNING" "√âchec partiel du d√©ploiement des services"
        log "INFO" "Vous pouvez les d√©ployer manuellement plus tard avec:"
        log "INFO" "${ansible_cmd}"
    fi
}

# Fonction de v√©rification finale (optimis√©e)
function verifier_installation() {
    log "STEP" "V√©rification de l'installation..."
    INSTALLATION_STEP="verify"

    # V√©rification des n≈ìuds
    log "INFO" "V√©rification des n≈ìuds Kubernetes..."
    local nodes_status=$(kubectl get nodes -o wide 2>&1)

    if echo "${nodes_status}" | grep -q "Ready"; then
        log "SUCCESS" "N≈ìuds Kubernetes op√©rationnels"
    else
        log "WARNING" "Probl√®mes d√©tect√©s sur les n≈ìuds"
    fi

    # V√©rification des namespaces
    local required_namespaces=("kube-system" "lions-infrastructure" "${environment}" "monitoring")
    local missing_namespaces=()

    for ns in "${required_namespaces[@]}"; do
        if ! kubectl get namespace "${ns}" &>/dev/null; then
            missing_namespaces+=("${ns}")
        fi
    done

    if [[ ${#missing_namespaces[@]} -eq 0 ]]; then
        log "SUCCESS" "Tous les namespaces requis sont pr√©sents"
    else
        log "WARNING" "Namespaces manquants: ${missing_namespaces[*]}"
    fi

    # V√©rification des pods en parall√®le
    declare -A pod_stats
    pod_stats["total"]=0
    pod_stats["running"]=0
    pod_stats["failed"]=0

    # Comptage des pods par statut
    while IFS= read -r line; do
        ((pod_stats["total"]++))
        if echo "${line}" | grep -q "Running"; then
            ((pod_stats["running"]++))
        elif echo "${line}" | grep -qE "Error|CrashLoopBackOff|ImagePullBackOff"; then
            ((pod_stats["failed"]++))
        fi
    done < <(kubectl get pods --all-namespaces --no-headers)

    log "INFO" "Statistiques des pods: ${pod_stats["running"]}/${pod_stats["total"]} en cours d'ex√©cution"

    if [[ ${pod_stats["failed"]} -gt 0 ]]; then
        log "WARNING" "${pod_stats["failed"]} pods en erreur d√©tect√©s"
    fi

    # V√©rification des services expos√©s
    local service_checks=(
        "http://${ansible_host}:30000|Grafana"
        "https://${ansible_host}:30001|Kubernetes Dashboard"
    )

    for service in "${service_checks[@]}"; do
        local url="${service%%|*}"
        local name="${service##*|}"

        if curl -s --connect-timeout 5 "${url}" | grep -q "200\|302"; then
            log "SUCCESS" "${name} accessible"
        else
            log "WARNING" "${name} non accessible"
        fi
    done &

    wait

    # G√©n√©ration du rapport final
    local report_file="${LOG_DIR}/verification-report-$(date +%Y%m%d-%H%M%S).txt"
    generate_verification_report "${report_file}"

    log "SUCCESS" "V√©rification termin√©e - Rapport: ${report_file}"

    # Nettoyage final
    rm -f "${STATE_FILE}"
}

# Fonction de g√©n√©ration du rapport de v√©rification
function generate_verification_report() {
    local report_file="$1"

    {
        echo "=== RAPPORT DE V√âRIFICATION DE L'INFRASTRUCTURE LIONS ==="
        echo "Date: $(date)"
        echo "Environnement: ${environment}"
        echo "Dur√©e d'installation: $(($(date +%s) - START_TIME)) secondes"
        echo ""

        echo "=== M√âTRIQUES DE PERFORMANCE ==="
        for key in "${!PERFORMANCE_METRICS[@]}"; do
            echo "- ${key}: ${PERFORMANCE_METRICS[${key}]}ms"
        done
        echo ""

        echo "=== R√âSUM√â DES COMPOSANTS ==="
        kubectl get nodes -o wide
        echo ""

        echo "=== PODS PAR NAMESPACE ==="
        kubectl get pods --all-namespaces -o wide
        echo ""

        echo "=== SERVICES EXPOS√âS ==="
        kubectl get services --all-namespaces -o wide | grep NodePort
        echo ""

        echo "=== √âTAT DE SANT√â GLOBAL ==="
        local health_score=$(kubectl get pods --all-namespaces -o json | jq '[.items[] | select(.status.phase=="Running")] | length')
        local total_pods=$(kubectl get pods --all-namespaces -o json | jq '.items | length')
        local health_percentage=$((health_score * 100 / total_pods))

        echo "Score de sant√©: ${health_percentage}% (${health_score}/${total_pods} pods en cours d'ex√©cution)"

        if [[ ${health_percentage} -ge 90 ]]; then
            echo "‚úÖ Infrastructure en excellent √©tat"
        elif [[ ${health_percentage} -ge 70 ]]; then
            echo "‚ö†Ô∏è Infrastructure op√©rationnelle avec probl√®mes mineurs"
        else
            echo "‚ùå Infrastructure n√©cessite une attention imm√©diate"
        fi

        echo ""
        echo "=== INFORMATIONS D'ACC√àS ==="
        echo "Grafana: http://${ansible_host}:30000 (admin/admin)"
        echo "Kubernetes Dashboard: https://${ansible_host}:30001"
        echo ""

        echo "=== FIN DU RAPPORT ==="
    } > "${report_file}"
}

# Fonction pour collecter les logs de mani√®re optimis√©e
function collect_logs() {
    local output_dir="${LOG_DIR}/diagnostic-$(date +%Y%m%d-%H%M%S)"
    mkdir -p "${output_dir}"

    log "INFO" "Collecte optimis√©e des logs pour diagnostic..."

    # Collecte en parall√®le
    {
        # Logs locaux
        cp "${LOG_FILE}" "${output_dir}/install.log"
        uname -a > "${output_dir}/local_system.log"
        df -h > "${output_dir}/local_disk.log"

        # Logs Kubernetes
        if command_exists kubectl; then
            kubectl get all --all-namespaces > "${output_dir}/k8s_all_resources.log"
            kubectl get events --all-namespaces --sort-by='.lastTimestamp' > "${output_dir}/k8s_events.log"

            # Logs des pods probl√©matiques
            kubectl get pods --all-namespaces -o json | jq -r '.items[] | select(.status.phase!="Running") | "\(.metadata.namespace) \(.metadata.name)"' | while read -r ns pod; do
                kubectl logs -n "${ns}" "${pod}" --tail=50 > "${output_dir}/pod_${ns}_${pod}.log" 2>/dev/null || true
            done
        fi
    } &

    {
        # Logs du VPS
        if [[ -n "${ansible_host}" ]]; then
            ssh_exec "sudo journalctl -u k3s --no-pager -n 100" false 10 > "${output_dir}/vps_k3s.log"
            ssh_exec "sudo systemctl status k3s" false 10 > "${output_dir}/vps_k3s_status.log"
            ssh_exec "free -m" false 10 > "${output_dir}/vps_memory.log"
            ssh_exec "df -h" false 10 > "${output_dir}/vps_disk.log"
        fi
    } &

    wait

    # Compression avec optimisation
    local archive_file="${LOG_DIR}/diagnostic-$(date +%Y%m%d-%H%M%S).tar.gz"
    tar -czf "${archive_file}" -C "$(dirname "${output_dir}")" "$(basename "${output_dir}")"
    rm -rf "${output_dir}"

    log "SUCCESS" "Logs collect√©s: ${archive_file}"
}

# Gestion des erreurs am√©lior√©e
function handle_error() {
    local exit_code=$?
    local line_number=$1
    local command_name=${2:-unknown}

    # D√©sactivation temporaire du mode strict
    set +euo pipefail

    log "ERROR" "Erreur √† la ligne ${line_number} (code ${exit_code})"
    log "ERROR" "Commande: ${LAST_COMMAND}"

    # Diagnostic de l'erreur
    case ${exit_code} in
        1)   log "ERROR" "Erreur g√©n√©rale" ;;
        2)   log "ERROR" "Erreur de syntaxe" ;;
        126) log "ERROR" "Permission refus√©e" ;;
        127) log "ERROR" "Commande non trouv√©e" ;;
        137) log "ERROR" "Processus termin√© (manque de m√©moire?)" ;;
        *)   log "ERROR" "Code d'erreur: ${exit_code}" ;;
    esac

    # Sauvegarde de l'√©tat d'erreur
    LAST_ERROR="Ligne ${line_number}: ${LAST_COMMAND} (code ${exit_code})"
    echo "${INSTALLATION_STEP}" > "${STATE_FILE}"
    cp "${LOG_FILE}" "${BACKUP_DIR}/error-$(date +%Y%m%d-%H%M%S).log"

    # Collecte automatique des logs
    collect_logs

    # Tentative de reprise pour certaines erreurs
    if [[ ${RETRY_COUNT} -lt ${MAX_RETRIES} && ${exit_code} -ne 2 ]]; then
        ((RETRY_COUNT++))
        log "WARNING" "Tentative ${RETRY_COUNT}/${MAX_RETRIES} de reprise..."
        sleep $((RETRY_COUNT * 5))

        # Tentative de reprise selon le contexte
        case "${command_name}" in
            "ansible_playbook")
                # Reprise avec des options plus s√ªres
                LAST_COMMAND="${LAST_COMMAND} --forks=1 --timeout=60"
                eval "${LAST_COMMAND}"
                ;;
            "kubectl_apply")
                # Reprise avec validation d√©sactiv√©e
                LAST_COMMAND="${LAST_COMMAND} --validate=false"
                eval "${LAST_COMMAND}"
                ;;
            *)
                # Reprise standard de la fonction
                case "${INSTALLATION_STEP}" in
                    "init_vps") initialiser_vps ;;
                    "install_k3s") installer_k3s ;;
                    "deploy_infra") deployer_infrastructure_base ;;
                    "deploy_monitoring") deployer_monitoring ;;
                    "deploy_services") deployer_services_infrastructure ;;
                    "verify") verifier_installation ;;
                esac
                ;;
        esac
    else
        log "ERROR" "Nombre maximum de tentatives atteint"
        log "INFO" "Rapport de diagnostic g√©n√©r√©. Consultez ${LOG_DIR} pour plus de d√©tails."

        # G√©n√©ration du rapport de diagnostic final
        generate_diagnostic_report

        cleanup
        exit ${exit_code}
    fi

    # R√©activation du mode strict
    set -euo pipefail
}

# Fonction de g√©n√©ration du rapport de diagnostic
function generate_diagnostic_report() {
    local report_file="${BACKUP_DIR}/diagnostic-$(date +%Y%m%d-%H%M%S).txt"

    {
        echo "=== RAPPORT DE DIAGNOSTIC LIONS INFRASTRUCTURE ==="
        echo "Date: $(date)"
        echo "Environnement: ${environment}"
        echo "√âtape d'√©chec: ${INSTALLATION_STEP}"
        echo "Erreur: ${LAST_ERROR}"
        echo ""

        echo "=== M√âTRIQUES DE PERFORMANCE ==="
        for key in "${!PERFORMANCE_METRICS[@]}"; do
            echo "- ${key}: ${PERFORMANCE_METRICS[${key}]}ms"
        done
        echo ""

        echo "=== RECOMMANDATIONS ==="
        case "${INSTALLATION_STEP}" in
            "init_vps")
                echo "1. V√©rifiez la connectivit√© SSH"
                echo "2. V√©rifiez les droits sudo de l'utilisateur"
                echo "3. V√©rifiez les ressources syst√®me du VPS"
                ;;
            "install_k3s")
                echo "1. V√©rifiez l'espace disque disponible"
                echo "2. V√©rifiez la m√©moire disponible (minimum 2GB)"
                echo "3. V√©rifiez les ports kubernetes (6443, 10250)"
                ;;
            "deploy_infra")
                echo "1. V√©rifiez le fichier kubeconfig"
                echo "2. V√©rifiez les ressources kubernetes"
                echo "3. V√©rifiez les permissions RBAC"
                ;;
            "deploy_monitoring")
                echo "1. V√©rifiez l'installation de Helm"
                echo "2. V√©rifiez l'espace de stockage disponible"
                echo "3. V√©rifiez les ressources pods"
                ;;
        esac
        echo ""

        echo "=== FIN DU RAPPORT ==="
    } > "${report_file}"

    log "SUCCESS" "Rapport de diagnostic: ${report_file}"
}

# Fonction d'affichage de l'aide
function afficher_aide() {
    cat << EOF
Script d'Installation de l'Infrastructure LIONS sur VPS (v1.2.0)

Ce script orchestre l'installation compl√®te de l'infrastructure LIONS sur un VPS.

Usage:
    $0 [options]

Options:
    -e, --environment <env>   Environnement cible (production, staging, development)
                             Par d√©faut: development
    -i, --inventory <file>    Fichier d'inventaire Ansible sp√©cifique
                             Par d√©faut: inventories/<environment>/hosts.yml
    -s, --skip-init           Ignorer l'initialisation du VPS (si d√©j√† effectu√©e)
    -d, --debug               Active le mode debug
    -t, --test                Execute les tests de robustesse
    -h, --help                Affiche cette aide

Exemples:
    $0                                   # Installation standard
    $0 --environment staging             # Installation pour l'environnement staging
    $0 --skip-init --debug              # Reprise avec debug activ√©
    $0 --test                           # Tests de robustesse

Notes:
    - Les logs sont stock√©s dans ${LOG_DIR}
    - Les sauvegardes automatiques sont cr√©√©es dans ${BACKUP_DIR}
    - Le script peut √™tre repris apr√®s une interruption
EOF
}

# Fonction de test de robustesse optimis√©e
function test_robustesse() {
    log "STEP" "Tests de robustesse de l'infrastructure..."

    # S√©rie de tests avec mesure de performance
    local tests=(
        "test_ssh_robustesse"
        "test_kubectl_robustesse"
        "test_timeout_robustesse"
        "test_network_robustesse"
        "test_backup_robustesse"
    )

    local passed=0
    local failed=0

    for test in "${tests[@]}"; do
        log "INFO" "Ex√©cution du test: ${test}"

        if measure_performance "${test}" ${test}; then
            ((passed++))
            log "SUCCESS" "Test ${test} r√©ussi"
        else
            ((failed++))
            log "ERROR" "Test ${test} √©chou√©"
        fi
    done

    log "INFO" "Tests termin√©s: ${passed} r√©ussi(s), ${failed} √©chou√©(s)"
    return $((failed > 0 ? 1 : 0))
}

# Tests de robustesse individuels
function test_ssh_robustesse() {
    local original_host="${ansible_host}"
    ansible_host="invalid.host.example.com"

    # Le test doit √©chouer
    if ! ssh_exec "echo test" false 5 &>/dev/null; then
        ansible_host="${original_host}"
        return 0
    else
        ansible_host="${original_host}"
        return 1
    fi
}

function test_kubectl_robustesse() {
    local original_config="${KUBECONFIG}"
    export KUBECONFIG="/tmp/invalid_kubeconfig"

    # Le test doit √©chouer
    if ! kubectl get nodes &>/dev/null; then
        export KUBECONFIG="${original_config}"
        return 0
    else
        export KUBECONFIG="${original_config}"
        return 1
    fi
}

function test_timeout_robustesse() {
    # Test avec timeout court
    if ! run_with_timeout "sleep 5" 1 "test"; then
        return 0
    else
        return 1
    fi
}

function test_network_robustesse() {
    # Test de connectivit√© r√©seau avec retry
    local retry_count=0
    local max_retries=3

    while [[ ${retry_count} -lt ${max_retries} ]]; do
        if ping -c 1 -W 2 "8.8.8.8" &>/dev/null; then
            return 0
        fi
        ((retry_count++))
        sleep 1
    done

    return 1
}

function test_backup_robustesse() {
    # Test de sauvegarde/restauration
    if backup_state "test-backup" "true"; then
        if [[ -f "${BACKUP_DIR}/.last_backup" ]]; then
            rm -f "${BACKUP_DIR}/test-backup.tar.gz" "${BACKUP_DIR}/test-backup.json"
            return 0
        fi
    fi

    return 1
}

# Point d'entr√©e principal
function main() {
    # Parsing des arguments
    environment="${DEFAULT_ENV}"
    inventory_file="inventories/${DEFAULT_ENV}/hosts.yml"
    skip_init="false"
    debug_mode="false"
    test_mode="false"

    while [[ $# -gt 0 ]]; do
        case "$1" in
            -e|--environment)
                environment="$2"
                inventory_file="inventories/${environment}/hosts.yml"
                shift 2
                ;;
            -i|--inventory)
                inventory_file="$2"
                shift 2
                ;;
            -s|--skip-init)
                skip_init="true"
                shift
                ;;
            -d|--debug)
                debug_mode="true"
                shift
                ;;
            -t|--test)
                test_mode="true"
                shift
                ;;
            -h|--help)
                afficher_aide
                exit 0
                ;;
            *)
                log "ERROR" "Argument inconnu: $1"
                afficher_aide
                exit 1
                ;;
        esac
    done

    # Affichage du titre
    echo -e "${COLOR_CYAN}${COLOR_BOLD}"
    echo -e "  _     ___ ___  _   _ ___    ___ _   _ _____ ___    _    "
    echo -e " | |   |_ _/ _ \| \ | / __|  |_ _| \ | |  ___/ _ \  / \   "
    echo -e " | |    | | | | |  \| \__ \   | ||  \| | |_ | | | |/ _ \  "
    echo -e " | |___ | | |_| | |\  |__) |  | || |\  |  _|| |_| / ___ \ "
    echo -e " |_____|___\___/|_| \_|____/  |___|_| \_|_|   \___/_/   \_\\"
    echo -e "${COLOR_RESET}"
    echo -e "${COLOR_YELLOW}${COLOR_BOLD}  Installation de l'Infrastructure sur VPS - v1.2.0${COLOR_RESET}"
    echo -e "${COLOR_CYAN}  ------------------------------------------------${COLOR_RESET}\n"

    # Affichage des param√®tres
    log "INFO" "Configuration:"
    log "INFO" "  - Environnement: ${environment}"
    log "INFO" "  - Inventaire: ${inventory_file}"
    log "INFO" "  - Ignorer l'initialisation: ${skip_init}"
    log "INFO" "  - Mode debug: ${debug_mode}"
    log "INFO" "  - Mode test: ${test_mode}"
    log "INFO" "  - Fichier de log: ${LOG_FILE}"
    echo ""

    # Mode test
    if [[ "${test_mode}" == "true" ]]; then
        log "INFO" "Ex√©cution en mode test..."
        verifier_prerequis
        test_robustesse
        log "INFO" "Mode test termin√©"
        exit 0
    fi

    # Installation normale
    verifier_prerequis

    # Sauvegarde de l'√©tat initial
    backup_state "pre-installation" "true"

    # Ex√©cution des √©tapes
    if [[ "${skip_init}" == "false" ]]; then
        initialiser_vps
    else
        log "INFO" "Initialisation du VPS ignor√©e"
    fi

    installer_k3s
    backup_state "post-k3s" "true"

    deployer_infrastructure_base
    backup_state "post-infrastructure" "true"

    deployer_monitoring
    backup_state "post-monitoring" "true"

    deployer_services_infrastructure
    backup_state "post-services" "true"

    verifier_installation

    # Affichage du r√©sum√© final
    echo -e "\n${COLOR_GREEN}${COLOR_BOLD}===========================================================${COLOR_RESET}"
    echo -e "${COLOR_GREEN}${COLOR_BOLD}  Installation de l'infrastructure LIONS termin√©e avec succ√®s !${COLOR_RESET}"
    echo -e "${COLOR_GREEN}${COLOR_BOLD}===========================================================${COLOR_RESET}\n"

    log "SUCCESS" "Installation termin√©e avec succ√®s"
    log "INFO" "Dur√©e totale: $(($(date +%s) - START_TIME)) secondes"

    echo ""
    log "INFO" "Informations d'acc√®s:"
    log "INFO" "  - Grafana: http://${ansible_host}:30000 (admin/admin)"
    log "INFO" "  - Kubernetes Dashboard: https://${ansible_host}:30001"
    echo ""

    # G√©n√©ration du rapport final
    local report_file="${LOG_DIR}/installation-report-$(date +%Y%m%d-%H%M%S).txt"
    generate_final_report "${report_file}"

    log "INFO" "Rapport d'installation: ${report_file}"
    log "INFO" "Pour d√©ployer des applications, utilisez: deploy.sh"
}

# Fonction de g√©n√©ration du rapport final
function generate_final_report() {
    local report_file="$1"

    {
        echo "=== RAPPORT D'INSTALLATION DE L'INFRASTRUCTURE LIONS ==="
        echo "Date: $(date)"
        echo "Version: 1.2.0"
        echo "Environnement: ${environment}"
        echo "Dur√©e d'installation: $(($(date +%s) - START_TIME)) secondes"
        echo ""

        echo "=== M√âTRIQUES DE PERFORMANCE ==="
        for key in "${!PERFORMANCE_METRICS[@]}"; do
            echo "- ${key}: ${PERFORMANCE_METRICS[${key}]}ms"
        done
        echo ""

        echo "=== R√âSUM√â DE L'INSTALLATION ==="
        echo "‚úÖ Initialisation du VPS: R√©ussie"
        echo "‚úÖ Installation de K3s: R√©ussie"
        echo "‚úÖ D√©ploiement de l'infrastructure: R√©ussie"
        echo "‚úÖ D√©ploiement du monitoring: R√©ussie"
        echo "‚úÖ D√©ploiement des services: R√©ussie"
        echo "‚úÖ V√©rification: R√©ussie"
        echo ""

        echo "=== INFORMATIONS D'ACC√àS ==="
        echo "- Grafana: http://${ansible_host}:30000 (admin/admin)"
        echo "- Kubernetes Dashboard: https://${ansible_host}:30001"
        echo ""

        echo "=== PROCHAINES √âTAPES ==="
        echo "1. Modifier le mot de passe par d√©faut de Grafana"
        echo "2. Configurer les alertes dans Prometheus"
        echo "3. D√©ployer vos applications avec deploy.sh"
        echo "4. Configurer les sauvegardes r√©guli√®res"
        echo ""

        echo "=== FICHIERS IMPORTANTS ==="
        echo "- Logs: ${LOG_FILE}"
        echo "- Sauvegardes: ${BACKUP_DIR}"
        echo "- Configuration: ${ANSIBLE_DIR}/${inventory_file}"
        echo ""

        echo "=== FIN DU RAPPORT ==="
    } > "${report_file}"
}

# Ex√©cution du script principal
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi