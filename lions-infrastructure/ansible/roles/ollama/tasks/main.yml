---
# =========================================================================
# LIONS INFRASTRUCTURE 5.0 - R√îLE OLLAMA AI SERVICE
# =========================================================================
# Description: Orchestrateur principal pour le d√©ploiement du service IA Ollama
# Composant: Ollama LLM Service - Plateforme d'ex√©cution de mod√®les de langage
# Version: 5.0.0
# Maintainer: DevOps Team <devops@lions.dev>
# Documentation: https://docs.lions.dev/infrastructure/ai/ollama
# D√©pendances: Kubernetes 1.24+, Persistent Storage, Prometheus
# =========================================================================

# =========================================================================
# M√âTADONN√âES ET CONFIGURATION
# =========================================================================
- name: "Ollama | Initialisation des m√©tadonn√©es de d√©ploiement"
  set_fact:
    ollama_deployment_metadata:
      role_name: "ollama"
      role_version: "5.0.0"
      deployment_id: "{{ ansible_date_time.epoch }}"
      environment: "{{ ollama_environment }}"
      namespace: "{{ ollama_namespace }}"
      cluster_name: "{{ ollama_cluster_name }}"
      started_at: "{{ ansible_date_time.iso8601 }}"
      started_by: "{{ ansible_user_id | default('ansible') }}"
    ollama_deployment_config:
      dry_run: "{{ lookup('env', 'OLLAMA_DRY_RUN') | default('false') | bool }}"
      debug_mode: "{{ lookup('env', 'OLLAMA_DEBUG_MODE') | default('false') | bool }}"
      skip_validation: "{{ lookup('env', 'OLLAMA_SKIP_VALIDATION') | default('false') | bool }}"
      force_recreate: "{{ lookup('env', 'OLLAMA_FORCE_RECREATE') | default('false') | bool }}"
      enable_gpu: "{{ ollama_resources.gpu.enabled }}"
      preload_models: "{{ ollama_app_config.models.auto_load }}"
      # Phases de d√©ploiement contr√¥lables
      app_prepare: "{{ lookup('env', 'OLLAMA_PHASE_PREPARE') | default('true') | bool }}"
      app_prerequisites: "{{ lookup('env', 'OLLAMA_PHASE_PREREQUISITES') | default('true') | bool }}"
      app_deploy: "{{ lookup('env', 'OLLAMA_PHASE_DEPLOY') | default('true') | bool }}"
      app_monitoring: "{{ lookup('env', 'OLLAMA_PHASE_MONITORING') | default('true') | bool }}"
      app_validate: "{{ lookup('env', 'OLLAMA_PHASE_VALIDATE') | default('true') | bool }}"
  tags:
    - ollama
    - ai-ml
    - metadata
    - always

- name: "Ollama | Affichage des informations de d√©ploiement"
  debug:
    msg:
      - "üöÄ D√©marrage du d√©ploiement Ollama AI Service"
      - "ü§ñ Service: {{ ollama_service_name }}"
      - "üìä Environnement: {{ ollama_deployment_metadata.environment }}"
      - "üè∑Ô∏è  Namespace: {{ ollama_deployment_metadata.namespace }}"
      - "üîß Cluster: {{ ollama_deployment_metadata.cluster_name }}"
      - "üÜî ID de d√©ploiement: {{ ollama_deployment_metadata.deployment_id }}"
      - "‚è∞ D√©marr√© le: {{ ollama_deployment_metadata.started_at }}"
      - "üë§ Initi√© par: {{ ollama_deployment_metadata.started_by }}"
      - "üß© Version: {{ ollama_service_meta.version }}"
      - "üîß Mode debug: {{ ollama_deployment_config.debug_mode }}"
      - "üß™ Dry run: {{ ollama_deployment_config.dry_run }}"
      - "‚ö° GPU activ√©: {{ ollama_deployment_config.enable_gpu }}"
      - "üì¶ Mod√®les pr√©-charg√©s: {{ ollama_deployment_config.preload_models }}"
  when: ollama_deployment_config.debug_mode | bool
  tags:
    - ollama
    - ai-ml
    - debug
    - always

# =========================================================================
# GESTION DES ERREURS ET ROLLBACK
# =========================================================================
- name: "Ollama | Configuration de la gestion d'erreurs"
  set_fact:
    ollama_error_handling:
      max_retries: "{{ lookup('env', 'OLLAMA_MAX_RETRIES') | default('3') }}"
      retry_delay: "{{ lookup('env', 'OLLAMA_RETRY_DELAY') | default('10') }}"
      rollback_on_failure: "{{ lookup('env', 'OLLAMA_ROLLBACK_ON_FAILURE') | default('true') | bool }}"
      continue_on_minor_errors: "{{ lookup('env', 'OLLAMA_CONTINUE_ON_MINOR_ERRORS') | default('true') | bool }}"
      error_log_file: "/tmp/ollama-deployment-{{ ollama_deployment_metadata.deployment_id }}.log"
      debug_log_file: "/tmp/ollama-debug-{{ ollama_deployment_metadata.deployment_id }}.log"
    ollama_deployment_status:
      phases_completed: []
      phases_failed: []
      warnings: []
      critical_errors: []
  tags:
    - ollama
    - ai-ml
    - error-handling
    - always

# =========================================================================
# V√âRIFICATIONS PR√âALABLES CRITIQUES
# =========================================================================
- name: "Ollama | V√©rification de l'√©tat de l'environnement"
  block:
    - name: "Ollama | V√©rification de l'accessibilit√© du cluster Kubernetes"
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Namespace
        name: "{{ ollama_namespace }}"
      register: ollama_namespace_check
      failed_when: false

    - name: "Ollama | V√©rification des variables d'environnement critiques"
      assert:
        that:
          - ollama_service_meta.name is defined
          - ollama_service_meta.name | length > 0
          - ollama_service_meta.version is defined
          - ollama_service_meta.version | length > 0
          - ollama_namespace is defined
          - ollama_namespace | length > 0
          - ollama_container.image.repository is defined
          - ollama_container.image.tag is defined
        fail_msg: "Variables d'environnement Ollama manquantes ou incorrectes"
        success_msg: "Variables d'environnement Ollama valid√©es"

    - name: "Ollama | V√©rification des ressources syst√®me disponibles"
      set_fact:
        ollama_system_check:
          cluster_accessible: "{{ ollama_namespace_check.resources is defined }}"
          namespace_exists: "{{ ollama_namespace_check.resources | length > 0 if ollama_namespace_check.resources is defined else false }}"
          config_valid: true

    - name: "Ollama | Affichage du statut des v√©rifications"
      debug:
        msg:
          - "üîç Statut des v√©rifications pr√©alables:"
          - "  - Cluster accessible: {{ ollama_system_check.cluster_accessible }}"
          - "  - Namespace existe: {{ ollama_system_check.namespace_exists }}"
          - "  - Configuration valide: {{ ollama_system_check.config_valid }}"

  rescue:
    - name: "Ollama | Gestion d'erreur - V√©rifications pr√©alables"
      fail:
        msg: "‚ùå √âchec des v√©rifications pr√©alables Ollama AI Service: {{ ansible_failed_result.msg | default('Erreur inconnue') }}"

  tags:
    - ollama
    - ai-ml
    - preflight
    - validation

# =========================================================================
# PHASE 1: PR√âREQUIS ET D√âPENDANCES
# =========================================================================
- name: "Ollama | Phase 1 - V√©rification des pr√©requis"
  block:
    - name: "Ollama | Inclusion des t√¢ches de pr√©requis"
      include_tasks: prerequisites.yml
      vars:
        current_phase: "prerequisites"
        phase_description: "V√©rification des pr√©requis syst√®me pour Ollama AI"
        phase_number: 1
      when: ollama_deployment_config.app_prerequisites | bool

    - name: "Ollama | Enregistrement du succ√®s Phase 1"
      set_fact:
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_completed': ollama_deployment_status.phases_completed + ['prerequisites']}) }}"

  rescue:
    - name: "Ollama | √âchec Phase 1 - Pr√©requis"
      set_fact:
        ollama_deployment_failed: true
        ollama_failure_phase: "prerequisites"
        ollama_failure_reason: "{{ ansible_failed_result.msg | default('√âchec des pr√©requis Ollama AI') }}"
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_failed': ollama_deployment_status.phases_failed + ['prerequisites'], 'critical_errors': ollama_deployment_status.critical_errors + [ansible_failed_result.msg | default('Erreur de pr√©requis')]}) }}"

    - name: "Ollama | Log d'erreur Phase 1"
      lineinfile:
        path: "{{ ollama_error_handling.error_log_file }}"
        line: "[{{ ansible_date_time.iso8601 }}] ERREUR Phase 1 (Pr√©requis): {{ ollama_failure_reason }}"
        create: yes

    - name: "Ollama | Arr√™t du d√©ploiement - Phase 1"
      fail:
        msg: "‚ùå D√©ploiement Ollama AI Service interrompu en Phase 1 (Pr√©requis): {{ ollama_failure_reason }}"

  tags:
    - ollama
    - ai-ml
    - prerequisites
    - phase-1

# =========================================================================
# PHASE 2: PR√âPARATION DES RESSOURCES
# =========================================================================
- name: "Ollama | Phase 2 - Pr√©paration des ressources"
  block:
    - name: "Ollama | Inclusion des t√¢ches de pr√©paration"
      include_tasks: prepare.yml
      vars:
        current_phase: "preparation"
        phase_description: "Cr√©ation des ressources Kubernetes pour Ollama AI"
        phase_number: 2
      when: ollama_deployment_config.app_prepare | bool

    - name: "Ollama | Enregistrement du succ√®s Phase 2"
      set_fact:
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_completed': ollama_deployment_status.phases_completed + ['preparation']}) }}"

  rescue:
    - name: "Ollama | √âchec Phase 2 - Pr√©paration"
      set_fact:
        ollama_deployment_failed: true
        ollama_failure_phase: "preparation"
        ollama_failure_reason: "{{ ansible_failed_result.msg | default('√âchec de la pr√©paration Ollama AI') }}"
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_failed': ollama_deployment_status.phases_failed + ['preparation'], 'critical_errors': ollama_deployment_status.critical_errors + [ansible_failed_result.msg | default('Erreur de pr√©paration')]}) }}"

    - name: "Ollama | Log d'erreur Phase 2"
      lineinfile:
        path: "{{ ollama_error_handling.error_log_file }}"
        line: "[{{ ansible_date_time.iso8601 }}] ERREUR Phase 2 (Pr√©paration): {{ ollama_failure_reason }}"
        create: yes

    - name: "Ollama | Nettoyage partiel apr√®s √©chec Phase 2"
      include_tasks: cleanup.yml
      vars:
        cleanup_scope: "preparation"
        cleanup_reason: "√âchec Phase 2"
      when: ollama_error_handling.rollback_on_failure | bool

    - name: "Ollama | Arr√™t du d√©ploiement - Phase 2"
      fail:
        msg: "‚ùå D√©ploiement Ollama AI Service interrompu en Phase 2 (Pr√©paration): {{ ollama_failure_reason }}"

  when: ollama_deployment_failed is not defined
  tags:
    - ollama
    - ai-ml
    - preparation
    - phase-2

# =========================================================================
# PHASE 3: D√âPLOIEMENT PRINCIPAL
# =========================================================================
- name: "Ollama | Phase 3 - D√©ploiement principal"
  block:
    - name: "Ollama | Inclusion des t√¢ches de d√©ploiement"
      include_tasks: deploy.yml
      vars:
        current_phase: "deployment"
        phase_description: "D√©ploiement des composants Ollama AI (Deployment, Service, Ingress)"
        phase_number: 3
      when: ollama_deployment_config.app_deploy | bool

    - name: "Ollama | Enregistrement du succ√®s Phase 3"
      set_fact:
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_completed': ollama_deployment_status.phases_completed + ['deployment']}) }}"

  rescue:
    - name: "Ollama | √âchec Phase 3 - D√©ploiement"
      set_fact:
        ollama_deployment_failed: true
        ollama_failure_phase: "deployment"
        ollama_failure_reason: "{{ ansible_failed_result.msg | default('√âchec du d√©ploiement Ollama AI') }}"
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_failed': ollama_deployment_status.phases_failed + ['deployment'], 'critical_errors': ollama_deployment_status.critical_errors + [ansible_failed_result.msg | default('Erreur de d√©ploiement')]}) }}"

    - name: "Ollama | Log d'erreur Phase 3"
      lineinfile:
        path: "{{ ollama_error_handling.error_log_file }}"
        line: "[{{ ansible_date_time.iso8601 }}] ERREUR Phase 3 (D√©ploiement): {{ ollama_failure_reason }}"
        create: yes

    - name: "Ollama | Rollback complet apr√®s √©chec Phase 3"
      include_tasks: rollback.yml
      vars:
        rollback_reason: "√âchec du d√©ploiement principal Ollama AI"
        rollback_scope: "full"
      when: ollama_error_handling.rollback_on_failure | bool

    - name: "Ollama | Arr√™t du d√©ploiement - Phase 3"
      fail:
        msg: "‚ùå D√©ploiement Ollama AI Service interrompu en Phase 3 (D√©ploiement): {{ ollama_failure_reason }}"

  when: ollama_deployment_failed is not defined
  tags:
    - ollama
    - ai-ml
    - deployment
    - phase-3

# =========================================================================
# PHASE 4: CONFIGURATION DU MONITORING
# =========================================================================
- name: "Ollama | Phase 4 - Configuration du monitoring"
  block:
    - name: "Ollama | Inclusion des t√¢ches de monitoring"
      include_tasks: monitoring.yml
      vars:
        current_phase: "monitoring"
        phase_description: "Configuration des m√©triques et alertes Ollama AI (Prometheus, ServiceMonitor)"
        phase_number: 4
      when: 
        - ollama_deployment_config.app_monitoring | bool
        - ollama_monitoring.enabled | bool

    - name: "Ollama | Enregistrement du succ√®s Phase 4"
      set_fact:
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_completed': ollama_deployment_status.phases_completed + ['monitoring']}) }}"

  rescue:
    - name: "Ollama | Avertissement Phase 4 - Monitoring"
      debug:
        msg:
          - "‚ö†Ô∏è  √âchec de la configuration du monitoring Ollama AI"
          - "‚ÑπÔ∏è  Le d√©ploiement principal a r√©ussi, mais les m√©triques peuvent √™tre indisponibles"
          - "üîç Erreur: {{ ansible_failed_result.msg | default('Erreur de monitoring inconnue') }}"
          - "üõ†Ô∏è  Les mod√®les IA restent fonctionnels malgr√© ce probl√®me"

    - name: "Ollama | Log d'avertissement Phase 4"
      lineinfile:
        path: "{{ ollama_error_handling.error_log_file }}"
        line: "[{{ ansible_date_time.iso8601 }}] AVERTISSEMENT Phase 4 (Monitoring): {{ ansible_failed_result.msg | default('Erreur de monitoring') }}"
        create: yes

    - name: "Ollama | Marquage du monitoring comme d√©faillant"
      set_fact:
        ollama_monitoring_failed: true
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'warnings': ollama_deployment_status.warnings + ['Monitoring Ollama AI indisponible']}) }}"

  when:
    - ollama_deployment_failed is not defined
    - ollama_monitoring.enabled | default(true) | bool
  tags:
    - ollama
    - ai-ml
    - monitoring
    - phase-4

# =========================================================================
# PHASE 5: VALIDATION POST-D√âPLOIEMENT
# =========================================================================
- name: "Ollama | Phase 5 - Validation post-d√©ploiement"
  block:
    - name: "Ollama | Inclusion des t√¢ches de validation"
      include_tasks: validate.yml
      vars:
        current_phase: "validation"
        phase_description: "Validation de l'√©tat et des fonctionnalit√©s Ollama AI (API, mod√®les, performance)"
        phase_number: 5
      when: ollama_deployment_config.app_validate | bool

    - name: "Ollama | Enregistrement du succ√®s Phase 5"
      set_fact:
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_completed': ollama_deployment_status.phases_completed + ['validation']}) }}"

  rescue:
    - name: "Ollama | √âchec Phase 5 - Validation"
      set_fact:
        ollama_deployment_failed: true
        ollama_failure_phase: "validation"
        ollama_failure_reason: "{{ ansible_failed_result.msg | default('√âchec de la validation Ollama AI') }}"
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_failed': ollama_deployment_status.phases_failed + ['validation'], 'critical_errors': ollama_deployment_status.critical_errors + [ansible_failed_result.msg | default('Erreur de validation')]}) }}"

    - name: "Ollama | Log d'erreur Phase 5"
      lineinfile:
        path: "{{ ollama_error_handling.error_log_file }}"
        line: "[{{ ansible_date_time.iso8601 }}] ERREUR Phase 5 (Validation): {{ ollama_failure_reason }}"
        create: yes

    - name: "Ollama | D√©cision sur le rollback apr√®s validation"
      debug:
        msg: 
          - "‚ö†Ô∏è  Validation √©chou√©e mais Ollama AI peut √™tre partiellement fonctionnel"
          - "ü§ñ Les mod√®les de base peuvent toujours √™tre accessibles"
          - "üîç V√©rifiez les logs pour plus de d√©tails"

    - name: "Ollama | Arr√™t avec avertissement - Phase 5"
      fail:
        msg: "‚ö†Ô∏è  D√©ploiement Ollama AI Service termin√© avec des erreurs de validation: {{ ollama_failure_reason }}"

  when:
    - ollama_deployment_failed is not defined
    - not ollama_deployment_config.skip_validation | bool
  tags:
    - ollama
    - ai-ml
    - validation
    - phase-5

# =========================================================================
# PHASE 6: CONFIGURATION DE LA SAUVEGARDE
# =========================================================================
- name: "Ollama | Phase 6 - Configuration de la sauvegarde"
  block:
    - name: "Ollama | Inclusion des t√¢ches de sauvegarde"
      include_tasks: backup.yml
      vars:
        current_phase: "backup"
        phase_description: "Configuration des strat√©gies de sauvegarde Ollama AI (mod√®les, configurations)"
        phase_number: 6

    - name: "Ollama | Enregistrement du succ√®s Phase 6"
      set_fact:
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_completed': ollama_deployment_status.phases_completed + ['backup']}) }}"

  rescue:
    - name: "Ollama | Avertissement Phase 6 - Sauvegarde"
      debug:
        msg:
          - "‚ö†Ô∏è  √âchec de la configuration de sauvegarde Ollama AI"
          - "‚ÑπÔ∏è  Ollama AI fonctionne mais les sauvegardes automatiques des mod√®les sont d√©sactiv√©es"
          - "üîç Erreur: {{ ansible_failed_result.msg | default('Erreur de sauvegarde inconnue') }}"
          - "üí° Recommandation: Configurez manuellement la sauvegarde des mod√®les"

    - name: "Ollama | Log d'avertissement Phase 6"
      lineinfile:
        path: "{{ ollama_error_handling.error_log_file }}"
        line: "[{{ ansible_date_time.iso8601 }}] AVERTISSEMENT Phase 6 (Sauvegarde): {{ ansible_failed_result.msg | default('Erreur de sauvegarde') }}"
        create: yes

    - name: "Ollama | Marquage de la sauvegarde comme d√©faillante"
      set_fact:
        ollama_backup_failed: true
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'warnings': ollama_deployment_status.warnings + ['Sauvegarde automatique Ollama AI d√©sactiv√©e']}) }}"

  when:
    - ollama_deployment_failed is not defined
    - ollama_storage.backup_enabled | default(true) | bool
  tags:
    - ollama
    - ai-ml
    - backup
    - phase-6

# =========================================================================
# FINALISATION ET RAPPORT DE D√âPLOIEMENT
# =========================================================================
- name: "Ollama | G√©n√©ration du rapport de d√©ploiement"
  set_fact:
    ollama_deployment_report:
      # Statut g√©n√©ral
      status: "{{ 'FAILED' if ollama_deployment_failed | default(false) else 'SUCCESS' }}"
      service_type: "ai-ml"
      component: "ollama"
      
      # M√©tadonn√©es de d√©ploiement
      environment: "{{ ollama_deployment_metadata.environment }}"
      namespace: "{{ ollama_deployment_metadata.namespace }}"
      cluster: "{{ ollama_deployment_metadata.cluster_name }}"
      deployment_id: "{{ ollama_deployment_metadata.deployment_id }}"
      started_at: "{{ ollama_deployment_metadata.started_at }}"
      completed_at: "{{ ansible_date_time.iso8601 }}"
      duration: "{{ (ansible_date_time.epoch | int) - (ollama_deployment_metadata.deployment_id | int) }}"
      
      # Statut des phases
      phases_completed: "{{ ollama_deployment_status.phases_completed }}"
      phases_failed: "{{ ollama_deployment_status.phases_failed }}"
      failed_phase: "{{ ollama_failure_phase | default('N/A') }}"
      failure_reason: "{{ ollama_failure_reason | default('N/A') }}"
      
      # Statut des composants
      monitoring_status: "{{ 'FAILED' if ollama_monitoring_failed | default(false) else 'OK' }}"
      backup_status: "{{ 'FAILED' if ollama_backup_failed | default(false) else 'OK' }}"
      
      # Informations du service
      ollama_version: "{{ ollama_service_meta.version }}"
      ollama_service_name: "{{ ollama_service_name }}"
      ollama_endpoint: "{{ ollama_service_name }}.{{ ollama_namespace }}.svc.cluster.local:{{ ollama_network.service.port }}"
      ollama_external_url: "{{ 'https' if ollama_ingress.tls.enabled else 'http' }}://{{ ollama_dns.full_domain }}"
      
      # Configuration sp√©cifique IA
      gpu_enabled: "{{ ollama_deployment_config.enable_gpu }}"
      preload_models: "{{ ollama_deployment_config.preload_models }}"
      models_configured: "{{ ollama_app_config.models.preload_models | selectattr('enabled', 'equalto', true) | map(attribute='name') | list }}"
      
      # Alertes et avertissements
      warnings: "{{ ollama_deployment_status.warnings }}"
      critical_errors: "{{ ollama_deployment_status.critical_errors }}"
  tags:
    - ollama
    - ai-ml
    - report
    - always

- name: "Ollama | Affichage du rapport de d√©ploiement"
  debug:
    msg:
      - "=============================================="
      - "ü§ñ RAPPORT DE D√âPLOIEMENT OLLAMA AI SERVICE"
      - "=============================================="
      - "üìà Statut: {{ ollama_deployment_report.status }}"
      - "üåç Environnement: {{ ollama_deployment_report.environment }}"
      - "üè∑Ô∏è  Namespace: {{ ollama_deployment_report.namespace }}"
      - "üîß Cluster: {{ ollama_deployment_report.cluster }}"
      - "üÜî ID de d√©ploiement: {{ ollama_deployment_report.deployment_id }}"
      - "‚è∞ Dur√©e: {{ ollama_deployment_report.duration }}s"
      - "üß© Version Ollama: {{ ollama_deployment_report.ollama_version }}"
      - "üîó Point de connexion interne: {{ ollama_deployment_report.ollama_endpoint }}"
      - "üåê URL externe: {{ ollama_deployment_report.ollama_external_url }}"
      - "‚ö° GPU activ√©: {{ ollama_deployment_report.gpu_enabled }}"
      - "üì¶ Mod√®les configur√©s: {{ ollama_deployment_report.models_configured | join(', ') }}"
      - "üìä Monitoring: {{ ollama_deployment_report.monitoring_status }}"
      - "üíæ Sauvegarde: {{ ollama_deployment_report.backup_status }}"
      - "‚úÖ Phases r√©ussies: {{ ollama_deployment_report.phases_completed | join(', ') }}"
      - "{{ '‚ùå Phases √©chou√©es: ' + (ollama_deployment_report.phases_failed | join(', ')) if ollama_deployment_report.phases_failed | length > 0 else '' }}"
      - "{{ '‚ö†Ô∏è  Avertissements: ' + (ollama_deployment_report.warnings | join(', ')) if ollama_deployment_report.warnings | length > 0 else '' }}"
      - "{{ '‚ùå Phase d\'√©chec: ' + ollama_deployment_report.failed_phase if ollama_deployment_report.status == 'FAILED' else '‚úÖ D√©ploiement r√©ussi' }}"
      - "{{ 'üîç Raison: ' + ollama_deployment_report.failure_reason if ollama_deployment_report.status == 'FAILED' else '' }}"
      - "=============================================="
  tags:
    - ollama
    - ai-ml
    - report
    - always

- name: "Ollama | Sauvegarde du rapport de d√©ploiement"
  copy:
    content: "{{ ollama_deployment_report | to_nice_json }}"
    dest: "/tmp/ollama-deployment-report-{{ ollama_deployment_metadata.deployment_id }}.json"
    mode: '0644'
  delegate_to: localhost
  tags:
    - ollama
    - ai-ml
    - report

# =========================================================================
# NETTOYAGE ET FINALISATION
# =========================================================================
- name: "Ollama | Nettoyage des fichiers temporaires"
  file:
    path: "{{ item }}"
    state: absent
  loop:
    - "{{ ollama_error_handling.error_log_file }}"
    - "{{ ollama_error_handling.debug_log_file }}"
  when:
    - ollama_deployment_report.status == "SUCCESS"
    - not ollama_deployment_config.debug_mode | bool
  ignore_errors: yes
  tags:
    - ollama
    - ai-ml
    - cleanup

- name: "Ollama | Message de finalisation"
  debug:
    msg: |
      {% if ollama_deployment_report.status == 'SUCCESS' %}
      üéâ D√©ploiement Ollama AI Service termin√© avec succ√®s !

      üìã Informations de connexion:
      - üîó API interne: {{ ollama_deployment_report.ollama_endpoint }}
      - üåê URL externe: {{ ollama_deployment_report.ollama_external_url }}
      - üö™ Port: {{ ollama_network.service.port }}
      
      ü§ñ Mod√®les IA disponibles:
      {% for model in ollama_deployment_report.models_configured %}
      - {{ model }}
      {% endfor %}
      
      üìö Documentation disponible √†: {{ ollama_service_meta.documentation_url }}
      üí¨ Support: {{ ollama_service_meta.support_channel }}
      {% else %}
      üí• D√©ploiement Ollama AI Service √©chou√© en phase {{ ollama_deployment_report.failed_phase }}

      üîç Consultez les logs d'erreur pour plus de d√©tails:
      - Fichier d'erreur: {{ ollama_error_handling.error_log_file }}
      - Rapport JSON: /tmp/ollama-deployment-report-{{ ollama_deployment_metadata.deployment_id }}.json

      üõ†Ô∏è  Guide de d√©pannage: {{ ollama_service_meta.documentation_url }}/troubleshooting
      üí¨ Support: {{ ollama_service_meta.support_channel }}
      {% endif %}
  tags:
    - ollama
    - ai-ml
    - always