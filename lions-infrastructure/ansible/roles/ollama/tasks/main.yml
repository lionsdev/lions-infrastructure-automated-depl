---
# =========================================================================
# LIONS INFRASTRUCTURE 5.0 - RÃ”LE OLLAMA AI SERVICE
# =========================================================================
# Description: Orchestrateur principal pour le dÃ©ploiement du service IA Ollama
# Composant: Ollama LLM Service - Plateforme d'exÃ©cution de modÃ¨les de langage
# Version: 5.0.0
# Maintainer: DevOps Team <devops@lions.dev>
# Documentation: https://docs.lions.dev/infrastructure/ai/ollama
# DÃ©pendances: Kubernetes 1.24+, Persistent Storage, Prometheus
# =========================================================================

# =========================================================================
# MÃ‰TADONNÃ‰ES ET CONFIGURATION
# =========================================================================
- name: "Ollama | Initialisation des mÃ©tadonnÃ©es de dÃ©ploiement"
  set_fact:
    ollama_deployment_metadata:
      role_name: "ollama"
      role_version: "5.0.0"
      deployment_id: "{{ ansible_date_time.epoch }}"
      environment: "{{ ollama_environment }}"
      namespace: "{{ ollama_namespace }}"
      cluster_name: "{{ ollama_cluster_name }}"
      started_at: "{{ ansible_date_time.iso8601 }}"
      started_by: "{{ ansible_user_id | default('ansible') }}"
    ollama_deployment_config:
      dry_run: "{{ lookup('env', 'OLLAMA_DRY_RUN') | default('false') | bool }}"
      debug_mode: "{{ lookup('env', 'OLLAMA_DEBUG_MODE') | default('false') | bool }}"
      skip_validation: "{{ lookup('env', 'OLLAMA_SKIP_VALIDATION') | default('false') | bool }}"
      force_recreate: "{{ lookup('env', 'OLLAMA_FORCE_RECREATE') | default('false') | bool }}"
      enable_gpu: "{{ ollama_resources.gpu.enabled }}"
      preload_models: "{{ ollama_app_config.models.auto_load }}"
      # Phases de dÃ©ploiement contrÃ´lables
      app_prepare: "{{ lookup('env', 'OLLAMA_PHASE_PREPARE') | default('true') | bool }}"
      app_prerequisites: "{{ lookup('env', 'OLLAMA_PHASE_PREREQUISITES') | default('true') | bool }}"
      app_deploy: "{{ lookup('env', 'OLLAMA_PHASE_DEPLOY') | default('true') | bool }}"
      app_monitoring: "{{ lookup('env', 'OLLAMA_PHASE_MONITORING') | default('true') | bool }}"
      app_validate: "{{ lookup('env', 'OLLAMA_PHASE_VALIDATE') | default('true') | bool }}"
  tags:
    - ollama
    - ai-ml
    - metadata
    - always

- name: "Ollama | Affichage des informations de dÃ©ploiement"
  debug:
    msg:
      - "ğŸš€ DÃ©marrage du dÃ©ploiement Ollama AI Service"
      - "ğŸ¤– Service: {{ ollama_service_name }}"
      - "ğŸ“Š Environnement: {{ ollama_deployment_metadata.environment }}"
      - "ğŸ·ï¸  Namespace: {{ ollama_deployment_metadata.namespace }}"
      - "ğŸ”§ Cluster: {{ ollama_deployment_metadata.cluster_name }}"
      - "ğŸ†” ID de dÃ©ploiement: {{ ollama_deployment_metadata.deployment_id }}"
      - "â° DÃ©marrÃ© le: {{ ollama_deployment_metadata.started_at }}"
      - "ğŸ‘¤ InitiÃ© par: {{ ollama_deployment_metadata.started_by }}"
      - "ğŸ§© Version: {{ ollama_service_meta.version }}"
      - "ğŸ”§ Mode debug: {{ ollama_deployment_config.debug_mode }}"
      - "ğŸ§ª Dry run: {{ ollama_deployment_config.dry_run }}"
      - "âš¡ GPU activÃ©: {{ ollama_deployment_config.enable_gpu }}"
      - "ğŸ“¦ ModÃ¨les prÃ©-chargÃ©s: {{ ollama_deployment_config.preload_models }}"
  when: ollama_deployment_config.debug_mode | bool
  tags:
    - ollama
    - ai-ml
    - debug
    - always

# =========================================================================
# GESTION DES ERREURS ET ROLLBACK
# =========================================================================
- name: "Ollama | Configuration de la gestion d'erreurs"
  set_fact:
    ollama_error_handling:
      max_retries: "{{ lookup('env', 'OLLAMA_MAX_RETRIES') | default('3') }}"
      retry_delay: "{{ lookup('env', 'OLLAMA_RETRY_DELAY') | default('10') }}"
      rollback_on_failure: "{{ lookup('env', 'OLLAMA_ROLLBACK_ON_FAILURE') | default('true') | bool }}"
      continue_on_minor_errors: "{{ lookup('env', 'OLLAMA_CONTINUE_ON_MINOR_ERRORS') | default('true') | bool }}"
      error_log_file: "/tmp/ollama-deployment-{{ ollama_deployment_metadata.deployment_id }}.log"
      debug_log_file: "/tmp/ollama-debug-{{ ollama_deployment_metadata.deployment_id }}.log"
    ollama_deployment_status:
      phases_completed: []
      phases_failed: []
      warnings: []
      critical_errors: []
  tags:
    - ollama
    - ai-ml
    - error-handling
    - always

# =========================================================================
# VÃ‰RIFICATIONS PRÃ‰ALABLES CRITIQUES
# =========================================================================
- name: "Ollama | VÃ©rification de l'Ã©tat de l'environnement"
  block:
    - name: "Ollama | VÃ©rification de l'accessibilitÃ© du cluster Kubernetes"
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Namespace
        name: "{{ ollama_namespace }}"
      register: ollama_namespace_check
      failed_when: false

    - name: "Ollama | VÃ©rification des variables d'environnement critiques"
      assert:
        that:
          - ollama_service_meta.name is defined
          - ollama_service_meta.name | length > 0
          - ollama_service_meta.version is defined
          - ollama_service_meta.version | length > 0
          - ollama_namespace is defined
          - ollama_namespace | length > 0
          - ollama_container.image.repository is defined
          - ollama_container.image.tag is defined
        fail_msg: "Variables d'environnement Ollama manquantes ou incorrectes"
        success_msg: "Variables d'environnement Ollama validÃ©es"

    - name: "Ollama | VÃ©rification des ressources systÃ¨me disponibles"
      set_fact:
        ollama_system_check:
          cluster_accessible: "{{ ollama_namespace_check.resources is defined }}"
          namespace_exists: "{{ ollama_namespace_check.resources | length > 0 if ollama_namespace_check.resources is defined else false }}"
          config_valid: true

    - name: "Ollama | Affichage du statut des vÃ©rifications"
      debug:
        msg:
          - "ğŸ” Statut des vÃ©rifications prÃ©alables:"
          - "  - Cluster accessible: {{ ollama_system_check.cluster_accessible }}"
          - "  - Namespace existe: {{ ollama_system_check.namespace_exists }}"
          - "  - Configuration valide: {{ ollama_system_check.config_valid }}"

  rescue:
    - name: "Ollama | Gestion d'erreur - VÃ©rifications prÃ©alables"
      fail:
        msg: "âŒ Ã‰chec des vÃ©rifications prÃ©alables Ollama AI Service: {{ ansible_failed_result.msg | default('Erreur inconnue') }}"

  tags:
    - ollama
    - ai-ml
    - preflight
    - validation

# =========================================================================
# PHASE 1: PRÃ‰REQUIS ET DÃ‰PENDANCES
# =========================================================================
- name: "Ollama | Phase 1 - VÃ©rification des prÃ©requis"
  block:
    - name: "Ollama | Inclusion des tÃ¢ches de prÃ©requis"
      include_tasks: prerequisites.yml
      vars:
        current_phase: "prerequisites"
        phase_description: "VÃ©rification des prÃ©requis systÃ¨me pour Ollama AI"
        phase_number: 1
      when: ollama_deployment_config.app_prerequisites | bool

    - name: "Ollama | Enregistrement du succÃ¨s Phase 1"
      set_fact:
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_completed': ollama_deployment_status.phases_completed + ['prerequisites']}) }}"

  rescue:
    - name: "Ollama | Ã‰chec Phase 1 - PrÃ©requis"
      set_fact:
        ollama_deployment_failed: true
        ollama_failure_phase: "prerequisites"
        ollama_failure_reason: "{{ ansible_failed_result.msg | default('Ã‰chec des prÃ©requis Ollama AI') }}"
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_failed': ollama_deployment_status.phases_failed + ['prerequisites'], 'critical_errors': ollama_deployment_status.critical_errors + [ansible_failed_result.msg | default('Erreur de prÃ©requis')]}) }}"

    - name: "Ollama | Log d'erreur Phase 1"
      lineinfile:
        path: "{{ ollama_error_handling.error_log_file }}"
        line: "[{{ ansible_date_time.iso8601 }}] ERREUR Phase 1 (PrÃ©requis): {{ ollama_failure_reason }}"
        create: yes

    - name: "Ollama | ArrÃªt du dÃ©ploiement - Phase 1"
      fail:
        msg: "âŒ DÃ©ploiement Ollama AI Service interrompu en Phase 1 (PrÃ©requis): {{ ollama_failure_reason }}"

  tags:
    - ollama
    - ai-ml
    - prerequisites
    - phase-1

# =========================================================================
# PHASE 2: PRÃ‰PARATION DES RESSOURCES
# =========================================================================
- name: "Ollama | Phase 2 - PrÃ©paration des ressources"
  block:
    - name: "Ollama | Inclusion des tÃ¢ches de prÃ©paration"
      include_tasks: prepare.yml
      vars:
        current_phase: "preparation"
        phase_description: "CrÃ©ation des ressources Kubernetes pour Ollama AI"
        phase_number: 2
      when: ollama_deployment_config.app_prepare | bool

    - name: "Ollama | Enregistrement du succÃ¨s Phase 2"
      set_fact:
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_completed': ollama_deployment_status.phases_completed + ['preparation']}) }}"

  rescue:
    - name: "Ollama | Ã‰chec Phase 2 - PrÃ©paration"
      set_fact:
        ollama_deployment_failed: true
        ollama_failure_phase: "preparation"
        ollama_failure_reason: "{{ ansible_failed_result.msg | default('Ã‰chec de la prÃ©paration Ollama AI') }}"
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_failed': ollama_deployment_status.phases_failed + ['preparation'], 'critical_errors': ollama_deployment_status.critical_errors + [ansible_failed_result.msg | default('Erreur de prÃ©paration')]}) }}"

    - name: "Ollama | Log d'erreur Phase 2"
      lineinfile:
        path: "{{ ollama_error_handling.error_log_file }}"
        line: "[{{ ansible_date_time.iso8601 }}] ERREUR Phase 2 (PrÃ©paration): {{ ollama_failure_reason }}"
        create: yes

    - name: "Ollama | Nettoyage partiel aprÃ¨s Ã©chec Phase 2"
      include_tasks: cleanup.yml
      vars:
        cleanup_scope: "preparation"
        cleanup_reason: "Ã‰chec Phase 2"
      when: ollama_error_handling.rollback_on_failure | bool

    - name: "Ollama | ArrÃªt du dÃ©ploiement - Phase 2"
      fail:
        msg: "âŒ DÃ©ploiement Ollama AI Service interrompu en Phase 2 (PrÃ©paration): {{ ollama_failure_reason }}"

  when: ollama_deployment_failed is not defined
  tags:
    - ollama
    - ai-ml
    - preparation
    - phase-2

# =========================================================================
# PHASE 3: DÃ‰PLOIEMENT PRINCIPAL
# =========================================================================
- name: "Ollama | Phase 3 - DÃ©ploiement principal"
  block:
    - name: "Ollama | Inclusion des tÃ¢ches de dÃ©ploiement"
      include_tasks: deploy.yml
      vars:
        current_phase: "deployment"
        phase_description: "DÃ©ploiement des composants Ollama AI (Deployment, Service, Ingress)"
        phase_number: 3
      when: ollama_deployment_config.app_deploy | bool

    - name: "Ollama | Enregistrement du succÃ¨s Phase 3"
      set_fact:
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_completed': ollama_deployment_status.phases_completed + ['deployment']}) }}"

  rescue:
    - name: "Ollama | Ã‰chec Phase 3 - DÃ©ploiement"
      set_fact:
        ollama_deployment_failed: true
        ollama_failure_phase: "deployment"
        ollama_failure_reason: "{{ ansible_failed_result.msg | default('Ã‰chec du dÃ©ploiement Ollama AI') }}"
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_failed': ollama_deployment_status.phases_failed + ['deployment'], 'critical_errors': ollama_deployment_status.critical_errors + [ansible_failed_result.msg | default('Erreur de dÃ©ploiement')]}) }}"

    - name: "Ollama | Log d'erreur Phase 3"
      lineinfile:
        path: "{{ ollama_error_handling.error_log_file }}"
        line: "[{{ ansible_date_time.iso8601 }}] ERREUR Phase 3 (DÃ©ploiement): {{ ollama_failure_reason }}"
        create: yes

    - name: "Ollama | Rollback complet aprÃ¨s Ã©chec Phase 3"
      include_tasks: rollback.yml
      vars:
        rollback_reason: "Ã‰chec du dÃ©ploiement principal Ollama AI"
        rollback_scope: "full"
      when: ollama_error_handling.rollback_on_failure | bool

    - name: "Ollama | ArrÃªt du dÃ©ploiement - Phase 3"
      fail:
        msg: "âŒ DÃ©ploiement Ollama AI Service interrompu en Phase 3 (DÃ©ploiement): {{ ollama_failure_reason }}"

  when: ollama_deployment_failed is not defined
  tags:
    - ollama
    - ai-ml
    - deployment
    - phase-3

# =========================================================================
# PHASE 4: CONFIGURATION DU MONITORING
# =========================================================================
- name: "Ollama | Phase 4 - Configuration du monitoring"
  block:
    - name: "Ollama | Inclusion des tÃ¢ches de monitoring"
      include_tasks: monitoring.yml
      vars:
        current_phase: "monitoring"
        phase_description: "Configuration des mÃ©triques et alertes Ollama AI (Prometheus, ServiceMonitor)"
        phase_number: 4
      when: 
        - ollama_deployment_config.app_monitoring | bool
        - ollama_monitoring.enabled | bool

    - name: "Ollama | Enregistrement du succÃ¨s Phase 4"
      set_fact:
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_completed': ollama_deployment_status.phases_completed + ['monitoring']}) }}"

  rescue:
    - name: "Ollama | Avertissement Phase 4 - Monitoring"
      debug:
        msg:
          - "âš ï¸  Ã‰chec de la configuration du monitoring Ollama AI"
          - "â„¹ï¸  Le dÃ©ploiement principal a rÃ©ussi, mais les mÃ©triques peuvent Ãªtre indisponibles"
          - "ğŸ” Erreur: {{ ansible_failed_result.msg | default('Erreur de monitoring inconnue') }}"
          - "ğŸ› ï¸  Les modÃ¨les IA restent fonctionnels malgrÃ© ce problÃ¨me"

    - name: "Ollama | Log d'avertissement Phase 4"
      lineinfile:
        path: "{{ ollama_error_handling.error_log_file }}"
        line: "[{{ ansible_date_time.iso8601 }}] AVERTISSEMENT Phase 4 (Monitoring): {{ ansible_failed_result.msg | default('Erreur de monitoring') }}"
        create: yes

    - name: "Ollama | Marquage du monitoring comme dÃ©faillant"
      set_fact:
        ollama_monitoring_failed: true
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'warnings': ollama_deployment_status.warnings + ['Monitoring Ollama AI indisponible']}) }}"

  when:
    - ollama_deployment_failed is not defined
    - ollama_monitoring.enabled | default(true) | bool
  tags:
    - ollama
    - ai-ml
    - monitoring
    - phase-4

# =========================================================================
# PHASE 5: VALIDATION POST-DÃ‰PLOIEMENT
# =========================================================================
- name: "Ollama | Phase 5 - Validation post-dÃ©ploiement"
  block:
    - name: "Ollama | Inclusion des tÃ¢ches de validation"
      include_tasks: validate.yml
      vars:
        current_phase: "validation"
        phase_description: "Validation de l'Ã©tat et des fonctionnalitÃ©s Ollama AI (API, modÃ¨les, performance)"
        phase_number: 5
      when: ollama_deployment_config.app_validate | bool

    - name: "Ollama | Enregistrement du succÃ¨s Phase 5"
      set_fact:
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_completed': ollama_deployment_status.phases_completed + ['validation']}) }}"

  rescue:
    - name: "Ollama | Ã‰chec Phase 5 - Validation"
      set_fact:
        ollama_deployment_failed: true
        ollama_failure_phase: "validation"
        ollama_failure_reason: "{{ ansible_failed_result.msg | default('Ã‰chec de la validation Ollama AI') }}"
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_failed': ollama_deployment_status.phases_failed + ['validation'], 'critical_errors': ollama_deployment_status.critical_errors + [ansible_failed_result.msg | default('Erreur de validation')]}) }}"

    - name: "Ollama | Log d'erreur Phase 5"
      lineinfile:
        path: "{{ ollama_error_handling.error_log_file }}"
        line: "[{{ ansible_date_time.iso8601 }}] ERREUR Phase 5 (Validation): {{ ollama_failure_reason }}"
        create: yes

    - name: "Ollama | DÃ©cision sur le rollback aprÃ¨s validation"
      debug:
        msg: 
          - "âš ï¸  Validation Ã©chouÃ©e mais Ollama AI peut Ãªtre partiellement fonctionnel"
          - "ğŸ¤– Les modÃ¨les de base peuvent toujours Ãªtre accessibles"
          - "ğŸ” VÃ©rifiez les logs pour plus de dÃ©tails"

    - name: "Ollama | ArrÃªt avec avertissement - Phase 5"
      fail:
        msg: "âš ï¸  DÃ©ploiement Ollama AI Service terminÃ© avec des erreurs de validation: {{ ollama_failure_reason }}"

  when:
    - ollama_deployment_failed is not defined
    - not ollama_deployment_config.skip_validation | bool
  tags:
    - ollama
    - ai-ml
    - validation
    - phase-5

# =========================================================================
# PHASE 6: CONFIGURATION DE LA SAUVEGARDE
# =========================================================================
- name: "Ollama | Phase 6 - Configuration de la sauvegarde"
  block:
    - name: "Ollama | Inclusion des tÃ¢ches de sauvegarde"
      include_tasks: backup.yml
      vars:
        current_phase: "backup"
        phase_description: "Configuration des stratÃ©gies de sauvegarde Ollama AI (modÃ¨les, configurations)"
        phase_number: 6

    - name: "Ollama | Enregistrement du succÃ¨s Phase 6"
      set_fact:
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'phases_completed': ollama_deployment_status.phases_completed + ['backup']}) }}"

  rescue:
    - name: "Ollama | Avertissement Phase 6 - Sauvegarde"
      debug:
        msg:
          - "âš ï¸  Ã‰chec de la configuration de sauvegarde Ollama AI"
          - "â„¹ï¸  Ollama AI fonctionne mais les sauvegardes automatiques des modÃ¨les sont dÃ©sactivÃ©es"
          - "ğŸ” Erreur: {{ ansible_failed_result.msg | default('Erreur de sauvegarde inconnue') }}"
          - "ğŸ’¡ Recommandation: Configurez manuellement la sauvegarde des modÃ¨les"

    - name: "Ollama | Log d'avertissement Phase 6"
      lineinfile:
        path: "{{ ollama_error_handling.error_log_file }}"
        line: "[{{ ansible_date_time.iso8601 }}] AVERTISSEMENT Phase 6 (Sauvegarde): {{ ansible_failed_result.msg | default('Erreur de sauvegarde') }}"
        create: yes

    - name: "Ollama | Marquage de la sauvegarde comme dÃ©faillante"
      set_fact:
        ollama_backup_failed: true
        ollama_deployment_status: "{{ ollama_deployment_status | combine({'warnings': ollama_deployment_status.warnings + ['Sauvegarde automatique Ollama AI dÃ©sactivÃ©e']}) }}"

  when:
    - ollama_deployment_failed is not defined
    - ollama_storage.backup_enabled | default(true) | bool
  tags:
    - ollama
    - ai-ml
    - backup
    - phase-6

# =========================================================================
# FINALISATION ET RAPPORT DE DÃ‰PLOIEMENT
# =========================================================================
- name: "Ollama | GÃ©nÃ©ration du rapport de dÃ©ploiement"
  set_fact:
    ollama_deployment_report:
      # Statut gÃ©nÃ©ral
      status: "{{ 'FAILED' if ollama_deployment_failed | default(false) else 'SUCCESS' }}"
      service_type: "ai-ml"
      component: "ollama"
      
      # MÃ©tadonnÃ©es de dÃ©ploiement
      environment: "{{ ollama_deployment_metadata.environment }}"
      namespace: "{{ ollama_deployment_metadata.namespace }}"
      cluster: "{{ ollama_deployment_metadata.cluster_name }}"
      deployment_id: "{{ ollama_deployment_metadata.deployment_id }}"
      started_at: "{{ ollama_deployment_metadata.started_at }}"
      completed_at: "{{ ansible_date_time.iso8601 }}"
      duration: "{{ (ansible_date_time.epoch | int) - (ollama_deployment_metadata.deployment_id | int) }}"
      
      # Statut des phases
      phases_completed: "{{ ollama_deployment_status.phases_completed }}"
      phases_failed: "{{ ollama_deployment_status.phases_failed }}"
      failed_phase: "{{ ollama_failure_phase | default('N/A') }}"
      failure_reason: "{{ ollama_failure_reason | default('N/A') }}"
      
      # Statut des composants
      monitoring_status: "{{ 'FAILED' if ollama_monitoring_failed | default(false) else 'OK' }}"
      backup_status: "{{ 'FAILED' if ollama_backup_failed | default(false) else 'OK' }}"
      
      # Informations du service
      ollama_version: "{{ ollama_service_meta.version }}"
      ollama_service_name: "{{ ollama_service_name }}"
      ollama_endpoint: "{{ ollama_service_name }}.{{ ollama_namespace }}.svc.cluster.local:{{ ollama_network.service.port }}"
      ollama_external_url: "{{ 'https' if ollama_ingress.tls.enabled else 'http' }}://{{ ollama_dns.full_domain }}"
      
      # Configuration spÃ©cifique IA
      gpu_enabled: "{{ ollama_deployment_config.enable_gpu }}"
      preload_models: "{{ ollama_deployment_config.preload_models }}"
      models_configured: "{{ ollama_app_config.models.preload_models | selectattr('enabled', 'equalto', true) | map(attribute='name') | list }}"
      
      # Alertes et avertissements
      warnings: "{{ ollama_deployment_status.warnings }}"
      critical_errors: "{{ ollama_deployment_status.critical_errors }}"
  tags:
    - ollama
    - ai-ml
    - report
    - always

- name: "Ollama | Affichage du rapport de dÃ©ploiement"
  debug:
    msg:
      - "=============================================="
      - "ğŸ¤– RAPPORT DE DÃ‰PLOIEMENT OLLAMA AI SERVICE"
      - "=============================================="
      - "ğŸ“ˆ Statut: {{ ollama_deployment_report.status }}"
      - "ğŸŒ Environnement: {{ ollama_deployment_report.environment }}"
      - "ğŸ·ï¸  Namespace: {{ ollama_deployment_report.namespace }}"
      - "ğŸ”§ Cluster: {{ ollama_deployment_report.cluster }}"
      - "ğŸ†” ID de dÃ©ploiement: {{ ollama_deployment_report.deployment_id }}"
      - "â° DurÃ©e: {{ ollama_deployment_report.duration }}s"
      - "ğŸ§© Version Ollama: {{ ollama_deployment_report.ollama_version }}"
      - "ğŸ”— Point de connexion interne: {{ ollama_deployment_report.ollama_endpoint }}"
      - "ğŸŒ URL externe: {{ ollama_deployment_report.ollama_external_url }}"
      - "âš¡ GPU activÃ©: {{ ollama_deployment_report.gpu_enabled }}"
      - "ğŸ“¦ ModÃ¨les configurÃ©s: {{ ollama_deployment_report.models_configured | join(', ') }}"
      - "ğŸ“Š Monitoring: {{ ollama_deployment_report.monitoring_status }}"
      - "ğŸ’¾ Sauvegarde: {{ ollama_deployment_report.backup_status }}"
      - "âœ… Phases rÃ©ussies: {{ ollama_deployment_report.phases_completed | join(', ') }}"
      - "{{ 'âŒ Phases Ã©chouÃ©es: ' + (ollama_deployment_report.phases_failed | join(', ')) if ollama_deployment_report.phases_failed | length > 0 else '' }}"
      - "{{ 'âš ï¸  Avertissements: ' + (ollama_deployment_report.warnings | join(', ')) if ollama_deployment_report.warnings | length > 0 else '' }}"
      - "{{ 'âŒ Phase d\'Ã©chec: ' + ollama_deployment_report.failed_phase if ollama_deployment_report.status == 'FAILED' else 'âœ… DÃ©ploiement rÃ©ussi' }}"
      - "{{ 'ğŸ” Raison: ' + ollama_deployment_report.failure_reason if ollama_deployment_report.status == 'FAILED' else '' }}"
      - "=============================================="
  tags:
    - ollama
    - ai-ml
    - report
    - always

- name: "Ollama | Sauvegarde du rapport de dÃ©ploiement"
  copy:
    content: "{{ ollama_deployment_report | to_nice_json }}"
    dest: "/tmp/ollama-deployment-report-{{ ollama_deployment_metadata.deployment_id }}.json"
    mode: '0644'
  delegate_to: localhost
  tags:
    - ollama
    - ai-ml
    - report

# =========================================================================
# NETTOYAGE ET FINALISATION
# =========================================================================
- name: "Ollama | Nettoyage des fichiers temporaires"
  file:
    path: "{{ item }}"
    state: absent
  loop:
    - "{{ ollama_error_handling.error_log_file }}"
    - "{{ ollama_error_handling.debug_log_file }}"
  when:
    - ollama_deployment_report.status == "SUCCESS"
    - not ollama_deployment_config.debug_mode | bool
  ignore_errors: yes
  tags:
    - ollama
    - ai-ml
    - cleanup

- name: "Ollama | Message de finalisation"
  debug:
    msg: |
      {% if ollama_deployment_report.status == 'SUCCESS' %}
      ğŸ‰ DÃ©ploiement Ollama AI Service terminÃ© avec succÃ¨s !

      ğŸ“‹ Informations de connexion:
      - ğŸ”— API interne: {{ ollama_deployment_report.ollama_endpoint }}
      - ğŸŒ URL externe: {{ ollama_deployment_report.ollama_external_url }}
      - ğŸšª Port: {{ ollama_network.service.port }}
      
      ğŸ¤– ModÃ¨les IA disponibles:
      {% for model in ollama_deployment_report.models_configured %}
      - {{ model }}
      {% endfor %}
      
      ğŸ“š Documentation disponible Ã : {{ ollama_service_meta.documentation_url }}
      ğŸ’¬ Support: {{ ollama_service_meta.support_channel }}
      {% else %}
      ğŸ’¥ DÃ©ploiement Ollama AI Service Ã©chouÃ© en phase {{ ollama_deployment_report.failed_phase }}

      ğŸ” Consultez les logs d'erreur pour plus de dÃ©tails:
      - Fichier d'erreur: {{ ollama_error_handling.error_log_file }}
      - Rapport JSON: /tmp/ollama-deployment-report-{{ ollama_deployment_metadata.deployment_id }}.json

      ğŸ› ï¸  Guide de dÃ©pannage: {{ ollama_service_meta.documentation_url }}/troubleshooting
      ğŸ’¬ Support: {{ ollama_service_meta.support_channel }}
      {% endif %}
  tags:
    - ollama
    - ai-ml
    - always