---
# =========================================================================
# LIONS INFRASTRUCTURE 5.0 - OLLAMA CONFIGMAP TEMPLATE
# =========================================================================
# Description: Template Jinja2 pour la ConfigMap d'Ollama avec intégration IA
# Version: 5.0.0
# Date: {{ ansible_date_time.iso8601 }}
# Maintainer: {{ lions_config_maintainer | default('devops@lions.dev') }}
# Documentation: https://docs.lions.dev/infrastructure/services/ollama
# =========================================================================

apiVersion: v1
kind: ConfigMap
metadata:
  name: "{{ lions_ollama_service_name | default('ollama') }}-config"
  namespace: "{{ lions_ollama_namespace | default('ai') }}"
  labels:
    # Labels standardisés LIONS
    app.kubernetes.io/name: "{{ lions_ollama_service_name | default('ollama') }}"
    app.kubernetes.io/instance: "{{ lions_ollama_service_name | default('ollama') }}-{{ lions_environment | default('development') }}"
    app.kubernetes.io/version: "{{ lions_ollama_version | default('0.1.26') }}"
    app.kubernetes.io/component: "ai-model-server"
    app.kubernetes.io/part-of: "lions-infrastructure"
    app.kubernetes.io/managed-by: "ansible"

    # Labels LIONS spécifiques
    lions.dev/environment: "{{ lions_environment | default('development') }}"
    lions.dev/service-type: "ai-service"
    lions.dev/tier: "ai"
    lions.dev/technology: "ollama"
    lions.dev/config-version: "5.0.0"

    # Labels techniques
    version: "{{ lions_ollama_version | default('0.1.26') }}"
    environment: "{{ lions_environment | default('development') }}"

  annotations:
    # Annotations de documentation
    description: "ConfigMap pour Ollama {{ lions_ollama_service_name | default('ollama') }} v{{ lions_ollama_version | default('0.1.26') }} en environnement {{ lions_environment | default('development') }}"
    lions.dev/documentation: "https://docs.lions.dev/infrastructure/services/ollama"
    lions.dev/contact: "{{ lions_config_maintainer | default('devops@lions.dev') }}"

    # Annotations de configuration
    config.lions.dev/generated-by: "ansible-{{ ansible_version.full }}"
    config.lions.dev/generated-on: "{{ ansible_date_time.iso8601 }}"
    config.lions.dev/checksum: "{{ (ollama_config_data | string) | hash('sha256') }}"

    # Annotations Kubernetes
    kubectl.kubernetes.io/last-applied-configuration: |
      Generated by LIONS Infrastructure Ansible automation

data:
  # =========================================================================
  # CONFIGURATION GÉNÉRALE OLLAMA
  # =========================================================================

  # Configuration de base
  OLLAMA_HOST: "0.0.0.0:{{ lions_ollama_port | default('11434') }}"
  OLLAMA_ORIGINS: "{{ ollama_allowed_origins | default('*') }}"
  OLLAMA_MODELS: "{{ ollama_models_dir | default('/root/.ollama/models') }}"
  OLLAMA_RUNNERS_DIR: "{{ ollama_runners_dir | default('/tmp/ollama_runners') }}"

  # Configuration d'environnement
  OLLAMA_ENV: "{{ lions_environment | default('development') }}"
  OLLAMA_DEBUG: "{{ lions_debug_mode | default('false') | string | lower }}"
  OLLAMA_LOG_LEVEL: "{{ lions_log_level | default('INFO') | lower }}"

  # Configuration réseau et API
  OLLAMA_API_BASE_URL: "{{ ollama_api_base_url | default('http://localhost:' + (lions_ollama_port | default('11434') | string)) }}"
  OLLAMA_EXTERNAL_URL: "https://{{ lions_ollama_service_name | default('ollama') }}.{{ lions_dns_full_domain | default('dev.lions.local') }}"
  OLLAMA_KEEP_ALIVE: "{{ ollama_keep_alive | default('5m') }}"
  OLLAMA_MAX_CONNECTIONS: "{{ ollama_max_connections | default('100') }}"

  # =========================================================================
  # CONFIGURATION DES MODÈLES IA
  # =========================================================================

  # Configuration des modèles par défaut
  OLLAMA_DEFAULT_MODELS: |
    {% set default_models = ollama_default_models | default([
      'llama3.2:3b',
      'mistral:7b',
      'codellama:7b'
    ]) %}
    {% for model in default_models %}
    - name: "{{ model.split(':')[0] }}"
      tag: "{{ model.split(':')[1] if ':' in model else 'latest' }}"
      full_name: "{{ model }}"
      auto_load: {{ model in (ollama_auto_load_models | default([])) }}
    {% endfor %}

  # Configuration avancée des modèles
  OLLAMA_MODEL_CONFIG: |
    # Configuration générale des modèles
    default_context_length: {{ ollama_default_context_length | default('4096') }}
    max_context_length: {{ ollama_max_context_length | default('32768') }}

    # Configuration par type de modèle
    model_configs:
      llm:
        temperature: {{ ollama_llm_temperature | default('0.7') }}
        top_p: {{ ollama_llm_top_p | default('0.9') }}
        top_k: {{ ollama_llm_top_k | default('40') }}
        repeat_penalty: {{ ollama_llm_repeat_penalty | default('1.1') }}

      code:
        temperature: {{ ollama_code_temperature | default('0.1') }}
        top_p: {{ ollama_code_top_p | default('0.95') }}
        stop_sequences: ["```", "END_CODE"]

      embedding:
        normalize: {{ ollama_embedding_normalize | default('true') }}
        dimensions: {{ ollama_embedding_dimensions | default('768') }}

  # =========================================================================
  # CONFIGURATION SYSTÈME ET PERFORMANCE
  # =========================================================================

  # Configuration des ressources système
  OLLAMA_NUM_PARALLEL: "{{ ollama_num_parallel | default('4') }}"
  OLLAMA_MAX_LOADED_MODELS: "{{ ollama_max_loaded_models | default('3') }}"
  OLLAMA_MAX_QUEUE: "{{ ollama_max_queue | default('512') }}"
  OLLAMA_FLASH_ATTENTION: "{{ ollama_flash_attention | default('true') }}"

  # Configuration GPU
  OLLAMA_GPU_ENABLED: "{{ lions_ollama_gpu_enabled | default('false') | string | lower }}"
  {% if lions_ollama_gpu_enabled | default(false) %}
  CUDA_VISIBLE_DEVICES: "{{ ollama_cuda_devices | default('0') }}"
  OLLAMA_GPU_MEMORY_FRACTION: "{{ ollama_gpu_memory_fraction | default('0.8') }}"
  OLLAMA_GPU_SPLIT_MODE: "{{ ollama_gpu_split_mode | default('auto') }}"
  {% endif %}

  # Configuration mémoire
  OLLAMA_MEMORY_LIMIT: "{{ ollama_memory_limit | default('4GB') }}"
  OLLAMA_SWAP_SIZE: "{{ ollama_swap_size | default('2GB') }}"
  OLLAMA_GC_INTERVAL: "{{ ollama_gc_interval | default('10m') }}"

  # Configuration threads et CPU
  OLLAMA_NUM_THREADS: "{{ ollama_num_threads | default(ansible_processor_vcpus | default('4')) }}"
  OLLAMA_CPU_AFFINITY: "{{ ollama_cpu_affinity | default('auto') }}"

  # =========================================================================
  # CONFIGURATION DE SÉCURITÉ
  # =========================================================================

  # Configuration d'authentification
  OLLAMA_AUTH_ENABLED: "{{ ollama_auth_enabled | default('true') | string | lower }}"
  {% if ollama_auth_enabled | default(true) %}
  OLLAMA_API_KEY_REQUIRED: "{{ ollama_api_key_required | default('true') | string | lower }}"
  OLLAMA_ALLOWED_IPS: "{{ ollama_allowed_ips | default('10.0.0.0/8,172.16.0.0/12,192.168.0.0/16') }}"
  {% endif %}

  # Configuration TLS/SSL
  OLLAMA_TLS_ENABLED: "{{ lions_security_tls_enabled | default('true') | string | lower }}"
  {% if lions_security_tls_enabled | default(true) %}
  OLLAMA_TLS_CERT_PATH: "{{ ollama_tls_cert_path | default('/etc/ssl/certs/ollama.crt') }}"
  OLLAMA_TLS_KEY_PATH: "{{ ollama_tls_key_path | default('/etc/ssl/private/ollama.key') }}"
  OLLAMA_TLS_MIN_VERSION: "{{ ollama_tls_min_version | default('1.2') }}"
  {% endif %}

  # Configuration de sécurité des modèles
  OLLAMA_MODEL_SECURITY: |
    # Restrictions sur les modèles
    max_model_size: "{{ ollama_max_model_size | default('10GB') }}"
    allowed_model_sources:
    {% for source in (ollama_allowed_model_sources | default(['huggingface.co', 'ollama.ai'])) %}
      - "{{ source }}"
    {% endfor %}

    # Validation des modèles
    verify_model_checksums: {{ ollama_verify_checksums | default('true') }}
    scan_models_for_malware: {{ ollama_scan_malware | default('true') }}

  # =========================================================================
  # CONFIGURATION DE MONITORING ET OBSERVABILITÉ
  # =========================================================================

  # Configuration des métriques
  OLLAMA_METRICS_ENABLED: "{{ lions_monitoring_enabled | default('true') | string | lower }}"
  {% if lions_monitoring_enabled | default(true) %}
  OLLAMA_METRICS_PATH: "{{ ollama_metrics_path | default('/metrics') }}"
  OLLAMA_METRICS_PORT: "{{ ollama_metrics_port | default('9090') }}"
  OLLAMA_METRICS_INTERVAL: "{{ ollama_metrics_interval | default('30s') }}"
  {% endif %}

  # Configuration des logs
  OLLAMA_LOG_FORMAT: "{{ lions_log_format | default('json') }}"
  OLLAMA_LOG_OUTPUT: "{{ lions_log_output | default('stdout') }}"
  OLLAMA_LOG_ROTATION: "{{ ollama_log_rotation | default('daily') }}"
  OLLAMA_LOG_MAX_SIZE: "{{ ollama_log_max_size | default('100MB') }}"
  OLLAMA_LOG_MAX_FILES: "{{ ollama_log_max_files | default('10') }}"

  # Configuration du tracing
  OLLAMA_TRACING_ENABLED: "{{ ollama_tracing_enabled | default('false') | string | lower }}"
  {% if ollama_tracing_enabled | default(false) %}
  OLLAMA_JAEGER_ENDPOINT: "{{ ollama_jaeger_endpoint | default('http://jaeger-collector:14268/api/traces') }}"
  OLLAMA_TRACE_SAMPLING_RATE: "{{ ollama_trace_sampling_rate | default('0.1') }}"
  {% endif %}

  # =========================================================================
  # CONFIGURATION D'INTÉGRATION
  # =========================================================================

  # Intégration avec les services LIONS
  LIONS_INTEGRATION_CONFIG: |
    # Configuration Keycloak (si activé)
    {% if lions_keycloak_enabled | default(true) %}
    keycloak:
      enabled: true
      server_url: "https://{{ lions_keycloak_service_name | default('keycloak') }}.{{ lions_dns_full_domain | default('dev.lions.local') }}"
      realm: "{{ lions_keycloak_realm | default('lions') }}"
      client_id: "ollama-service"
    {% endif %}

    # Configuration PostgreSQL (si activé)
    {% if lions_postgres_enabled | default(true) %}
    database:
      enabled: true
      host: "{{ lions_postgres_service_name | default('postgresql') }}.{{ lions_postgres_namespace | default('database') }}.svc.cluster.local"
      port: {{ lions_postgres_port | default('5432') }}
      database: "ollama_db"
    {% endif %}

    # Configuration Redis (si activé)
    {% if lions_redis_enabled | default(true) %}
    cache:
      enabled: true
      host: "{{ lions_redis_service_name | default('redis') }}.{{ lions_redis_namespace | default('database') }}.svc.cluster.local"
      port: {{ lions_redis_port | default('6379') }}
      ttl: "{{ ollama_cache_ttl | default('3600') }}"
    {% endif %}

  # Configuration des webhooks et notifications
  OLLAMA_WEBHOOKS_CONFIG: |
    # Webhooks pour les événements de modèles
    {% if ollama_webhooks_enabled | default(false) %}
    webhooks:
      model_loaded:
        url: "{{ ollama_webhook_model_loaded | default('') }}"
        enabled: {{ (ollama_webhook_model_loaded | default('')) != '' }}

      model_unloaded:
        url: "{{ ollama_webhook_model_unloaded | default('') }}"
        enabled: {{ (ollama_webhook_model_unloaded | default('')) != '' }}

      generation_complete:
        url: "{{ ollama_webhook_generation_complete | default('') }}"
        enabled: {{ (ollama_webhook_generation_complete | default('')) != '' }}
    {% endif %}

  # =========================================================================
  # CONFIGURATION SPÉCIFIQUE PAR ENVIRONNEMENT
  # =========================================================================

  # Configuration par environnement
  OLLAMA_ENV_CONFIG: |
    environment: "{{ lions_environment | default('development') }}"

    {% if lions_environment == 'development' %}
    # Configuration développement
    auto_pull_models: true
    enable_model_playground: true
    debug_api: true
    relaxed_cors: true

    {% elif lions_environment == 'staging' %}
    # Configuration staging
    auto_pull_models: false
    enable_model_playground: true
    debug_api: false
    strict_validation: true

    {% elif lions_environment == 'production' %}
    # Configuration production
    auto_pull_models: false
    enable_model_playground: false
    debug_api: false
    strict_validation: true
    performance_monitoring: true
    {% endif %}

  # =========================================================================
  # CONFIGURATION DE SAUVEGARDE ET RESTAURATION
  # =========================================================================

  {% if lions_backup_enabled | default(true) %}
  OLLAMA_BACKUP_CONFIG: |
    backup:
      enabled: {{ lions_backup_enabled | default('true') }}
      schedule: "{{ ollama_backup_schedule | default('0 2 * * *') }}"  # 2AM daily
      retention_days: {{ lions_backup_retention_days | default('30') }}

      # Éléments à sauvegarder
      include:
        - models
        - configurations
        - user_data
        - chat_histories

      # Configuration S3/MinIO (si configuré)
      {% if lions_backup_external_enabled | default(false) %}
      external_storage:
        type: "{{ lions_backup_external_type | default('s3') }}"
        bucket: "{{ lions_backup_external_bucket | default('lions-backup-' + lions_environment) }}"
        encryption: {{ lions_backup_encryption | default('true') }}
      {% endif %}
  {% endif %}

  # =========================================================================
  # CONFIGURATION DE SANTÉ ET DIAGNOSTIC
  # =========================================================================

  # Configuration des health checks
  OLLAMA_HEALTH_CONFIG: |
    health_checks:
      startup_timeout: {{ ollama_startup_timeout | default('300') }}s
      readiness_timeout: {{ ollama_readiness_timeout | default('30') }}s
      liveness_timeout: {{ ollama_liveness_timeout | default('10') }}s

      # Checks personnalisés
      custom_checks:
        - name: "model_availability"
          endpoint: "/api/tags"
          expected_models: {{ ollama_expected_models | default('1') }}

        - name: "memory_usage"
          threshold: {{ ollama_memory_threshold | default('80') }}%

        - name: "gpu_status"
          enabled: {{ lions_ollama_gpu_enabled | default('false') }}

  # =========================================================================
  # MÉTADONNÉES DE CONFIGURATION
  # =========================================================================

  # Informations de configuration pour debugging
  LIONS_CONFIG_INFO: |
    # Informations de génération
    generated_by: "ansible-{{ ansible_version.full }}"
    generated_on: "{{ ansible_date_time.iso8601 }}"
    config_version: "5.0.0"

    # Informations d'environnement
    target_environment: "{{ lions_environment | default('development') }}"
    kubernetes_version: "{{ lions_k8s_version | default('v1.30.2+k3s1') }}"

    # Variables utilisées
    variables_checksum: "{{ (hostvars[inventory_hostname] | dict2items | selectattr('key', 'match', '^lions_.*|^ollama_.*') | list | string) | hash('sha256') }}"
