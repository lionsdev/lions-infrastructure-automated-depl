---
# =============================================================================
# LIONS Infrastructure - Playbook d'Installation K3s Complet avec Monitoring
# =============================================================================
# Titre: Playbook d'installation K3s optimisé avec Prometheus/Grafana intégré
# Description: Installe et configure K3s sur VPS avec monitoring complet
# Auteur: Équipe LIONS Infrastructure
# Date: 2025-05-23
# Version: 2.1.0
#
# Corrections appliquées:
# - Suppression du flag déprécié RemoveSelfLink=false
# - Correction de la syntaxe des flags --disable
# - Ajout du déploiement Prometheus/Grafana optimisé
# - Configuration monitoring haute performance
# - Amélioration de la documentation et du logging
# - Application des meilleures pratiques DevOps
# =============================================================================

- name: "LIONS K3s Installation - Production Ready Deployment with Monitoring"
  hosts: vps
  become: yes
  gather_facts: yes

  # =============================================================================
  # VARIABLES DE CONFIGURATION
  # =============================================================================
  vars:
    # Version K3s - Version LTS stable recommandée
    k3s_version: "v1.28.6+k3s2"

    # Configuration K3s optimisée (FLAGS CORRIGÉS)
    k3s_server_args: >-
      server
      --disable=traefik
      --disable=servicelb
      --disable=local-storage
      --write-kubeconfig-mode=644
      --kubelet-arg=cgroup-driver=systemd
      --kubelet-arg=feature-gates=GracefulNodeShutdown=false

    # Chemins et configurations
    kubeconfig_local_path: "~/.kube/config"
    k3s_service_file: "/etc/systemd/system/k3s.service"
    k3s_kubeconfig: "/etc/rancher/k3s/k3s.yaml"

    # Versions des composants
    traefik_chart_version: "25.0.0"
    metallb_chart_version: "0.13.12"
    cert_manager_version: "v1.13.3"
    kube_prometheus_stack_version: "56.21.4"

    # Flags dépréciés à supprimer automatiquement
    deprecated_flags:
      - pattern: "--kube-controller-manager-arg.*feature-gates=.*RemoveSelfLink=false.*"
        replacement: ""
        description: "Flag RemoveSelfLink déprécié"
      - pattern: "--no-deploy ([a-zA-Z0-9-]+)"
        replacement: "--disable=\\1"
        description: "Syntaxe --no-deploy dépréciée"

    # Configuration monitoring optimisée
    monitoring_config:
      namespace: "monitoring"
      grafana_admin_password: "{{ lions_grafana_password | default('admin123!') }}"
      prometheus_retention: "15d"
      prometheus_storage: "10Gi"
      grafana_storage: "5Gi"
      resource_limits:
        prometheus_cpu: "1000m"
        prometheus_memory: "2Gi"
        grafana_cpu: "500m"
        grafana_memory: "512Mi"

  # =============================================================================
  # TÂCHES PRINCIPALES
  # =============================================================================
  tasks:

    # =========================================================================
    # PHASE 1: VÉRIFICATIONS PRÉLIMINAIRES ET NETTOYAGE
    # =========================================================================

    - name: "📋 PHASE 1 - Vérifications préliminaires"
      debug:
        msg: |
          ==========================================================
          🚀 DÉMARRAGE INSTALLATION K3S - LIONS INFRASTRUCTURE
          ==========================================================
          Version K3s: {{ k3s_version }}
          Host cible: {{ ansible_host }}
          Environment: {{ lions_env | default('development') }}
          Monitoring: ✅ Prometheus + Grafana inclus
          ==========================================================

    - name: "🔍 Vérification de l'environnement système"
      block:
        - name: "Vérification des ressources système minimales"
          assert:
            that:
              - ansible_memtotal_mb >= 2048  # Augmenté pour le monitoring
              - ansible_processor_vcpus >= 2
            fail_msg: "Ressources système insuffisantes pour le monitoring (RAM: {{ ansible_memtotal_mb }}MB, CPU: {{ ansible_processor_vcpus }})"
            success_msg: "✅ Ressources système suffisantes (RAM: {{ ansible_memtotal_mb }}MB, CPU: {{ ansible_processor_vcpus }})"

        - name: "Vérification de l'espace disque disponible"
          shell: df / | awk 'NR==2 {print $4}'
          register: disk_space_check
          changed_when: false

        - name: "Validation de l'espace disque"
          assert:
            that:
              - disk_space_check.stdout | int > 10000000  # 10GB minimum pour le monitoring
            fail_msg: "Espace disque insuffisant: {{ (disk_space_check.stdout | int / 1000 / 1000) | round(1) }}GB disponible"
            success_msg: "✅ Espace disque suffisant: {{ (disk_space_check.stdout | int / 1000 / 1000) | round(1) }}GB disponible"

      rescue:
        - name: "❌ Échec des vérifications préliminaires"
          fail:
            msg: "Les vérifications système ont échoué. Installation annulée."

    - name: "🧹 Détection et nettoyage de l'installation K3s existante"
      block:
        - name: "Vérification de l'existence du binaire K3s"
          stat:
            path: /usr/local/bin/k3s
          register: k3s_binary_exists

        - name: "Vérification du service K3s existant"
          systemd:
            name: k3s
          register: k3s_service_check
          ignore_errors: true

        - name: "Analyse de l'état du service K3s"
          debug:
            msg: |
              K3s Binary: {{ 'Présent' if k3s_binary_exists.stat.exists else 'Absent' }}
              Service K3s: {{ k3s_service_check.status.ActiveState | default('Inexistant') }}

        - name: "Correction proactive des flags dépréciés"
          block:
            - name: "Lecture du fichier de service K3s"
              slurp:
                src: "{{ k3s_service_file }}"
              register: k3s_service_content_raw
              when: k3s_binary_exists.stat.exists

            - name: "Décodage du contenu du service"
              set_fact:
                k3s_service_content: "{{ k3s_service_content_raw.content | b64decode }}"
              when: k3s_service_content_raw is defined

            - name: "🔍 Diagnostic du contenu du service K3s"
              debug:
                msg: |
                  Contenu du service K3s:
                  {{ k3s_service_content }}
              when: k3s_service_content is defined

            - name: "Détection des flags dépréciés"
              set_fact:
                deprecated_flags_found: "{{ deprecated_flags_found | default([]) + [item] }}"
              loop: "{{ deprecated_flags }}"
              when:
                - k3s_service_content is defined
                - k3s_service_content is search(item.pattern)

            - name: "Notification des flags dépréciés détectés"
              debug:
                msg: |
                  ⚠️  FLAGS DÉPRÉCIÉS DÉTECTÉS:
                  {% for flag in deprecated_flags_found | default([]) %}
                  - {{ flag.description }}
                  {% endfor %}
              when: deprecated_flags_found is defined and deprecated_flags_found | length > 0

            - name: "Suppression des flags dépréciés"
              replace:
                path: "{{ k3s_service_file }}"
                regexp: "{{ item.pattern }}"
                replace: "{{ item.replacement | default('') }}"
                backup: yes
              loop: "{{ deprecated_flags }}"
              when:
                - k3s_service_content is defined
                - k3s_service_content is search(item.pattern)
              register: flags_corrected
              notify: "reload systemd and restart k3s"

            - name: "🔧 Correction forcée du flag RemoveSelfLink (solution de secours)"
              replace:
                path: "{{ k3s_service_file }}"
                regexp: "RemoveSelfLink=false"
                replace: ""
                backup: yes
              when:
                - k3s_service_content is defined
                - "'RemoveSelfLink=false' in k3s_service_content"
              register: forced_correction
              notify: "reload systemd and restart k3s"

            - name: "📋 Rapport de correction des flags"
              debug:
                msg: |
                  Flags corrigés automatiquement: {{ 'Oui' if flags_corrected.changed else 'Non' }}
                  Correction forcée effectuée: {{ 'Oui' if forced_correction.changed else 'Non' }}

          when: k3s_binary_exists.stat.exists

    # =========================================================================
    # PHASE 2: INSTALLATION K3S
    # =========================================================================

    - name: "🚀 PHASE 2 - Installation K3s"
      debug:
        msg: "Démarrage de l'installation K3s avec la configuration corrigée"

    - name: "📥 Téléchargement du script d'installation K3s"
      get_url:
        url: "https://get.k3s.io"
        dest: "/tmp/k3s-install.sh"
        mode: '0755'
        timeout: 30
      register: k3s_script_download
      retries: 3
      delay: 5

    - name: "⚙️  Installation K3s avec configuration optimisée"
      command: "/tmp/k3s-install.sh"
      environment:
        INSTALL_K3S_VERSION: "{{ k3s_version }}"
        INSTALL_K3S_EXEC: "{{ k3s_server_args }}"
        K3S_KUBECONFIG_MODE: "644"
      register: k3s_installation
      when: not k3s_binary_exists.stat.exists or (deprecated_flags_found is defined and deprecated_flags_found | length > 0)

    - name: "🔄 Démarrage et activation du service K3s"
      systemd:
        name: k3s
        state: started
        enabled: yes
        daemon_reload: yes
      register: k3s_service_start
      retries: 3
      delay: 10

    # =========================================================================
    # PHASE 3: VÉRIFICATIONS POST-INSTALLATION
    # =========================================================================

    - name: "✅ PHASE 3 - Vérifications post-installation"
      debug:
        msg: "Vérification de l'installation K3s"

    - name: "⏳ Attente de la disponibilité de l'API K3s"
      wait_for:
        port: 6443
        host: localhost
        delay: 10
        timeout: 300
      register: k3s_api_ready

    - name: "🔍 Vérification de l'état du service K3s"
      systemd:
        name: k3s
      register: k3s_final_status

    - name: "📊 Validation de l'installation K3s"
      block:
        - name: "Test de connectivité kubectl"
          command: "/usr/local/bin/k3s kubectl get nodes"
          register: k3s_nodes_check
          changed_when: false
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Vérification des pods système"
          command: "/usr/local/bin/k3s kubectl get pods -n kube-system"
          register: k3s_system_pods
          changed_when: false
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "📈 Rapport d'état K3s"
          debug:
            msg: |
              ==========================================================
              ✅ K3S INSTALLATION RÉUSSIE
              ==========================================================
              Service Status: {{ k3s_final_status.status.ActiveState }}
              API Port: ✅ Accessible sur :6443
              Nodes: {{ k3s_nodes_check.stdout_lines | length }} nœud(s) détecté(s)
              System Pods: {{ k3s_system_pods.stdout_lines | length - 1 }} pod(s) système
              ==========================================================

      rescue:
        - name: "🔧 Diagnostic en cas d'échec"
          block:
            - name: "Collecte des logs K3s"
              command: "journalctl -u k3s -n 20 --no-pager"
              register: k3s_logs

            - name: "🔍 Vérification du contenu actuel du service K3s"
              slurp:
                src: "{{ k3s_service_file }}"
              register: current_service_content

            - name: "📋 Diagnostic détaillé"
              debug:
                msg: |
                  ❌ ÉCHEC DE L'INSTALLATION K3S - DIAGNOSTIC DÉTAILLÉ
                  ==========================================================
                  Service Status: {{ k3s_final_status.status.ActiveState | default('Unknown') }}
                  
                  Contenu actuel du service K3s:
                  {{ current_service_content.content | b64decode }}
                  
                  Derniers logs:
                  {{ k3s_logs.stdout }}
                  ==========================================================

            - name: "🔧 Nettoyage complet et réinstallation si flag RemoveSelfLink détecté"
              block:
                - name: "Arrêt du service K3s"
                  systemd:
                    name: k3s
                    state: stopped
                  ignore_errors: true

                - name: "Désinstallation complète de K3s"
                  shell: |
                    /usr/local/bin/k3s-uninstall.sh || true
                    rm -rf /etc/rancher/k3s/*
                    rm -rf /var/lib/rancher/k3s/*
                    rm -f /etc/systemd/system/k3s.service*
                  ignore_errors: true

                - name: "Rechargement systemd"
                  systemd:
                    daemon_reload: yes

                - name: "Réinstallation propre de K3s"
                  command: "/tmp/k3s-install.sh"
                  environment:
                    INSTALL_K3S_VERSION: "{{ k3s_version }}"
                    INSTALL_K3S_EXEC: "{{ k3s_server_args }}"
                    K3S_KUBECONFIG_MODE: "644"

                - name: "Démarrage du service K3s après réinstallation"
                  systemd:
                    name: k3s
                    state: started
                    enabled: yes
                    daemon_reload: yes
                  register: k3s_fresh_start

                - name: "Attente de l'API après réinstallation"
                  wait_for:
                    port: 6443
                    host: localhost
                    timeout: 120
                  when: k3s_fresh_start is succeeded

              when: "'RemoveSelfLink=false' in (current_service_content.content | b64decode)"

            - name: "❌ Échec définitif si problème persiste"
              fail:
                msg: |
                  ❌ INSTALLATION K3S ÉCHOUÉE DÉFINITIVEMENT
                  Le flag RemoveSelfLink=false cause toujours des problèmes.
                  Vérifiez manuellement le fichier {{ k3s_service_file }}
                  et supprimez toute référence à RemoveSelfLink=false
              when:
                - "'RemoveSelfLink=false' in (current_service_content.content | b64decode)"
                - k3s_fresh_start is failed

    # =========================================================================
    # PHASE 4: CONFIGURATION KUBECTL ET KUBECONFIG
    # =========================================================================

    - name: "🔧 PHASE 4 - Configuration kubectl et kubeconfig"
      debug:
        msg: "Configuration de l'accès kubectl"

    - name: "🔍 Détection de l'utilisateur courant"
      set_fact:
        current_user: "{{ ansible_user | default(ansible_user_id) | default('root') }}"
        current_user_home: "{{ ansible_user_dir | default('/root') }}"

    - name: "📁 Création des répertoires de configuration"
      file:
        path: "{{ item }}"
        state: directory
        mode: '0755'
        owner: "{{ current_user }}"
        group: "{{ current_user }}"
      loop:
        - "{{ current_user_home }}/.kube"
        - "/root/.kube"

    - name: "📄 Configuration du kubeconfig utilisateur"
      copy:
        src: "{{ k3s_kubeconfig }}"
        dest: "{{ current_user_home }}/.kube/config"
        remote_src: yes
        owner: "{{ current_user }}"
        group: "{{ current_user }}"
        mode: '0600'
      when:
        - k3s_kubeconfig is exists
        - current_user_home != '/root'

    - name: "📄 Configuration du kubeconfig root"
      copy:
        src: "{{ k3s_kubeconfig }}"
        dest: "/root/.kube/config"
        remote_src: yes
        mode: '0600'
      when: k3s_kubeconfig is exists

    - name: "🌐 Mise à jour du kubeconfig avec l'IP externe (utilisateur)"
      replace:
        path: "{{ current_user_home }}/.kube/config"
        regexp: 'https://127.0.0.1:6443'
        replace: 'https://{{ ansible_host }}:6443'
      when: current_user_home != '/root'

    - name: "🌐 Mise à jour du kubeconfig avec l'IP externe (root)"
      replace:
        path: "/root/.kube/config"
        regexp: 'https://127.0.0.1:6443'
        replace: 'https://{{ ansible_host }}:6443'

    - name: "📁 Création du fichier .bashrc si nécessaire"
      file:
        path: "{{ current_user_home }}/.bashrc"
        state: touch
        owner: "{{ current_user }}"
        group: "{{ current_user }}"
        mode: '0644'
      when: current_user_home != '/root'

    - name: "⚙️  Configuration de l'environnement bash"
      lineinfile:
        path: "{{ current_user_home }}/.bashrc"
        line: "export KUBECONFIG={{ current_user_home }}/.kube/config"
        state: present
      when: current_user_home != '/root'

    # =========================================================================
    # PHASE 5: INSTALLATION DES OUTILS COMPLÉMENTAIRES
    # =========================================================================

    - name: "🛠️  PHASE 5 - Installation des outils complémentaires"
      debug:
        msg: "Installation de kubectl et Helm"

    - name: "📦 Installation de kubectl"
      block:
        - name: "Création du répertoire pour les clés GPG"
          file:
            path: /etc/apt/keyrings
            state: directory
            mode: '0755'

        - name: "Téléchargement de la clé GPG Kubernetes"
          get_url:
            url: "https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key"
            dest: "/tmp/kubernetes-release.key"
            mode: '0644'

        - name: "Installation de la clé GPG Kubernetes"
          shell: |
            cat /tmp/kubernetes-release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
          args:
            creates: /etc/apt/keyrings/kubernetes-apt-keyring.gpg

        - name: "Ajout du dépôt Kubernetes"
          apt_repository:
            repo: "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /"
            state: present
            filename: kubernetes

        - name: "Installation de kubectl"
          apt:
            name: kubectl
            state: present
            update_cache: yes

    - name: "🎛️  Installation de Helm"
      block:
        - name: "Téléchargement du script d'installation Helm"
          get_url:
            url: "https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3"
            dest: "/tmp/get-helm-3.sh"
            mode: '0755'

        - name: "Exécution de l'installation Helm"
          command: "/tmp/get-helm-3.sh"
          args:
            creates: /usr/local/bin/helm

    - name: "🐍 Installation des dépendances Python Kubernetes"
      pip:
        name:
          - kubernetes>=28.0.0
          - openshift>=0.13.0
          - PyYAML>=6.0
        state: present
        extra_args: "--upgrade"

    # =========================================================================
    # PHASE 6: DÉPLOIEMENT DE L'INFRASTRUCTURE DE BASE
    # =========================================================================

    - name: "🏗️  PHASE 6 - Déploiement de l'infrastructure de base"
      debug:
        msg: "Déploiement des composants d'infrastructure essentiels"

    - name: "🌐 Déploiement de Traefik (Ingress Controller)"
      block:
        - name: "Ajout du dépôt Helm Traefik"
          kubernetes.core.helm_repository:
            name: traefik
            repo_url: "https://helm.traefik.io/traefik"
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Création du namespace Traefik"
          kubernetes.core.k8s:
            name: traefik
            api_version: v1
            kind: Namespace
            state: present
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Déploiement de Traefik via Helm"
          kubernetes.core.helm:
            name: traefik
            chart_ref: "traefik/traefik"
            chart_version: "{{ traefik_chart_version }}"
            release_namespace: traefik
            create_namespace: true
            wait: true
            wait_timeout: "600s"
            values:
              deployment:
                replicas: 1
              ports:
                web:
                  port: 80
                  expose: true
                  exposedPort: 80
                websecure:
                  port: 443
                  expose: true
                  exposedPort: 443
              service:
                type: LoadBalancer
                spec:
                  externalIPs:
                    - "{{ ansible_host }}"
              ingressClass:
                enabled: true
                isDefaultClass: true
              logs:
                general:
                  level: INFO
              metrics:
                prometheus:
                  enabled: true
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

    - name: "🔒 Déploiement de cert-manager (Gestion TLS)"
      block:
        - name: "Ajout du dépôt Helm cert-manager"
          kubernetes.core.helm_repository:
            name: jetstack
            repo_url: "https://charts.jetstack.io"
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Nettoyage des CRDs cert-manager orphelins"
          kubernetes.core.k8s:
            name: "{{ item }}"
            api_version: apiextensions.k8s.io/v1
            kind: CustomResourceDefinition
            state: absent
          loop:
            - certificaterequests.cert-manager.io
            - certificates.cert-manager.io
            - challenges.acme.cert-manager.io
            - clusterissuers.cert-manager.io
            - issuers.cert-manager.io
            - orders.acme.cert-manager.io
          ignore_errors: true
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Déploiement de cert-manager"
          kubernetes.core.helm:
            name: cert-manager
            chart_ref: "jetstack/cert-manager"
            chart_version: "{{ cert_manager_version }}"
            release_namespace: cert-manager
            create_namespace: true
            wait: true
            wait_timeout: "600s"
            values:
              installCRDs: true
              global:
                leaderElection:
                  namespace: cert-manager
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

    - name: "⚖️  Déploiement de MetalLB (Load Balancer)"
      block:
        - name: "Ajout du dépôt Helm MetalLB"
          kubernetes.core.helm_repository:
            name: metallb
            repo_url: "https://metallb.github.io/metallb"
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Déploiement de MetalLB"
          kubernetes.core.helm:
            name: metallb
            chart_ref: "metallb/metallb"
            chart_version: "{{ metallb_chart_version }}"
            release_namespace: metallb-system
            create_namespace: true
            wait: true
            wait_timeout: "600s"
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Configuration IPAddressPool MetalLB"
          kubernetes.core.k8s:
            state: present
            definition:
              apiVersion: metallb.io/v1beta1
              kind: IPAddressPool
              metadata:
                name: lions-ip-pool
                namespace: metallb-system
              spec:
                addresses:
                  - "{{ ansible_host }}/32"
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Configuration L2Advertisement MetalLB"
          kubernetes.core.k8s:
            state: present
            definition:
              apiVersion: metallb.io/v1beta1
              kind: L2Advertisement
              metadata:
                name: lions-l2-advert
                namespace: metallb-system
              spec:
                ipAddressPools:
                  - lions-ip-pool
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

    # =========================================================================
    # PHASE 7: DÉPLOIEMENT DU MONITORING COMPLET (NOUVELLE PHASE)
    # =========================================================================

    - name: "📊 PHASE 7 - Déploiement du système de monitoring complet"
      debug:
        msg: |
          Déploiement de Prometheus et Grafana avec configuration optimisée
          Namespace: {{ monitoring_config.namespace }}
          Rétention Prometheus: {{ monitoring_config.prometheus_retention }}

    - name: "📊 Préparation du monitoring"
      block:
        - name: "Création du namespace monitoring"
          kubernetes.core.k8s:
            name: "{{ monitoring_config.namespace }}"
            api_version: v1
            kind: Namespace
            state: present
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Ajout du dépôt Helm Prometheus Community"
          kubernetes.core.helm_repository:
            name: prometheus-community
            repo_url: "https://prometheus-community.github.io/helm-charts"
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Mise à jour des dépôts Helm"
          command: "helm repo update"
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

    - name: "🔍 Nettoyage des installations monitoring précédentes"
      block:
        - name: "Vérification de l'existence d'une installation Prometheus existante"
          command: "helm list -n {{ monitoring_config.namespace }} --filter prometheus"
          register: existing_prometheus
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"
          ignore_errors: yes

        - name: "Suppression de l'installation Prometheus défaillante si nécessaire"
          command: "helm uninstall prometheus -n {{ monitoring_config.namespace }}"
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"
          when:
            - existing_prometheus.stdout is defined
            - "'failed' in existing_prometheus.stdout or 'pending' in existing_prometheus.stdout"
          ignore_errors: yes

        - name: "Attente de la suppression complète"
          pause:
            seconds: 30
          when:
            - existing_prometheus.stdout is defined
            - "'failed' in existing_prometheus.stdout or 'pending' in existing_prometheus.stdout"

    - name: "🚀 Déploiement de kube-prometheus-stack optimisé"
      kubernetes.core.helm:
        name: prometheus
        chart_ref: "prometheus-community/kube-prometheus-stack"
        chart_version: "{{ kube_prometheus_stack_version }}"
        release_namespace: "{{ monitoring_config.namespace }}"
        create_namespace: true
        wait: true
        wait_timeout: "900s"
        force: true
        values:
          # Configuration Prometheus optimisée
          prometheus:
            prometheusSpec:
              retention: "{{ monitoring_config.prometheus_retention }}"
              retentionSize: "8GB"
              storageSpec:
                volumeClaimTemplate:
                  spec:
                    accessModes: ["ReadWriteOnce"]
                    resources:
                      requests:
                        storage: "{{ monitoring_config.prometheus_storage }}"
              resources:
                requests:
                  cpu: "200m"
                  memory: "512Mi"
                limits:
                  cpu: "{{ monitoring_config.resource_limits.prometheus_cpu }}"
                  memory: "{{ monitoring_config.resource_limits.prometheus_memory }}"
              # Configuration pour éviter les problèmes de performance
              evaluationInterval: "30s"
              scrapeInterval: "30s"
              scrapeTimeout: "10s"
              # Règles d'alerte essentielles uniquement
              ruleSelector:
                matchLabels:
                  app: lions-infrastructure
                  tier: essential
            service:
              type: ClusterIP
              port: 9090
              targetPort: 9090

          # Configuration Grafana optimisée
          grafana:
            enabled: true
            adminPassword: "{{ monitoring_config.grafana_admin_password }}"
            persistence:
              enabled: true
              size: "{{ monitoring_config.grafana_storage }}"
              accessModes:
                - ReadWriteOnce
            service:
              type: NodePort
              nodePort: 30000
              port: 80
              targetPort: 3000
            resources:
              requests:
                cpu: "100m"
                memory: "128Mi"
              limits:
                cpu: "{{ monitoring_config.resource_limits.grafana_cpu }}"
                memory: "{{ monitoring_config.resource_limits.grafana_memory }}"
            # Configuration pour de meilleures performances
            grafana.ini:
              server:
                root_url: "http://{{ ansible_host }}:30000"
                serve_from_sub_path: false
              database:
                type: sqlite3
                cache_mode: shared
              users:
                allow_sign_up: false
                auto_assign_org: true
                auto_assign_org_role: Viewer
                default_theme: dark
              dashboards:
                default_home_dashboard_path: /tmp/dashboards/lions-overview.json
            # Dashboards par défaut optimisés
            defaultDashboardsEnabled: true
            defaultDashboardsTimezone: Europe/Paris
            sidecar:
              dashboards:
                enabled: true
                label: grafana_dashboard
                folder: /tmp/dashboards
                searchNamespace: ALL
              datasources:
                enabled: true
                defaultDatasourceEnabled: true

          # Configuration AlertManager simplifiée
          alertmanager:
            enabled: true
            alertmanagerSpec:
              storage:
                volumeClaimTemplate:
                  spec:
                    accessModes: ["ReadWriteOnce"]
                    resources:
                      requests:
                        storage: "2Gi"
              resources:
                requests:
                  cpu: "50m"
                  memory: "64Mi"
                limits:
                  cpu: "100m"
                  memory: "256Mi"
            service:
              type: ClusterIP
              port: 9093
            config:
              global:
                resolve_timeout: 5m
              route:
                group_by: ['alertname', 'cluster', 'service']
                group_wait: 30s
                group_interval: 5m
                repeat_interval: 12h
                receiver: 'lions-default'
              receivers:
                - name: 'lions-default'
                  webhook_configs:
                    - url: 'http://localhost:9093/api/v1/alerts'
                      send_resolved: true

          # Node Exporter optimisé
          nodeExporter:
            enabled: true
            serviceMonitor:
              enabled: true
              interval: "30s"
              scrapeTimeout: "10s"

          # Kube State Metrics optimisé
          kubeStateMetrics:
            enabled: true
            resources:
              requests:
                cpu: "10m"
                memory: "32Mi"
              limits:
                cpu: "100m"
                memory: "128Mi"

          # Configuration Service Monitor
          serviceMonitor:
            enabled: true
            interval: "30s"
            scrapeTimeout: "10s"

          # Désactivation des composants non essentiels pour optimiser les performances
          kubeApiServer:
            enabled: false
          kubelet:
            enabled: true
            serviceMonitor:
              interval: "30s"
          kubeControllerManager:
            enabled: false
          coreDns:
            enabled: true
            serviceMonitor:
              interval: "30s"
          kubeEtcd:
            enabled: false
          kubeScheduler:
            enabled: false
          kubeProxy:
            enabled: false

      environment:
        KUBECONFIG: "{{ k3s_kubeconfig }}"

    - name: "⏳ Vérification du déploiement du monitoring"
      block:
        - name: "Attente de la disponibilité des pods Prometheus"
          kubernetes.core.k8s_info:
            api_version: v1
            kind: Pod
            namespace: "{{ monitoring_config.namespace }}"
            label_selectors:
              - "app.kubernetes.io/name=prometheus"
            wait: true
            wait_condition:
              type: Ready
              status: "True"
            wait_timeout: 300
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Attente de la disponibilité des pods Grafana"
          kubernetes.core.k8s_info:
            api_version: v1
            kind: Pod
            namespace: "{{ monitoring_config.namespace }}"
            label_selectors:
              - "app.kubernetes.io/name=grafana"
            wait: true
            wait_condition:
              type: Ready
              status: "True"
            wait_timeout: 300
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Vérification de l'état des services monitoring"
          command: "/usr/local/bin/k3s kubectl get pods -n {{ monitoring_config.namespace }}"
          register: monitoring_pods_status
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Affichage de l'état du monitoring"
          debug:
            msg: |
              ==========================================================
              📊 ÉTAT DU MONITORING
              ==========================================================
              {{ monitoring_pods_status.stdout }}
              ==========================================================

    - name: "🔗 Configuration des accès monitoring"
      block:
        - name: "Création du service NodePort pour Prometheus"
          kubernetes.core.k8s:
            state: present
            definition:
              apiVersion: v1
              kind: Service
              metadata:
                name: prometheus-external
                namespace: "{{ monitoring_config.namespace }}"
                labels:
                  app: prometheus-external
              spec:
                type: NodePort
                ports:
                  - port: 9090
                    targetPort: 9090
                    nodePort: 30090
                    protocol: TCP
                    name: prometheus
                selector:
                  app.kubernetes.io/name: prometheus
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Récupération du mot de passe Grafana"
          kubernetes.core.k8s_info:
            api_version: v1
            kind: Secret
            name: prometheus-grafana
            namespace: "{{ monitoring_config.namespace }}"
          register: grafana_secret
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Affichage des informations d'accès"
          debug:
            msg: |
              ==========================================================
              🔐 INFORMATIONS D'ACCÈS MONITORING
              ==========================================================
              🎯 Grafana:
                URL: http://{{ ansible_host }}:30000
                Utilisateur: admin
                Mot de passe: {{ monitoring_config.grafana_admin_password }}
              
              📊 Prometheus:
                URL: http://{{ ansible_host }}:30090
                Interface Web: http://{{ ansible_host }}:30090/graph
              
              🚨 AlertManager:
                URL interne: http://prometheus-kube-prometheus-alertmanager:9093
              ==========================================================

    # =========================================================================
    # PHASE 8: VÉRIFICATIONS FINALES ET RAPPORT
    # =========================================================================

    - name: "✅ PHASE 8 - Vérifications finales et tests d'intégration"
      debug:
        msg: "Validation finale de l'installation complète avec monitoring"

    - name: "🏥 Tests de santé des composants"
      block:
        - name: "Vérification des nœuds K3s"
          command: "/usr/local/bin/k3s kubectl get nodes -o wide"
          register: final_nodes_check
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Vérification des pods système"
          command: "/usr/local/bin/k3s kubectl get pods --all-namespaces"
          register: final_pods_check
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Vérification des services"
          command: "/usr/local/bin/k3s kubectl get services --all-namespaces"
          register: final_services_check
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

        - name: "Vérification spécifique du monitoring"
          command: "/usr/local/bin/k3s kubectl get pods -n {{ monitoring_config.namespace }} -o wide"
          register: monitoring_final_check
          environment:
            KUBECONFIG: "{{ k3s_kubeconfig }}"

    - name: "🎯 Tests de connectivité des services"
      block:
        - name: "Test de connectivité Traefik"
          uri:
            url: "http://{{ ansible_host }}"
            method: GET
            status_code: [200, 404, 503]
            timeout: 10
          register: traefik_connectivity
          ignore_errors: true

        - name: "Test de connectivité Grafana"
          uri:
            url: "http://{{ ansible_host }}:30000"
            method: GET
            status_code: [200, 302]
            timeout: 15
          register: grafana_connectivity
          ignore_errors: true

        - name: "Test de connectivité Prometheus"
          uri:
            url: "http://{{ ansible_host }}:30090"
            method: GET
            status_code: [200]
            timeout: 15
          register: prometheus_connectivity
          ignore_errors: true

    - name: "📊 RAPPORT FINAL D'INSTALLATION COMPLÈTE"
      debug:
        msg: |
          ==========================================================
          🎉 INSTALLATION K3S LIONS + MONITORING TERMINÉE
          ==========================================================
          
          📍 INFORMATIONS GÉNÉRALES:
          • Host: {{ ansible_host }}
          • Version K3s: {{ k3s_version }}
          • Environment: {{ lions_env | default('development') }}
          • Date: {{ ansible_date_time.iso8601 }}
          
          🔧 COMPOSANTS INSTALLÉS:
          • ✅ K3s Server (API: :6443)
          • ✅ kubectl
          • ✅ Helm v3
          • ✅ Traefik Ingress Controller
          • ✅ cert-manager (TLS)
          • ✅ MetalLB Load Balancer
          • ✅ Prometheus Stack {{ kube_prometheus_stack_version }}
          • ✅ Grafana avec dashboards
          • ✅ AlertManager
          • ✅ Node Exporter
          
          🌐 ACCÈS SERVICES:
          • API Kubernetes: https://{{ ansible_host }}:6443
          • Traefik: http://{{ ansible_host }} {{ '✅' if traefik_connectivity.status == 200 else '⚠️' }}
          • Grafana: http://{{ ansible_host }}:30000 {{ '✅' if grafana_connectivity.status in [200, 302] else '⚠️' }}
          • Prometheus: http://{{ ansible_host }}:30090 {{ '✅' if prometheus_connectivity.status == 200 else '⚠️' }}
          
          🔐 CREDENTIALS:
          • Grafana User: admin
          • Grafana Password: {{ monitoring_config.grafana_admin_password }}
          
          📈 STATISTIQUES:
          • Nœuds: {{ final_nodes_check.stdout_lines | length - 1 }}
          • Namespaces: {{ (final_pods_check.stdout_lines | select('match', '^[^\\s]+\\s+[^\\s]+\\s+') | list | map('regex_replace', '^([^\\s]+)\\s+.*', '\\1') | unique | list) | length }}
          • Pods actifs: {{ (final_pods_check.stdout_lines | select('match', '.*Running.*') | list) | length }}
          • Pods monitoring: {{ (monitoring_final_check.stdout_lines | select('match', '.*Running.*') | list) | length }} / {{ monitoring_final_check.stdout_lines | length - 1 }}
          
          🚀 PROCHAINES ÉTAPES:
          1. ✅ Monitoring opérationnel (Prometheus + Grafana)
          2. Configurer les alertes personnalisées
          3. Configurer les certificats SSL (Let's Encrypt)
          4. Déployer les applications LIONS
          5. Configurer les sauvegardes automatiques
          
          💡 CONSEILS D'UTILISATION:
          • Accédez à Grafana pour visualiser vos métriques
          • Consultez Prometheus pour les requêtes avancées
          • Les dashboards par défaut sont pré-installés
          • Le monitoring est configuré pour une rétention de {{ monitoring_config.prometheus_retention }}
          
          ==========================================================

  # =============================================================================
  # HANDLERS
  # =============================================================================
  handlers:
    - name: "reload systemd and restart k3s"
      listen: "reload systemd and restart k3s"
      systemd:
        name: k3s
        state: restarted
        daemon_reload: yes
      register: k3s_handler_restart

    - name: "verify k3s after handler restart"
      listen: "reload systemd and restart k3s"
      wait_for:
        port: 6443
        host: localhost
        timeout: 120
      when: k3s_handler_restart is succeeded